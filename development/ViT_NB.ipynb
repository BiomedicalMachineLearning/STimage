{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "allied-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import stlearn as st\n",
    "st.settings.set_figure_params(dpi=300)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sys\n",
    "file = Path(\"../stimage\").resolve()\n",
    "parent= file.parent\n",
    "sys.path.append(str(parent))\n",
    "from PIL import Image\n",
    "from stimage._utils import gene_plot, Read10X, ReadOldST, tiling, ensembl_to_id\n",
    "from stimage._model import CNN_NB_multiple_genes, negative_binomial_layer, negative_binomial_loss\n",
    "from stimage._data_generator import DataGenerator\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "# import geopandas as gpd\n",
    "from sklearn.neighbors import KDTree\n",
    "from anndata import read_h5ad\n",
    "from tensorflow.keras import backend as K\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "modified-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "endangered-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from libpysal.weights.contiguity import Queen\n",
    "from libpysal import examples\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import splot\n",
    "from splot.esda import moran_scatterplot, lisa_cluster\n",
    "from esda.moran import Moran, Moran_Local\n",
    "from esda.moran import Moran_BV, Moran_Local_BV\n",
    "from splot.esda import plot_moran_bv_simulation, plot_moran_bv, plot_local_autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "presidential-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def plot_correlation(df, attr_1, attr_2):\n",
    "    r = stats.pearsonr(df[attr_1], \n",
    "                       df[attr_2])[0] **2\n",
    "\n",
    "    g = sns.lmplot(data=df,\n",
    "        x=attr_1, y=attr_2,\n",
    "        height=5, legend=True\n",
    "    )\n",
    "    # g.set(ylim=(0, 360), xlim=(0,360))\n",
    "\n",
    "    g.set_axis_labels(attr_1, attr_2)\n",
    "    plt.annotate(r'$R^2:{0:.2f}$'.format(r),\n",
    "                (max(df[attr_1])*0.9, max(df[attr_2])*0.9))\n",
    "    return g\n",
    "\n",
    "\n",
    "def calculate_correlation(attr_1, attr_2):\n",
    "    r = stats.pearsonr(attr_1, \n",
    "                       attr_2)[0]\n",
    "    return r\n",
    "\n",
    "def calculate_correlation_2(attr_1, attr_2):\n",
    "    r = stats.spearmanr(attr_1, \n",
    "                       attr_2)[0]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "jewish-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"/clusterdata/uqxtan9/Q1851/Xiao/Working_project/her2st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lasting-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_all = read_h5ad(DATA_PATH / \"all_adata.h5ad\")\n",
    "\n",
    "# adata_all = ensembl_to_id(adata_all)\n",
    "\n",
    "samples = adata_all.obs[\"library_id\"].unique().tolist()\n",
    "\n",
    "gene_list=[\"COX6C\",\"TTLL12\", \"PABPC1\", \"GNAS\", \"HSP90AB1\",\n",
    "           \"TFF3\", \"ATP1A1\", \"B2M\", \"FASN\", \"SPARC\", \"CD74\", \"CD63\", \"CD24\", \"CD81\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surgical-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_all.obs[\"X\"] = [x for x,y in adata_all.obs.index.str.split(\"x\")]\n",
    "adata_all.obs[\"Y\"] = [y.split(\"-\")[0] for x,y in adata_all.obs.index.str.split(\"x\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "appointed-swedish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10x22-C2     True\n",
       "10x23-C2     True\n",
       "11x21-C2     True\n",
       "11x22-C2     True\n",
       "11x23-C2     True\n",
       "            ...  \n",
       "9x23-D3     False\n",
       "9x24-D3     False\n",
       "9x25-D3     False\n",
       "9x26-D3     False\n",
       "9x27-D3     False\n",
       "Name: library_id, Length: 12584, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_all.obs.library_id == adata_all.obs.library_id.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "combined-oliver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagecol</th>\n",
       "      <th>imagerow</th>\n",
       "      <th>tile_path</th>\n",
       "      <th>tile_tissue_mask_path</th>\n",
       "      <th>tissue_area</th>\n",
       "      <th>library_id</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10x22-C2</th>\n",
       "      <td>2537.89</td>\n",
       "      <td>6112.46</td>\n",
       "      <td>/clusterdata/uqxtan9/Q1851/Xiao/Working_projec...</td>\n",
       "      <td>/tmp/C2_tissue_mask/C2-2537.89-6112.46-299.jpeg</td>\n",
       "      <td>0.985537</td>\n",
       "      <td>C2</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10x23-C2</th>\n",
       "      <td>2535.86</td>\n",
       "      <td>6396.68</td>\n",
       "      <td>/clusterdata/uqxtan9/Q1851/Xiao/Working_projec...</td>\n",
       "      <td>/tmp/C2_tissue_mask/C2-2535.86-6396.68-299.jpeg</td>\n",
       "      <td>0.891332</td>\n",
       "      <td>C2</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11x21-C2</th>\n",
       "      <td>2839.29</td>\n",
       "      <td>5824.46</td>\n",
       "      <td>/clusterdata/uqxtan9/Q1851/Xiao/Working_projec...</td>\n",
       "      <td>/tmp/C2_tissue_mask/C2-2839.29-5824.46-299.jpeg</td>\n",
       "      <td>0.994899</td>\n",
       "      <td>C2</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11x22-C2</th>\n",
       "      <td>2854.07</td>\n",
       "      <td>6104.30</td>\n",
       "      <td>/clusterdata/uqxtan9/Q1851/Xiao/Working_projec...</td>\n",
       "      <td>/tmp/C2_tissue_mask/C2-2854.07-6104.3-299.jpeg</td>\n",
       "      <td>0.990157</td>\n",
       "      <td>C2</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11x23-C2</th>\n",
       "      <td>2847.41</td>\n",
       "      <td>6388.81</td>\n",
       "      <td>/clusterdata/uqxtan9/Q1851/Xiao/Working_projec...</td>\n",
       "      <td>/tmp/C2_tissue_mask/C2-2847.41-6388.81-299.jpeg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>C2</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9x23-D3</th>\n",
       "      <td>2343.72</td>\n",
       "      <td>6411.11</td>\n",
       "      <td>/clusterdata/uqxtan9/Q1851/Xiao/Working_projec...</td>\n",
       "      <td>/tmp/D3_tissue_mask/D3-2343.72-6411.11-299.jpeg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>D3</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9x24-D3</th>\n",
       "      <td>2338.20</td>\n",
       "      <td>6707.19</td>\n",
       "      <td>/clusterdata/uqxtan9/Q1851/Xiao/Working_projec...</td>\n",
       "      <td>/tmp/D3_tissue_mask/D3-2338.2-6707.19-299.jpeg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>D3</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9x25-D3</th>\n",
       "      <td>2345.75</td>\n",
       "      <td>6992.77</td>\n",
       "      <td>/clusterdata/uqxtan9/Q1851/Xiao/Working_projec...</td>\n",
       "      <td>/tmp/D3_tissue_mask/D3-2345.75-6992.77-299.jpeg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>D3</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9x26-D3</th>\n",
       "      <td>2332.38</td>\n",
       "      <td>7289.73</td>\n",
       "      <td>/clusterdata/uqxtan9/Q1851/Xiao/Working_projec...</td>\n",
       "      <td>/tmp/D3_tissue_mask/D3-2332.38-7289.73-299.jpeg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>D3</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9x27-D3</th>\n",
       "      <td>2347.78</td>\n",
       "      <td>7565.10</td>\n",
       "      <td>/clusterdata/uqxtan9/Q1851/Xiao/Working_projec...</td>\n",
       "      <td>/tmp/D3_tissue_mask/D3-2347.78-7565.1-299.jpeg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>D3</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12584 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          imagecol  imagerow  \\\n",
       "10x22-C2   2537.89   6112.46   \n",
       "10x23-C2   2535.86   6396.68   \n",
       "11x21-C2   2839.29   5824.46   \n",
       "11x22-C2   2854.07   6104.30   \n",
       "11x23-C2   2847.41   6388.81   \n",
       "...            ...       ...   \n",
       "9x23-D3    2343.72   6411.11   \n",
       "9x24-D3    2338.20   6707.19   \n",
       "9x25-D3    2345.75   6992.77   \n",
       "9x26-D3    2332.38   7289.73   \n",
       "9x27-D3    2347.78   7565.10   \n",
       "\n",
       "                                                  tile_path  \\\n",
       "10x22-C2  /clusterdata/uqxtan9/Q1851/Xiao/Working_projec...   \n",
       "10x23-C2  /clusterdata/uqxtan9/Q1851/Xiao/Working_projec...   \n",
       "11x21-C2  /clusterdata/uqxtan9/Q1851/Xiao/Working_projec...   \n",
       "11x22-C2  /clusterdata/uqxtan9/Q1851/Xiao/Working_projec...   \n",
       "11x23-C2  /clusterdata/uqxtan9/Q1851/Xiao/Working_projec...   \n",
       "...                                                     ...   \n",
       "9x23-D3   /clusterdata/uqxtan9/Q1851/Xiao/Working_projec...   \n",
       "9x24-D3   /clusterdata/uqxtan9/Q1851/Xiao/Working_projec...   \n",
       "9x25-D3   /clusterdata/uqxtan9/Q1851/Xiao/Working_projec...   \n",
       "9x26-D3   /clusterdata/uqxtan9/Q1851/Xiao/Working_projec...   \n",
       "9x27-D3   /clusterdata/uqxtan9/Q1851/Xiao/Working_projec...   \n",
       "\n",
       "                                    tile_tissue_mask_path  tissue_area  \\\n",
       "10x22-C2  /tmp/C2_tissue_mask/C2-2537.89-6112.46-299.jpeg     0.985537   \n",
       "10x23-C2  /tmp/C2_tissue_mask/C2-2535.86-6396.68-299.jpeg     0.891332   \n",
       "11x21-C2  /tmp/C2_tissue_mask/C2-2839.29-5824.46-299.jpeg     0.994899   \n",
       "11x22-C2   /tmp/C2_tissue_mask/C2-2854.07-6104.3-299.jpeg     0.990157   \n",
       "11x23-C2  /tmp/C2_tissue_mask/C2-2847.41-6388.81-299.jpeg     1.000000   \n",
       "...                                                   ...          ...   \n",
       "9x23-D3   /tmp/D3_tissue_mask/D3-2343.72-6411.11-299.jpeg     1.000000   \n",
       "9x24-D3    /tmp/D3_tissue_mask/D3-2338.2-6707.19-299.jpeg     1.000000   \n",
       "9x25-D3   /tmp/D3_tissue_mask/D3-2345.75-6992.77-299.jpeg     1.000000   \n",
       "9x26-D3   /tmp/D3_tissue_mask/D3-2332.38-7289.73-299.jpeg     1.000000   \n",
       "9x27-D3    /tmp/D3_tissue_mask/D3-2347.78-7565.1-299.jpeg     1.000000   \n",
       "\n",
       "         library_id   X   Y  \n",
       "10x22-C2         C2  10  22  \n",
       "10x23-C2         C2  10  23  \n",
       "11x21-C2         C2  11  21  \n",
       "11x22-C2         C2  11  22  \n",
       "11x23-C2         C2  11  23  \n",
       "...             ...  ..  ..  \n",
       "9x23-D3          D3   9  23  \n",
       "9x24-D3          D3   9  24  \n",
       "9x25-D3          D3   9  25  \n",
       "9x26-D3          D3   9  26  \n",
       "9x27-D3          D3   9  27  \n",
       "\n",
       "[12584 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_all.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intellectual-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_x = adata_all.obs.X.astype(int).max()\n",
    "max_y = adata_all.obs.Y.astype(int).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dimensional-evanescence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "amino-following",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pursuant-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from stimage._imgaug import seq_aug\n",
    "# from sklearn.neighbors import KDTree\n",
    "\n",
    "\n",
    "# class DataGenerator(keras.utils.Sequence):\n",
    "#     'Generates data for Keras'\n",
    "\n",
    "#     def __init__(self, adata, dim=(299, 299), n_channels=3, genes=None, aug=False, tile_path=\"tile_path\"):\n",
    "#         'Initialization'\n",
    "#         self.dim = dim\n",
    "#         self.adata = adata\n",
    "#         self.n_channels = n_channels\n",
    "#         self.genes = genes\n",
    "#         self.num_genes = len(genes)\n",
    "#         self.aug = aug\n",
    "#         self.tile_path = tile_path\n",
    "#         self.on_epoch_end()\n",
    "\n",
    "#     def __len__(self):\n",
    "#         'Denotes the number of batches per epoch'\n",
    "#         return len(self.adata.obs.library_id.unique())\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         'Generate one batch of data'\n",
    "#         # Find list of IDs\n",
    "#         obs_temp = self.adata.obs_names[self.adata.obs.library_id == self.adata.obs.library_id.unique()[index]]\n",
    "\n",
    "#         # Generate data\n",
    "#         X_img = self._load_img(obs_temp)\n",
    "#         y = self._load_label(obs_temp)\n",
    "#         pos_x,pos_y = self._load_position(obs_temp)\n",
    "        \n",
    "#         return {\"input_img\":X_img, \"x\":pos_x, \"y\":pos_y}, y\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         'Updates indexes after each epoch'\n",
    "#         self.indexes = np.arange(len(self.adata.obs.library_id.unique()))\n",
    "\n",
    "#     def _load_img(self, obs):\n",
    "#         img_paths = self.adata.obs.loc[obs, 'tile_path']\n",
    "#         X_img = np.zeros(shape=(len(img_paths),299,299,3))\n",
    "#         for i, img_path in enumerate(img_paths):\n",
    "#             X_img_ = image.load_img(img_path, target_size=self.dim)\n",
    "#             X_img[i] = image.img_to_array(X_img_).astype('uint8')\n",
    "#             #         X_img = np.expand_dims(X_img, axis=0)\n",
    "#             #         n_rotate = np.random.randint(0, 4)\n",
    "#             #         X_img = np.rot90(X_img, k=n_rotate, axes=(1, 2))\n",
    "#             if self.aug:\n",
    "#                 X_img = seq_aug(image=X_img)\n",
    "#                 # X_img = preprocess_resnet(X_img)\n",
    "#         return X_img\n",
    "\n",
    "#     def _load_label(self, obs):\n",
    "#         batch_adata = self.adata[obs, self.genes].copy()\n",
    "\n",
    "#         return tuple([batch_adata.to_df()[i].values for i in self.genes])\n",
    "    \n",
    "#     def _load_position(self, obs):\n",
    "#         return self.adata.obs.loc[obs, \"X\"].values, self.adata.obs.loc[obs, \"Y\"].values\n",
    "        \n",
    "        \n",
    "#     def get_classes(self):\n",
    "#         return self.adata.to_df().loc[:, self.genes]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "million-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from stimage._imgaug import seq_aug\n",
    "from sklearn.neighbors import KDTree\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    def __init__(self, adata, dim=(299, 299), n_channels=3, genes=None, aug=False, tile_path=\"tile_path\"):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.adata = adata\n",
    "        self.n_channels = n_channels\n",
    "        self.genes = genes\n",
    "        self.num_genes = len(genes)\n",
    "        self.aug = aug\n",
    "        self.tile_path = tile_path\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(self.adata.n_obs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Find list of IDs\n",
    "        obs_temp = self.adata.obs_names[index]\n",
    "\n",
    "        # Generate data\n",
    "        X_img = self._load_img(obs_temp)\n",
    "        y = self._load_label(obs_temp)\n",
    "        pos_x,pos_y = self._load_position(obs_temp)\n",
    "        \n",
    "        return {\"input_img\":X_img, \"x\":pos_x, \"y\":pos_y}, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.adata.n_obs)\n",
    "\n",
    "    def _load_img(self, obs):\n",
    "        img_path = self.adata.obs.loc[obs, 'tile_path']\n",
    "        X_img = image.load_img(img_path, target_size=self.dim)\n",
    "        X_img = image.img_to_array(X_img).astype('uint8')\n",
    "        #         X_img = np.expand_dims(X_img, axis=0)\n",
    "        #         n_rotate = np.random.randint(0, 4)\n",
    "        #         X_img = np.rot90(X_img, k=n_rotate, axes=(1, 2))\n",
    "        if self.aug:\n",
    "            X_img = seq_aug(image=X_img)\n",
    "#         X_img = preprocess_resnet(X_img)\n",
    "        return X_img\n",
    "\n",
    "    def _load_label(self, obs):\n",
    "        batch_adata = self.adata[obs, self.genes].copy()\n",
    "\n",
    "        return tuple([batch_adata.to_df()[i].values for i in self.genes])\n",
    "    \n",
    "    def _load_position(self, obs):\n",
    "        return int(self.adata.obs.loc[obs, \"X\"]), int(self.adata.obs.loc[obs, \"Y\"])\n",
    "\n",
    "    def get_classes(self):\n",
    "        return self.adata.to_df().loc[:, self.genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "german-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = int(sys.argv[1])\n",
    "i = 0\n",
    "\n",
    "test_sample = samples[i]\n",
    "n_genes = len(gene_list)\n",
    "\n",
    "adata_all_train_valid = adata_all[adata_all.obs[\"library_id\"].isin(\n",
    "    adata_all.obs.library_id.cat.remove_categories(test_sample).unique())]\n",
    "\n",
    "training_index = adata_all_train_valid.obs.sample(frac=0.7, random_state=1).index\n",
    "training_dataset = adata_all_train_valid[training_index,].copy()\n",
    "\n",
    "valid_index = adata_all_train_valid.obs.index.isin(training_index)\n",
    "valid_dataset = adata_all_train_valid[~valid_index,].copy()\n",
    "\n",
    "test_index = adata_all.obs.library_id == test_sample\n",
    "test_dataset_1 = adata_all[test_index,].copy()\n",
    "\n",
    "\n",
    "train_gen = tf.data.Dataset.from_generator(\n",
    "        lambda:DataGenerator(adata=training_dataset,\n",
    "                      genes=gene_list, aug=False),\n",
    "        output_types=({\"input_img\":tf.float32, \"x\":tf.float32, \"y\":tf.float32}, tuple([tf.float32]*n_genes)),\n",
    "#         output_shapes=([299,299,3],1,1, tuple([1]*n_genes))\n",
    ")\n",
    "train_gen_ = train_gen.shuffle(buffer_size=10).batch(32).repeat(1).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_gen = tf.data.Dataset.from_generator(\n",
    "        lambda:DataGenerator(adata=valid_dataset,\n",
    "                      genes=gene_list),\n",
    "        output_types=({\"input_img\":tf.float32, \"x\":tf.float32, \"y\":tf.float32}, tuple([tf.float32]*n_genes)),\n",
    "#         output_shapes=(([299,299,3],1,1), tuple([1]*n_genes))\n",
    ")\n",
    "valid_gen_ = valid_gen.shuffle(buffer_size=10).batch(32).repeat(1).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_gen_1 = tf.data.Dataset.from_generator(\n",
    "        lambda:DataGenerator(adata=test_dataset_1,\n",
    "                      genes=gene_list),\n",
    "        output_types=({\"input_img\":tf.float32, \"x\":tf.float32, \"y\":tf.float32}, tuple([tf.float32]*n_genes)),\n",
    "#         output_shapes=(([299,299,3],1,1), tuple([1]*n_genes))\n",
    ")\n",
    "test_gen__1 = test_gen_1.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "turned-value",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for a, b in train_gen_.take(1):\n",
    "#     print(a)\n",
    "#     print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-martial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "disturbed-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "racial-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PatchEncoder(layers.Layer):\n",
    "#     def __init__(self, position_dim, projection_dim):\n",
    "#         super(PatchEncoder, self).__init__()\n",
    "#         self.num_patches = position_dim\n",
    "#         self.projection = layers.Dense(units=projection_dim)\n",
    "#         self.position_embedding = layers.Embedding(\n",
    "#             input_dim=position_dim, output_dim=projection_dim\n",
    "#         )\n",
    "\n",
    "#     def call(self, patch, x, y):\n",
    "#         encoded = self.projection(patch) + self.position_embedding(x) + self.position_embedding(y)\n",
    "# #         encoded = self.position_embedding(x) + self.position_embedding(y)\n",
    "#         return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "tracked-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PatchEncoder(layers.Layer):\n",
    "#     def __init__(self, position_dim, projection_dim):\n",
    "#         super(PatchEncoder, self).__init__()\n",
    "#         self.num_patches = position_dim\n",
    "#         self.projection = layers.Dense(projection_dim, input_shape=(299,299,3), activation=None)\n",
    "#         self.position_embedding_x = layers.Embedding(\n",
    "#             input_dim=position_dim, output_dim=projection_dim\n",
    "#         )\n",
    "#         self.position_embedding_y = layers.Embedding(\n",
    "#             input_dim=position_dim, output_dim=projection_dim\n",
    "#         )\n",
    "\n",
    "#     def call(self, patch, x, y):\n",
    "#         encoded = self.projection(patch) + self.position_embedding_x(x) + self.position_embedding_y(y)\n",
    "# #         encoded = self.position_embedding(x) + self.position_embedding(y)\n",
    "#         return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "printable-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "endless-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "def ViT_NB(tile_shape, pos_shape, n_genes=None, projection_dim=64, num_patches=24, transformer_layers=8,\n",
    "           mlp_head_units = [256, 128], num_heads = 4, patch_size=13):\n",
    "    tile_inputs = layers.Input(shape=tile_shape,name=\"input_img\")\n",
    "    x = layers.Input(shape=pos_shape, name=\"x\")\n",
    "    y = layers.Input(shape=pos_shape, name=\"y\")\n",
    "#     tile_emb = layers.Flatten()(tile_inputs)\n",
    "#     resnet_base = ResNet50(weights='imagenet', include_top=False, pooling=\"max\")\n",
    "#     for i in range(len(resnet_base.layers)):\n",
    "#         resnet_base.layers[i].trainable = False\n",
    "#     tile_features = resnet_base(tile_inputs)\n",
    "    \n",
    "    num_patches = (299 // patch_size) ** 2\n",
    "    patches = Patches(patch_size)(tile_inputs)\n",
    "    \n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "    \n",
    "    transformer_units = [\n",
    "        projection_dim*2,\n",
    "        projection_dim,\n",
    "    ]\n",
    "\n",
    "    for _ in range(transformer_layers):\n",
    "\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1,x1)\n",
    "\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "#     representation = layers.GlobalAveragePooling1D()(representation)\n",
    "    representation = layers.Flatten()(representation)\n",
    "#     representation = layers.Dropout(0.5)(representation)\n",
    "\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.1)\n",
    "\n",
    "    output_layers = []\n",
    "    for i in range(n_genes):\n",
    "        output = layers.Dense(2)(features)\n",
    "        output_layers.append(layers.Lambda(negative_binomial_layer, name=\"gene_{}\".format(i))(output))\n",
    "\n",
    "    model = Model(inputs=[tile_inputs, x, y], outputs=output_layers)\n",
    "    #     losses={}\n",
    "    #     for i in range(8):\n",
    "    #         losses[\"gene_{}\".format(i)] = negative_binomial_loss(i)\n",
    "    #     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "    model.compile(loss=negative_binomial_loss,\n",
    "                  optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "technological-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = ViT_NB(tile_shape=(299,299,3), pos_shape=1, n_genes=n_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "brave-serum",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_img (InputLayer)          [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "patches (Patches)               (None, None, 507)    0           input_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "patch_encoder (PatchEncoder)    (None, 529, 64)      66368       patches[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 529, 64)      128         patch_encoder[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 529, 64)      66368       layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 529, 64)      0           multi_head_attention[0][0]       \n",
      "                                                                 patch_encoder[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 529, 64)      128         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 529, 128)     8320        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 529, 128)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 529, 64)      8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 529, 64)      0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 529, 64)      0           dropout_1[0][0]                  \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 529, 64)      128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 529, 64)      66368       layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 529, 64)      0           multi_head_attention_1[0][0]     \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 529, 64)      128         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 529, 128)     8320        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 529, 128)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 529, 64)      8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 529, 64)      0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 529, 64)      0           dropout_3[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 529, 64)      128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 529, 64)      66368       layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 529, 64)      0           multi_head_attention_2[0][0]     \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 529, 64)      128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 529, 128)     8320        layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 529, 128)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 529, 64)      8256        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 529, 64)      0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 529, 64)      0           dropout_5[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 529, 64)      128         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 529, 64)      66368       layer_normalization_6[0][0]      \n",
      "                                                                 layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 529, 64)      0           multi_head_attention_3[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 529, 64)      128         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 529, 128)     8320        layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 529, 128)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 529, 64)      8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 529, 64)      0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 529, 64)      0           dropout_7[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 529, 64)      128         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 529, 64)      66368       layer_normalization_8[0][0]      \n",
      "                                                                 layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 529, 64)      0           multi_head_attention_4[0][0]     \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (None, 529, 64)      128         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 529, 128)     8320        layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 529, 128)     0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 529, 64)      8256        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 529, 64)      0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 529, 64)      0           dropout_9[0][0]                  \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNo (None, 529, 64)      128         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHe (None, 529, 64)      66368       layer_normalization_10[0][0]     \n",
      "                                                                 layer_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 529, 64)      0           multi_head_attention_5[0][0]     \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNo (None, 529, 64)      128         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 529, 128)     8320        layer_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 529, 128)     0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 529, 64)      8256        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 529, 64)      0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 529, 64)      0           dropout_11[0][0]                 \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, 529, 64)      128         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_6 (MultiHe (None, 529, 64)      66368       layer_normalization_12[0][0]     \n",
      "                                                                 layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 529, 64)      0           multi_head_attention_6[0][0]     \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNo (None, 529, 64)      128         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 529, 128)     8320        layer_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 529, 128)     0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 529, 64)      8256        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 529, 64)      0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 529, 64)      0           dropout_13[0][0]                 \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, 529, 64)      128         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_7 (MultiHe (None, 529, 64)      66368       layer_normalization_14[0][0]     \n",
      "                                                                 layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 529, 64)      0           multi_head_attention_7[0][0]     \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_15 (LayerNo (None, 529, 64)      128         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 529, 128)     8320        layer_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 529, 128)     0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 529, 64)      8256        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 529, 64)      0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 529, 64)      0           dropout_15[0][0]                 \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, 529, 64)      128         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 33856)        0           layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          8667392     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 256)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          32896       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 128)          0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 2)            258         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "x (InputLayer)                  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "y (InputLayer)                  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gene_0 (Lambda)                 (None, 2)            0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_1 (Lambda)                 (None, 2)            0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_2 (Lambda)                 (None, 2)            0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_3 (Lambda)                 (None, 2)            0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_4 (Lambda)                 (None, 2)            0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_5 (Lambda)                 (None, 2)            0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_6 (Lambda)                 (None, 2)            0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_7 (Lambda)                 (None, 2)            0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_8 (Lambda)                 (None, 2)            0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_9 (Lambda)                 (None, 2)            0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_10 (Lambda)                (None, 2)            0           dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_11 (Lambda)                (None, 2)            0           dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_12 (Lambda)                (None, 2)            0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gene_13 (Lambda)                (None, 2)            0           dense_32[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 9,435,996\n",
      "Trainable params: 9,435,996\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "hairy-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 403s 1s/step - loss: 21.0997 - gene_0_loss: 1.3475 - gene_1_loss: 0.9480 - gene_2_loss: 1.6502 - gene_3_loss: 1.5688 - gene_4_loss: 1.4606 - gene_5_loss: 1.1574 - gene_6_loss: 1.5859 - gene_7_loss: 1.7486 - gene_8_loss: 1.6521 - gene_9_loss: 1.4427 - gene_10_loss: 1.7358 - gene_11_loss: 1.8393 - gene_12_loss: 1.4009 - gene_13_loss: 1.5619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5e25426670>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen_, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "engaged-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_gen__1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "lightweight-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import nbinom\n",
    "y_preds = []\n",
    "for i in range(n_genes):\n",
    "    n = test_predictions[i][:, 0]\n",
    "    p = test_predictions[i][:, 1]\n",
    "    y_pred = nbinom.mean(n, p)\n",
    "    y_preds.append(y_pred)\n",
    "test_dataset_1.obsm[\"predicted_gene\"] = np.array(y_preds).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "exotic-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "three-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_1_ = test_dataset_1[:,gene_list].copy()\n",
    "test_dataset_1_.X = test_dataset_1_.obsm[\"predicted_gene\"]\n",
    "\n",
    "pred_adata = test_dataset_1_\n",
    "test_dataset = test_dataset_1\n",
    "\n",
    "for gene in pred_adata.var_names:\n",
    "    cor_val = calculate_correlation(pred_adata.to_df().loc[:,gene], test_dataset.to_df().loc[:,gene])\n",
    "    df = df.append(pd.Series([gene, cor_val, test_sample, \"STimage\"], \n",
    "                         index=[\"Gene\", \"Pearson correlation\", \"Slide\", \"Method\"]),\n",
    "                  ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "golden-moldova",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23832510908865237"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Pearson correlation\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-amino",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
