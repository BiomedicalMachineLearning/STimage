{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import stlearn as st\n",
    "st.settings.set_figure_params(dpi=300)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sys\n",
    "file = Path(\"../stimage\").resolve()\n",
    "parent= file.parent\n",
    "sys.path.append(str(parent))\n",
    "from PIL import Image\n",
    "from stimage._utils import gene_plot, Read10X, ReadOldST, tiling\n",
    "from stimage._model import CNN_NB_multiple_genes\n",
    "from stimage._data_generator import DataGenerator\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout, Lambda, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "class PrinterCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    # def on_train_batch_begin(self, batch, logs=None):\n",
    "    #     # Do something on begin of training batch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('EPOCH: {}, Train Loss: {}, Val Loss: {}'.format(epoch,\n",
    "                                                               logs['loss'],\n",
    "                                                               logs['val_loss']))\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print('-' * 50)\n",
    "        print('STARTING EPOCH: {}'.format(epoch))\n",
    "\n",
    "\n",
    "def negative_binomial_layer(x):\n",
    "    \"\"\"\n",
    "    Lambda function for generating negative binomial parameters\n",
    "    n and p from a Dense(2) output.\n",
    "    Assumes tensorflow 2 backend.\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    outputs = Dense(2)(final_layer)\n",
    "    distribution_outputs = Lambda(negative_binomial_layer)(outputs)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : tf.Tensor\n",
    "        output tensor of Dense layer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out_tensor : tf.Tensor\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the number of dimensions of the input\n",
    "    num_dims = len(x.get_shape())\n",
    "\n",
    "    # Separate the parameters\n",
    "    n, p = tf.unstack(x, num=2, axis=-1)\n",
    "\n",
    "    # Add one dimension to make the right shape\n",
    "    n = tf.expand_dims(n, -1)\n",
    "    p = tf.expand_dims(p, -1)\n",
    "\n",
    "    # Apply a softplus to make positive\n",
    "    n = tf.keras.activations.softplus(n)\n",
    "\n",
    "    # Apply a sigmoid activation to bound between 0 and 1\n",
    "    p = tf.keras.activations.sigmoid(p)\n",
    "\n",
    "    # Join back together again\n",
    "    out_tensor = tf.concat((n, p), axis=num_dims - 1)\n",
    "\n",
    "    return out_tensor\n",
    "\n",
    "\n",
    "def negative_binomial_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Negative binomial loss function.\n",
    "    Assumes tensorflow backend.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : tf.Tensor\n",
    "        Ground truth values of predicted variable.\n",
    "    y_pred : tf.Tensor\n",
    "        n and p values of predicted distribution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nll : tf.Tensor\n",
    "        Negative log likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate the parameters\n",
    "    n, p = tf.unstack(y_pred, num=2, axis=-1)\n",
    "\n",
    "    # Add one dimension to make the right shape\n",
    "    n = tf.expand_dims(n, -1)\n",
    "    p = tf.expand_dims(p, -1)\n",
    "\n",
    "    # Calculate the negative log likelihood\n",
    "    nll = (\n",
    "            tf.math.lgamma(n)\n",
    "            + tf.math.lgamma(y_true + 1)\n",
    "            - tf.math.lgamma(n + y_true)\n",
    "            - n * tf.math.log(p)\n",
    "            - y_true * tf.math.log(1 - p)\n",
    "    )\n",
    "\n",
    "    return nll\n",
    "\n",
    "\n",
    "\n",
    "def CNN_NB_multiple_genes_feature_z(tile_shape, n_genes):\n",
    "    tile_input = Input(shape=tile_shape, name=\"tile_input\")\n",
    "    resnet_base = ResNet50(input_tensor=tile_input, weights='imagenet', include_top=False)\n",
    "    #     stage_5_start = resnet_base.get_layer(\"conv5_block1_1_conv\")\n",
    "    #     for i in range(resnet_base.layers.index(stage_5_start)):\n",
    "    #         resnet_base.layers[i].trainable = False\n",
    "\n",
    "    for i in resnet_base.layers:\n",
    "        i.trainable = False\n",
    "    cnn = resnet_base.output\n",
    "    cnn = GlobalAveragePooling2D()(cnn)\n",
    "    #     cnn = Dropout(0.5)(cnn)\n",
    "    #     cnn = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.01),\n",
    "    #                 activity_regularizer=tf.keras.regularizers.l2(0.01))(cnn)\n",
    "    # cnn = Dense(256, activation='relu')(cnn)\n",
    "    cnn = LayerNormalization()(cnn)\n",
    "    output_layers = []\n",
    "    for i in range(n_genes):\n",
    "        output = Dense(2)(cnn)\n",
    "        output_layers.append(Lambda(negative_binomial_layer, name=\"gene_{}\".format(i))(output))\n",
    "\n",
    "    model = Model(inputs=tile_input, outputs=output_layers)\n",
    "    #     losses={}\n",
    "    #     for i in range(8):\n",
    "    #         losses[\"gene_{}\".format(i)] = negative_binomial_loss(i)\n",
    "    #     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "    model.compile(loss=negative_binomial_loss,\n",
    "                  optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "\n",
    "def CNN_NB_multiple_genes_feature_minmax(tile_shape, n_genes):\n",
    "    tile_input = Input(shape=tile_shape, name=\"tile_input\")\n",
    "    resnet_base = ResNet50(input_tensor=tile_input, weights='imagenet', include_top=False)\n",
    "    #     stage_5_start = resnet_base.get_layer(\"conv5_block1_1_conv\")\n",
    "    #     for i in range(resnet_base.layers.index(stage_5_start)):\n",
    "    #         resnet_base.layers[i].trainable = False\n",
    "\n",
    "    for i in resnet_base.layers:\n",
    "        i.trainable = False\n",
    "    cnn = resnet_base.output\n",
    "    cnn = GlobalAveragePooling2D()(cnn)\n",
    "    #     cnn = Dropout(0.5)(cnn)\n",
    "    #     cnn = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.01),\n",
    "    #                 activity_regularizer=tf.keras.regularizers.l2(0.01))(cnn)\n",
    "    # cnn = Dense(256, activation='relu')(cnn)\n",
    "    cnn = Lambda(lambda x: (x - tf.math.reduce_min(x))/(tf.math.reduce_max(x) - tf.math.reduce_min(x)))(cnn)\n",
    "    output_layers = []\n",
    "    for i in range(n_genes):\n",
    "        output = Dense(2)(cnn)\n",
    "        output_layers.append(Lambda(negative_binomial_layer, name=\"gene_{}\".format(i))(output))\n",
    "\n",
    "    model = Model(inputs=tile_input, outputs=output_layers)\n",
    "    #     losses={}\n",
    "    #     for i in range(8):\n",
    "    #         losses[\"gene_{}\".format(i)] = negative_binomial_loss(i)\n",
    "    #     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "    model.compile(loss=negative_binomial_loss,\n",
    "                  optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "\n",
    "def CNN_NB_multiple_genes_feature_global(n_genes):\n",
    "    inputs = Input(shape=(2048,))\n",
    "    output_layers = []\n",
    "    for i in range(n_genes):\n",
    "        output = Dense(2)(inputs)\n",
    "        output_layers.append(Lambda(negative_binomial_layer, name=\"gene_{}\".format(i))(output))\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output_layers)\n",
    "    #     losses={}\n",
    "    #     for i in range(8):\n",
    "    #         losses[\"gene_{}\".format(i)] = negative_binomial_loss(i)\n",
    "    #     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "    model.compile(loss=negative_binomial_loss,\n",
    "                  optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(\"/clusterdata/uqxtan9/Xiao/STimage/dataset/breast_cancer_10x_visium\")\n",
    "TILE_PATH = Path(\"/tmp\") / \"tiles\"\n",
    "TILE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAMPLE = \"block1\"\n",
    "Sample1 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\", 0)\n",
    "Sample1.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img\n",
    "\n",
    "SAMPLE = \"block2\"\n",
    "Sample2 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_2_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_2_image.tif\", 0)\n",
    "Sample2.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_list = [\"ACTA2\", \"CNN1\", \"COL1A1\", \"MYLK\", \"MME\", \"MYH11\", \"KRT5\", \"ITGB6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_plot(Sample1, genes=gene_list, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_plot(Sample2, genes=gene_list, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anndata import AnnData\n",
    "from typing import Iterable, Union, Optional\n",
    "import pandas as pd\n",
    "def enrich_group(adata: AnnData,\n",
    "                 gene_list: Iterable,\n",
    "                 enrich_name: Union[pd.Index, list],\n",
    "                 \n",
    "\n",
    "                \n",
    ") -> Optional[AnnData]:\n",
    "    adata_ = adata[:,adata.var_names.isin(gene_list)].copy()\n",
    "    adata_enrich = AnnData(X=adata_.X.sum(axis=1),\n",
    "                       obs=adata_.obs,\n",
    "                       uns=adata_.uns,\n",
    "                       obsm=adata_.obsm)\n",
    "    adata_enrich.var_names = enrich_name\n",
    "    return adata_enrich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-graphic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-publicity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-audience",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_list=[\"SLITRK6\", \"PGM5\", \"LINC00645\", \n",
    "#            \"TTLL12\", \"COX6C\", \"CPB1\",\n",
    "#            \"KRT5\", \"MALAT1\"]\n",
    "# gene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-carbon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for adata in [\n",
    "    Sample1,\n",
    "    Sample2,\n",
    "]:\n",
    "#     count_df = adata.to_df()\n",
    "#     count_df[count_df <=1] = 0\n",
    "#     count_df[count_df >1] = 1\n",
    "#     adata.X = count_df\n",
    "#     adata[:,gene_list]\n",
    "    st.pp.filter_genes(adata,min_cells=3)\n",
    "#     st.pp.normalize_total(adata)\n",
    "    st.pp.log1p(adata)\n",
    "#     st.pp.scale(adata)\n",
    "\n",
    "    # pre-processing for spot image\n",
    "    TILE_PATH_ = TILE_PATH / list(adata.uns[\"spatial\"].keys())[0]\n",
    "    TILE_PATH_.mkdir(parents=True, exist_ok=True)\n",
    "    tiling(adata, TILE_PATH_, crop_size=299)\n",
    "#     st.pp.extract_feature(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_1 = Sample1.to_df().filter(regex=(\"KRT.*\")).columns\n",
    "gene_list_2 = Sample2.to_df().filter(regex=(\"KRT.*\")).columns\n",
    "gene_list_share = gene_list_1.intersection(gene_list_2)\n",
    "len(gene_list_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-malpractice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list=pd.Index([\"KRT_enrich\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample1 = enrich_group(Sample1, \n",
    "                       gene_list_share, \n",
    "                       gene_list)\n",
    "Sample2 = enrich_group(Sample2, \n",
    "                       gene_list_share, \n",
    "                       gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from libpysal.weights.contiguity import Queen\n",
    "from libpysal import examples\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import splot\n",
    "from splot.esda import moran_scatterplot, lisa_cluster\n",
    "from esda.moran import Moran, Moran_Local\n",
    "from esda.moran import Moran_BV, Moran_Local_BV\n",
    "from splot.esda import plot_moran_bv_simulation, plot_moran_bv, plot_local_autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample1.obsm[\"gpd\"] = gpd.GeoDataFrame(Sample1.obs,\n",
    "                                             geometry=gpd.points_from_xy(\n",
    "                                                 Sample1.obs.imagecol, \n",
    "                                                 Sample1.obs.imagerow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-attribute",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Sample1.obsm[\"gpd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-fifth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-robin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Sample1.to_df()[gene_list].values\n",
    "y = Sample1.to_df()[gene_list].values\n",
    "w = Queen.from_dataframe(Sample1.obsm[\"gpd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample1.obsm[\"gpd\"][\"gc_{}\".format(gene_list.names)] = x\n",
    "tissue_image = Sample1.uns[\"spatial\"][\"block1\"][\"images\"][\"fulres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "moran = Moran(y,w)\n",
    "moran_bv = Moran_BV(y, x, w)\n",
    "moran_loc = Moran_Local(y, w, permutations=0)\n",
    "moran_loc_bv = Moran_Local_BV(y, x, w, permutations=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = moran_scatterplot(moran_loc, aspect_equal=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa_cluster(moran_loc, Sample1.obsm[\"gpd\"], p=0.05,\n",
    "             figsize = (9,9), markersize=12, **{\"alpha\":1 })\n",
    "plt.imshow(Sample1.uns[\"spatial\"][\"block1\"][\"images\"][\"fulres\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc.p_sim =mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sim = moran_loc.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (p_sim>=20) & (p_sim<=32) & (lag >=20) & (lag<=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask *1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample1_ = Sample1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample1_.X = (Sample1_.X >18)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_plot(Sample1, genes=gene_list, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-treatment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-roberts",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-aggregate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-republic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal.weights.spatial_lag import lag_spatial\n",
    "lag = lag_spatial(moran_loc.w, moran_loc.y)\n",
    "b, a = np.polyfit(moran_loc.y, lag, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(moran_loc.y, lag)\n",
    "plt.plot(moran_loc.y, a + b*moran_loc.y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-traffic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-malta",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-granny",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = len(gene_list)\n",
    "training_index = Sample1.obs.sample(frac=0.7, random_state=1).index\n",
    "training_dataset = Sample1[training_index,].copy()\n",
    "\n",
    "valid_index = Sample1.obs.index.isin(training_index)\n",
    "valid_dataset = Sample1[~valid_index,].copy()\n",
    "\n",
    "test_dataset = Sample2.copy()\n",
    "\n",
    "train_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator(adata=training_dataset, \n",
    "                          genes=gene_list, aug=False),\n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "train_gen_ = train_gen.shuffle(buffer_size=500).batch(128).repeat(3).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator(adata=valid_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "valid_gen_ = valid_gen.shuffle(buffer_size=500).batch(128).repeat(3).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator(adata=test_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "test_gen_ = test_gen.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-minimum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_NB_multiple_genes((299, 299, 3), n_genes)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,\n",
    "                                            restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-present",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_history = model.fit(train_gen_,\n",
    "                          epochs=100,\n",
    "                          validation_data=valid_gen_,\n",
    "                          callbacks=[callback]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_gen_)\n",
    "from scipy.stats import nbinom\n",
    "y_preds = []\n",
    "if n_genes >1:\n",
    "    for i in range(n_genes):\n",
    "        n = test_predictions[i][:, 0]\n",
    "        p = test_predictions[i][:, 1]\n",
    "        y_pred = nbinom.mean(n, p)\n",
    "        y_preds.append(y_pred)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = np.array(y_preds).transpose()\n",
    "else:\n",
    "    n = test_predictions[:, 0]\n",
    "    p = test_predictions[:, 1]\n",
    "    y_pred = nbinom.mean(n, p)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./CNN_NB_8genes_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_ = test_dataset[:,gene_list].copy()\n",
    "test_dataset_.X = test_dataset_.obsm[\"predicted_gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gene_list:\n",
    "    print(i)\n",
    "    gene_plot(Sample1, genes=i, spot_size=8)\n",
    "    gene_plot(test_dataset_, genes=i, spot_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-familiar",
   "metadata": {},
   "source": [
    "# z score transformed features layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_NB_multiple_genes_feature_z((299, 299, 3), n_genes)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,\n",
    "                                            restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-sound",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_history = model.fit(train_gen_,\n",
    "                          epochs=100,\n",
    "                          validation_data=valid_gen_,\n",
    "                          callbacks=[callback]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_gen_)\n",
    "from scipy.stats import nbinom\n",
    "y_preds = []\n",
    "if n_genes >1:\n",
    "    for i in range(n_genes):\n",
    "        n = test_predictions[i][:, 0]\n",
    "        p = test_predictions[i][:, 1]\n",
    "        y_pred = nbinom.mean(n, p)\n",
    "        # scale\n",
    "        y_preds.append(y_pred)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = np.array(y_preds).transpose()\n",
    "else:\n",
    "    n = test_predictions[:, 0]\n",
    "    p = test_predictions[:, 1]\n",
    "    y_pred = nbinom.mean(n, p)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_ = test_dataset[:,gene_list].copy()\n",
    "test_dataset_.X = test_dataset_.obsm[\"predicted_gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gene_list:\n",
    "    print(i)\n",
    "    gene_plot(Sample1, genes=i, spot_size=8)\n",
    "    gene_plot(test_dataset_, genes=i, spot_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-beast",
   "metadata": {},
   "source": [
    "# minmax scaler transformed features layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_NB_multiple_genes_feature_minmax((299, 299, 3), n_genes)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,\n",
    "                                            restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = model.fit(train_gen_,\n",
    "                          epochs=100,\n",
    "                          validation_data=valid_gen_,\n",
    "                          callbacks=[callback]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_gen_)\n",
    "from scipy.stats import nbinom\n",
    "y_preds = []\n",
    "if n_genes >1:\n",
    "    for i in range(n_genes):\n",
    "        n = test_predictions[i][:, 0]\n",
    "        p = test_predictions[i][:, 1]\n",
    "        y_pred = nbinom.mean(n, p)\n",
    "        y_preds.append(y_pred)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = np.array(y_preds).transpose()\n",
    "else:\n",
    "    n = test_predictions[:, 0]\n",
    "    p = test_predictions[:, 1]\n",
    "    y_pred = nbinom.mean(n, p)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_ = test_dataset[:,gene_list].copy()\n",
    "test_dataset_.X = test_dataset_.obsm[\"predicted_gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gene_list:\n",
    "    print(i)\n",
    "    gene_plot(Sample1, genes=i, spot_size=8)\n",
    "    gene_plot(test_dataset_, genes=i, spot_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-darwin",
   "metadata": {},
   "source": [
    "# z score transformed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in [\n",
    "    training_dataset,\n",
    "    valid_dataset,\n",
    "    test_dataset\n",
    "]:\n",
    "    st.pp.extract_feature(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_NB_multiple_genes_feature_global(n_genes)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,\n",
    "                                            restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = scaler.fit_transform(training_dataset.obsm[\"X_tile_feature\"])\n",
    "train_Y = training_dataset.to_df()[gene_list]\n",
    "\n",
    "valid_X = scaler.fit_transform(valid_dataset.obsm[\"X_tile_feature\"])\n",
    "valid_Y = valid_dataset.to_df()[gene_list]\n",
    "\n",
    "test_X = scaler.fit_transform(test_dataset.obsm[\"X_tile_feature\"])\n",
    "test_Y = test_dataset.to_df()[gene_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-learning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-building",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_history = model.fit(x=train_X,\n",
    "                          y=train_Y,\n",
    "                          epochs=100,\n",
    "                          validation_data=(valid_X, valid_Y),\n",
    "                          callbacks=[callback]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_X)\n",
    "from scipy.stats import nbinom\n",
    "y_preds = []\n",
    "if n_genes >1:\n",
    "    for i in range(n_genes):\n",
    "        n = test_predictions[i][:, 0]\n",
    "        p = test_predictions[i][:, 1]\n",
    "        y_pred = nbinom.mean(n, p)\n",
    "        y_preds.append(y_pred)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = np.array(y_preds).transpose()\n",
    "else:\n",
    "    n = test_predictions[:, 0]\n",
    "    p = test_predictions[:, 1]\n",
    "    y_pred = nbinom.mean(n, p)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_ = test_dataset[:,gene_list].copy()\n",
    "test_dataset_.X = test_dataset_.obsm[\"predicted_gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gene_list:\n",
    "    print(i)\n",
    "    gene_plot(Sample1, genes=i, spot_size=8)\n",
    "    gene_plot(test_dataset_, genes=i, spot_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-contents",
   "metadata": {},
   "source": [
    "# minmax scaler transformed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-nancy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_NB_multiple_genes_feature_global(n_genes)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,\n",
    "                                            restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = scaler.fit_transform(training_dataset.obsm[\"X_tile_feature\"])\n",
    "train_Y = training_dataset.to_df()[gene_list]\n",
    "\n",
    "valid_X = scaler.fit_transform(valid_dataset.obsm[\"X_tile_feature\"])\n",
    "valid_Y = valid_dataset.to_df()[gene_list]\n",
    "\n",
    "test_X = scaler.fit_transform(test_dataset.obsm[\"X_tile_feature\"])\n",
    "test_Y = test_dataset.to_df()[gene_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-sally",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_history = model.fit(x=train_X,\n",
    "                          y=train_Y,\n",
    "                          epochs=100,\n",
    "                          validation_data=(valid_X, valid_Y),\n",
    "                          callbacks=[callback]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_X)\n",
    "from scipy.stats import nbinom\n",
    "y_preds = []\n",
    "if n_genes >1:\n",
    "    for i in range(n_genes):\n",
    "        n = test_predictions[i][:, 0]\n",
    "        p = test_predictions[i][:, 1]\n",
    "        y_pred = nbinom.mean(n, p)\n",
    "        y_preds.append(y_pred)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = np.array(y_preds).transpose()\n",
    "else:\n",
    "    n = test_predictions[:, 0]\n",
    "    p = test_predictions[:, 1]\n",
    "    y_pred = nbinom.mean(n, p)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_ = test_dataset[:,gene_list].copy()\n",
    "test_dataset_.X = test_dataset_.obsm[\"predicted_gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gene_list:\n",
    "    print(i)\n",
    "    gene_plot(Sample1, genes=i, spot_size=8)\n",
    "    gene_plot(test_dataset_, genes=i, spot_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-developer",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-county",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-executive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-blackberry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-revelation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-asset",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-error",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-plastic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
