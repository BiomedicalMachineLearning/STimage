{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import stlearn as st\n",
    "st.settings.set_figure_params(dpi=300)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sys\n",
    "file = Path(\"../stimage\").resolve()\n",
    "parent= file.parent\n",
    "sys.path.append(str(parent))\n",
    "from PIL import Image\n",
    "from stimage._utils import gene_plot, Read10X, ReadOldST, tiling\n",
    "from stimage._model import CNN_NB_multiple_genes\n",
    "from stimage._data_generator import DataGenerator\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "from PIL import Image, ImageOps, ImageChops, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# Tools for stain normalisation\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from staintools.preprocessing.input_validation import is_uint8_image\n",
    "from staintools import ReinhardColorNormalizer, LuminosityStandardizer, StainNormalizer\n",
    "from staintools.stain_extraction.macenko_stain_extractor import MacenkoStainExtractor\n",
    "from staintools.stain_extraction.vahadane_stain_extractor import VahadaneStainExtractor\n",
    "from staintools.miscellaneous.optical_density_conversion import convert_OD_to_RGB\n",
    "from staintools.miscellaneous.get_concentrations import get_concentrations\n",
    "\n",
    "class LuminosityStandardizerIterative(LuminosityStandardizer):\n",
    "    \"\"\"\n",
    "    Transforms image to a standard brightness\n",
    "    Modifies the luminosity channel such that a fixed percentile is saturated\n",
    "    \n",
    "    Standardiser can fit to source slide image and apply the same luminosity standardisation settings to all tiles generated\n",
    "    from the source slide image\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.p = None\n",
    "\n",
    "    def fit(self, I, percentile = 95):\n",
    "        assert is_uint8_image(I), \"Image should be RGB uint8.\"\n",
    "        I_LAB = cv.cvtColor(I, cv.COLOR_RGB2LAB)\n",
    "        L_float = I_LAB[:, :, 0].astype(float)\n",
    "        self.p = np.percentile(L_float, percentile)\n",
    "\n",
    "    def standardize_tile(self, I):\n",
    "        I_LAB = cv.cvtColor(I, cv.COLOR_RGB2LAB)\n",
    "        L_float = I_LAB[:, :, 0].astype(float)\n",
    "        I_LAB[:, :, 0] = np.clip(255 * L_float / self.p, 0, 255).astype(np.uint8)\n",
    "        I = cv.cvtColor(I_LAB, cv.COLOR_LAB2RGB)\n",
    "        return I\n",
    "\n",
    "class ReinhardColorNormalizerIterative(ReinhardColorNormalizer):\n",
    "    \"\"\"\n",
    "    Normalise each tile from a slide to a target slide using the method of:\n",
    "    E. Reinhard, M. Adhikhmin, B. Gooch, and P. Shirley,\n",
    "    'Color transfer between images'\n",
    "    Normaliser can fit to source slide image and apply the same normalisation settings to all tiles generated from the\n",
    "    source slide image\n",
    "    Attributes\n",
    "    ----------\n",
    "    target_means : tuple float\n",
    "        means pixel value for each channel in target image\n",
    "    target_stds : tuple float\n",
    "        standard deviation of pixel values for each channel in target image\n",
    "    source_means : tuple float\n",
    "        mean pixel value for each channel in source image\n",
    "    source_stds : tuple float\n",
    "        standard deviation of pixel values for each channel in source image\n",
    "    Methods\n",
    "    -------\n",
    "    fit_target(target)\n",
    "        Fit normaliser to target image\n",
    "    fit_source(source)\n",
    "        Fit normaliser to source image\n",
    "    transform(I)\n",
    "        Transform an image to normalise it to the target image\n",
    "    transform_tile(I)\n",
    "        Transform a tile using precomputed parameters that normalise the source slide image to the target slide image\n",
    "    lab_split(I)\n",
    "        Convert from RGB unint8 to LAB and split into channels\n",
    "    merge_back(I1, I2, I3)\n",
    "        Take separate LAB channels and merge back to give RGB uint8\n",
    "    get_mean_std(I)\n",
    "        Get mean and standard deviation of each channel\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.source_means = None\n",
    "        self.source_stds = None\n",
    "\n",
    "    def fit_target(self, target):\n",
    "        \"\"\"Fit to a target image\n",
    "        Parameters\n",
    "        ----------\n",
    "        target : Image RGB uint8\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        means, stds = self.get_mean_std(target)\n",
    "        self.target_means = means\n",
    "        self.target_stds = stds\n",
    "\n",
    "    def fit_source(self, source):\n",
    "        \"\"\"Fit to a source image\n",
    "        Parameters\n",
    "        ----------\n",
    "        source : Image RGB uint8\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        means, stds = self.get_mean_std(source)\n",
    "        self.source_means = means\n",
    "        self.source_stds = stds\n",
    "\n",
    "    def transform_tile(self, I):\n",
    "        \"\"\"Transform a tile using precomputed parameters that normalise the source slide image to the target slide image\n",
    "        Parameters\n",
    "        ----------\n",
    "        I : Image RGB uint8\n",
    "        Returns\n",
    "        -------\n",
    "        transformed_tile : Image RGB uint8\n",
    "        \"\"\"\n",
    "        I1, I2, I3 = self.lab_split(I)\n",
    "        norm1 = ((I1 - self.source_means[0]) * (self.target_stds[0] / self.source_stds[0])) + self.target_means[0]\n",
    "        norm2 = ((I2 - self.source_means[1]) * (self.target_stds[1] / self.source_stds[1])) + self.target_means[1]\n",
    "        norm3 = ((I3 - self.source_means[2]) * (self.target_stds[2] / self.source_stds[2])) + self.target_means[2]\n",
    "        return self.merge_back(norm1, norm2, norm3)\n",
    "\n",
    "class StainNormalizerIterative(StainNormalizer):\n",
    "    \"\"\"Normalise each tile from a slide to a target slide using the Macenko or Vahadane method\n",
    "    \"\"\"\n",
    "    def __init__(self, method):\n",
    "        super().__init__(method)\n",
    "        self.maxC_source = None\n",
    "\n",
    "    def fit_target(self, I):\n",
    "        self.fit(I)\n",
    "\n",
    "    def fit_source(self, I):\n",
    "        self.stain_matrix_source = self.extractor.get_stain_matrix(I)\n",
    "        source_concentrations = get_concentrations(I, self.stain_matrix_source)\n",
    "        self.maxC_source = np.percentile(source_concentrations, 99, axis=0).reshape((1, 2))\n",
    "\n",
    "    def transform_tile(self, I):\n",
    "        source_concentrations = get_concentrations(I, self.stain_matrix_source)\n",
    "        source_concentrations *= (self.maxC_target / self.maxC_source)\n",
    "        tmp = 255 * np.exp(-1 * np.dot(source_concentrations, self.stain_matrix_target))\n",
    "        return tmp.reshape(I.shape).astype(np.uint8)\n",
    "\n",
    "class IterativeNormaliser:\n",
    "    \"\"\"Iterative normalise each tile from a slide to a target using a selectable method\n",
    "    Normalisation methods include: 'none', 'reinhard', 'macenko' and 'vahadane'\n",
    "    Luminosity standardisation is also selectable\n",
    "    \"\"\"\n",
    "    def __init__(self, normalisation_method = 'vahadane', standardise_luminosity = True):\n",
    "        self.method = normalisation_method\n",
    "        self.standardise_luminosity = standardise_luminosity\n",
    "        # Instantiate normaliser and luminosity standardiser\n",
    "        if normalisation_method == 'none':\n",
    "            pass\n",
    "        elif normalisation_method == 'reinhard':\n",
    "            self.normaliser = ReinhardColorNormalizerIterative()\n",
    "        elif normalisation_method == 'macenko' or normalisation_method == 'vahadane':\n",
    "            self.normaliser = StainNormalizerIterative(normalisation_method)\n",
    "        if standardise_luminosity:\n",
    "            self.lum_std = LuminosityStandardizerIterative()\n",
    "\n",
    "    def fit_target(self, target_img):\n",
    "        if self.standardise_luminosity:\n",
    "            self.target_std = self.lum_std.standardize(np.array(target_img))\n",
    "        else:\n",
    "            self.target_std = np.array(target_img)\n",
    "        if self.method != 'none':\n",
    "            self.normaliser.fit_target(self.target_std)\n",
    "\n",
    "    def fit_source(self, source_img):\n",
    "        if self.standardise_luminosity:\n",
    "            self.lum_std.fit(np.array(source_img))\n",
    "            source_std = self.lum_std.standardize_tile(np.array(source_img))\n",
    "        else:\n",
    "            source_std = np.array(source_img)\n",
    "        if self.method != 'none':\n",
    "            self.normaliser.fit_source(source_std)\n",
    "\n",
    "    def transform_tile(self, tile_img):\n",
    "        if self.standardise_luminosity:\n",
    "            tile_std = self.lum_std.standardize_tile(np.array(tile_img))\n",
    "        else:\n",
    "            tile_std = np.array(tile_img)\n",
    "        if self.method != 'none':\n",
    "            tile_norm = self.normaliser.transform_tile(tile_std)\n",
    "        else:\n",
    "            tile_norm = tile_std\n",
    "        return Image.fromarray(tile_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thumbnail(img, size = (1000,1000)):\n",
    "    \"\"\"Converts Pillow images to a different size without modifying the original image\n",
    "    \"\"\"\n",
    "    img_thumbnail = img.copy()\n",
    "    img_thumbnail.thumbnail(size)\n",
    "    return img_thumbnail\n",
    "\n",
    "def scale_img(img, scale_f=10):\n",
    "    return img.resize((img.size[0]//scale_f, img.size[1]//scale_f))\n",
    "\n",
    "def tissue_mask_grabcut(img):\n",
    "    img_cv = img[:, :, ::-1]   #Convert RGB to BGR\n",
    "    mask_initial = (np.array(Image.fromarray(img).convert('L')) <250).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    # Grabcut\n",
    "    bgdModel = np.zeros((1,65),np.float64)\n",
    "    fgdModel = np.zeros((1,65),np.float64)\n",
    "    cv.grabCut(img_cv, mask_initial, None, bgdModel, fgdModel, 5, cv.GC_INIT_WITH_MASK)\n",
    "    mask_final = np.where((mask_initial==2)|(mask_initial==0),0,1).astype('uint8')\n",
    "    \n",
    "    # Generate a rough 'filled in' mask of the tissue\n",
    "    kernal_64 = cv.getStructuringElement(cv.MORPH_ELLIPSE, (64,64))\n",
    "    mask_closed = cv.morphologyEx(mask_final, cv.MORPH_CLOSE, kernal_64)\n",
    "    mask_opened = cv.morphologyEx(mask_closed, cv.MORPH_OPEN, kernal_64)\n",
    "    \n",
    "    # Use rough mask to remove small debris in grabcut mask\n",
    "    mask_cleaned = cv.bitwise_and(mask_final, mask_final, mask = mask_opened)\n",
    "    mask_cleaned_pil = Image.fromarray(mask_cleaned.astype(np.bool))\n",
    "    return mask_cleaned_pil\n",
    "\n",
    "def filter_green(img, g_thresh = 240):\n",
    "    \"\"\"Replaces green pixels greater than threshold with white pixels\n",
    "    \n",
    "    Used to remove background from tissue images\n",
    "    \"\"\"\n",
    "    img = img.convert('RGB')\n",
    "    r, g, b = img.split()\n",
    "    green_mask = (np.array(g) > 240)*255\n",
    "    green_mask_img = Image.fromarray(green_mask.astype(np.uint8), 'L')\n",
    "    white_image = Image.new('RGB', img.size, (255,255,255))\n",
    "    img_filtered = img.copy()\n",
    "    img_filtered.paste(white_image, mask = green_mask_img)\n",
    "    return img_filtered\n",
    "\n",
    "def filter_grays(img, tolerance = 3):\n",
    "    \"\"\"Replaces gray pixels greater than threshold with white pixels\n",
    "    \n",
    "    Used to remove background from tissue images\n",
    "    \"\"\"\n",
    "    img = img.convert('RGB')\n",
    "    r, g, b = img.split()\n",
    "    rg_diff = np.array(ImageChops.difference(r,g)) <= tolerance\n",
    "    rb_diff = np.array(ImageChops.difference(r,b)) <= tolerance\n",
    "    gb_diff = np.array(ImageChops.difference(g,b)) <= tolerance\n",
    "    grays = (rg_diff & rb_diff & gb_diff)*255\n",
    "    grays_mask = Image.fromarray(grays.astype(np.uint8), 'L')\n",
    "    white_image = Image.new('RGB', img.size, (255,255,255))\n",
    "    img_filtered = img.copy()\n",
    "    img_filtered.paste(white_image, mask = grays_mask)\n",
    "    return img_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "from anndata import AnnData\n",
    "from pathlib import Path\n",
    "\n",
    "# Test progress bar\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def tiling(\n",
    "        adata: AnnData,\n",
    "        out_path: Union[Path, str] = \"./tiling\",\n",
    "        library_id: str = None,\n",
    "        crop_size: int = 40,\n",
    "        target_size: int = 299,\n",
    "        stain_normaliser = None,\n",
    "        image_select = \"HE\",\n",
    "        verbose: bool = False,\n",
    "        copy: bool = False,\n",
    "        save_name: str = \"tile_path\",\n",
    ") -> Optional[AnnData]:\n",
    "    \"\"\"\\\n",
    "    Tiling H&E images to small tiles based on spot spatial location\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata\n",
    "        Annotated data matrix.\n",
    "    out_path\n",
    "        Path to save spot image tiles\n",
    "    library_id\n",
    "        Library id stored in AnnData.\n",
    "    crop_size\n",
    "        Size of tiles\n",
    "    verbose\n",
    "        Verbose output\n",
    "    copy\n",
    "        Return a copy instead of writing to adata.\n",
    "    target_size\n",
    "        Input size for convolutional neuron network\n",
    "    Returns\n",
    "    -------\n",
    "    Depending on `copy`, returns or updates `adata` with the following fields.\n",
    "    **tile_path** : `adata.obs` field\n",
    "        Saved path for each spot image tiles\n",
    "    \"\"\"\n",
    "\n",
    "    if library_id is None:\n",
    "        library_id = list(adata.uns[\"spatial\"].keys())[0]\n",
    "\n",
    "    # Check the exist of out_path\n",
    "    if not os.path.isdir(out_path):\n",
    "        os.mkdir(out_path)\n",
    "    if image_select == \"HE\":\n",
    "        image = adata.uns[\"spatial\"][library_id][\"images\"][adata.uns[\"spatial\"][library_id][\"use_quality\"]]\n",
    "    else:\n",
    "        image = image_select\n",
    "    if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    img_pillow = Image.fromarray(image)\n",
    "    \n",
    "    if stain_normaliser:\n",
    "        stain_normaliser.fit_source(scale_img(img_pillow))\n",
    "    tile_names = []\n",
    "\n",
    "    with tqdm(\n",
    "            total=len(adata),\n",
    "            desc=\"Tiling image\",\n",
    "            bar_format=\"{l_bar}{bar} [ time left: {remaining} ]\",\n",
    "    ) as pbar:\n",
    "        for imagerow, imagecol in zip(adata.obs[\"imagerow\"], adata.obs[\"imagecol\"]):\n",
    "            \n",
    "            imagerow_down = imagerow - crop_size / 2\n",
    "            imagerow_up = imagerow + crop_size / 2\n",
    "            imagecol_left = imagecol - crop_size / 2\n",
    "            imagecol_right = imagecol + crop_size / 2\n",
    "            tile = img_pillow.crop(\n",
    "                (imagecol_left, imagerow_down, imagecol_right, imagerow_up)\n",
    "            )\n",
    "            if stain_normaliser:\n",
    "                tile = stain_normaliser.transform_tile(tile)\n",
    "            # tile.thumbnail((target_size, target_size), Image.ANTIALIAS)\n",
    "            tile = tile.resize((target_size, target_size))\n",
    "            tile_name = library_id + \"-\" + str(imagecol) + \"-\" + str(imagerow) + \"-\" + str(crop_size)\n",
    "            out_tile = Path(out_path) / (tile_name + \".jpeg\")\n",
    "            tile_names.append(str(out_tile))\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"generate tile at location ({}, {})\".format(\n",
    "                        str(imagecol), str(imagerow)\n",
    "                    )\n",
    "                )\n",
    "            tile.save(out_tile, \"JPEG\")\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    adata.obs[save_name] = tile_names\n",
    "    return adata if copy else None\n",
    "\n",
    "\n",
    "def calculate_bg(\n",
    "    adata: AnnData,\n",
    "    copy: bool = False,\n",
    ") -> Optional[AnnData]:\n",
    "    tissue_area_list = []\n",
    "    for img_path in adata.obs[\"tile_tissue_mask_path\"]:\n",
    "        tile_mask = plt.imread(img_path, 0)\n",
    "        tissue_area = (tile_mask > 200).sum() / tile_mask.size\n",
    "        tissue_area_list.append(tissue_area)\n",
    "    adata.obs[\"tissue_area\"] = np.array(tissue_area_list)\n",
    "    return adata if copy else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Optional, Union\n",
    "from anndata import AnnData\n",
    "from matplotlib import pyplot as plt\n",
    "# from .utils import get_img_from_fig, checkType\n",
    "\n",
    "\n",
    "def tissue_area_plot(\n",
    "        adata: AnnData,\n",
    "        threshold: float = None,\n",
    "        library_id: str = None,\n",
    "        data_alpha: float = 1.0,\n",
    "        tissue_alpha: float = 1.0,\n",
    "        vmin: float = None,\n",
    "        vmax: float = None,\n",
    "        cmap: str = \"Spectral_r\",\n",
    "        spot_size: Union[float, int] = 6.5,\n",
    "        show_legend: bool = False,\n",
    "        show_color_bar: bool = True,\n",
    "        show_axis: bool = False,\n",
    "        cropped: bool = True,\n",
    "        margin: int = 100,\n",
    "        name: str = None,\n",
    "        output: str = None,\n",
    "        copy: bool = False,\n",
    ") -> Optional[AnnData]:\n",
    "    \n",
    "    colors = adata.obs[\"tissue_area\"]\n",
    "\n",
    "    if threshold is not None:\n",
    "        colors = colors[colors > threshold]\n",
    "\n",
    "    index_filter = colors.index\n",
    "\n",
    "    filter_obs = adata.obs.loc[index_filter]\n",
    "\n",
    "    imagecol = filter_obs[\"imagecol\"]\n",
    "    imagerow = filter_obs[\"imagerow\"]\n",
    "\n",
    "    # Option for turning off showing figure\n",
    "    plt.ioff()\n",
    "\n",
    "    # Initialize matplotlib\n",
    "    fig, a = plt.subplots()\n",
    "    if vmin:\n",
    "        vmin = vmin\n",
    "    else:\n",
    "        vmin = min(colors)\n",
    "    if vmax:\n",
    "        vmax = vmax\n",
    "    else:\n",
    "        vmax = max(colors)\n",
    "    # Plot scatter plot based on pixel of spots\n",
    "    plot = a.scatter(imagecol, imagerow, edgecolor=\"none\", alpha=data_alpha, s=spot_size, marker=\"o\",\n",
    "                     vmin=vmin, vmax=vmax, cmap=plt.get_cmap(cmap), c=colors)\n",
    "    plot.set_clim(vmin=vmin, vmax=vmax)\n",
    "    if show_color_bar:\n",
    "        cb = plt.colorbar(plot, cax=fig.add_axes(\n",
    "            [0.9, 0.3, 0.03, 0.38]), cmap=cmap)\n",
    "        cb.outline.set_visible(False)\n",
    "\n",
    "    if not show_axis:\n",
    "        a.axis('off')\n",
    "\n",
    "    if library_id is None:\n",
    "        library_id = list(adata.uns[\"spatial\"].keys())[0]\n",
    "\n",
    "    image = adata.uns[\"spatial\"][library_id][\"images\"][adata.uns[\"spatial\"][library_id][\"use_quality\"]]\n",
    "    # Overlay the tissue image\n",
    "    a.imshow(image, alpha=tissue_alpha, zorder=-1, )\n",
    "\n",
    "    if cropped:\n",
    "        imagecol = adata.obs[\"imagecol\"]\n",
    "        imagerow = adata.obs[\"imagerow\"]\n",
    "\n",
    "        a.set_xlim(imagecol.min() - margin,\n",
    "                   imagecol.max() + margin)\n",
    "\n",
    "        a.set_ylim(imagerow.min() - margin,\n",
    "                   imagerow.max() + margin)\n",
    "\n",
    "        a.set_ylim(a.get_ylim()[::-1])\n",
    "\n",
    "    if name is None:\n",
    "        name = \"tissue_area_plot\"\n",
    "    if output is not None:\n",
    "        fig.savefig(output + \"/\" + name, dpi=plt.figure().dpi,\n",
    "                    bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(\"/clusterdata/uqxtan9/Xiao/STimage/dataset/breast_cancer_10x_visium\")\n",
    "TILE_PATH = Path(\"/tmp\") / \"tiles\"\n",
    "TILE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAMPLE = \"block1\"\n",
    "Sample1 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\", 0)\n",
    "Sample1.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img\n",
    "\n",
    "SAMPLE = \"block2\"\n",
    "Sample2 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_2_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_2_image.tif\", 0)\n",
    "Sample2.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img\n",
    "\n",
    "SAMPLE = \"FFPE\"\n",
    "Sample3 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"Visium_FFPE_Human_Breast_Cancer_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"Visium_FFPE_Human_Breast_Cancer_image.tif\", 0)\n",
    "Sample3.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list=[\"SLITRK6\", \"PGM5\", \"LINC00645\", \n",
    "           \"TTLL12\", \"COX6C\", \"CPB1\",\n",
    "           \"KRT5\", \"MALAT1\"]\n",
    "gene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_img = Sample1.uns[\"spatial\"][\"block1\"]['images'][\"fulres\"]\n",
    "template_img = Image.fromarray(template_img.astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "template_img = Sample1.uns[\"spatial\"][\"block1\"]['images'][\"fulres\"]\n",
    "template_img = Image.fromarray(template_img.astype(\"uint8\"))\n",
    "\n",
    "normaliser = IterativeNormaliser(normalisation_method = 'vahadane', standardise_luminosity = True)\n",
    "normaliser.fit_target(scale_img(template_img))\n",
    "\n",
    "end = time.time()\n",
    "print(time.strftime('%H:%M:%S', time.gmtime(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-glance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thumbnail(template_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-sunday",
   "metadata": {},
   "source": [
    "# standard tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for adata in [\n",
    "#     Sample1,\n",
    "#     Sample2,\n",
    "    Sample3\n",
    "]:\n",
    "#     count_df = adata.to_df()\n",
    "#     count_df[count_df <=1] = 0\n",
    "#     count_df[count_df >1] = 1\n",
    "#     adata.X = count_df\n",
    "#     adata[:,gene_list]\n",
    "    st.pp.filter_genes(adata,min_cells=3)\n",
    "#     st.pp.normalize_total(adata)\n",
    "    st.pp.log1p(adata)\n",
    "#     st.pp.scale(adata)\n",
    "\n",
    "    # pre-processing for spot image\n",
    "\n",
    "    TILE_PATH_ = TILE_PATH / list(adata.uns[\"spatial\"].keys())[0]\n",
    "    TILE_PATH_.mkdir(parents=True, exist_ok=True)\n",
    "    tiling(adata, TILE_PATH_, crop_size=299)\n",
    "\n",
    "end = time.time()\n",
    "print(time.strftime('%H:%M:%S', time.gmtime(end - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-thickness",
   "metadata": {},
   "source": [
    "# tiling + stain normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample3_stain_norm = Sample3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for adata in [\n",
    "#     Sample1,\n",
    "#     Sample2,\n",
    "    Sample3_stain_norm\n",
    "]:\n",
    "\n",
    "    TILE_PATH_ = TILE_PATH / list(adata.uns[\"spatial\"].keys())[0]\n",
    "    TILE_PATH_.mkdir(parents=True, exist_ok=True)\n",
    "    tiling(adata, TILE_PATH_, crop_size=299, stain_normaliser=normaliser)\n",
    "\n",
    "end = time.time()\n",
    "print(time.strftime('%H:%M:%S', time.gmtime(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-flight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = Image.fromarray(Sample3.uns[\"spatial\"][\"FFPE\"]['images'][\"fulres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img_norm = normaliser.transform_tile(scale_img(target_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img_norm_filtered = filter_green(target_img_norm, g_thresh = 250)\n",
    "target_img_norm_filtered = filter_grays(target_img_norm_filtered, tolerance=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_mask = tissue_mask_grabcut(np.array(target_img_norm_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail(target_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_mask_up_scale = tissue_mask.resize(target_img.size, Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_mask_up_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in [\n",
    "#     Sample1,\n",
    "#     Sample2,\n",
    "    Sample3_stain_norm\n",
    "]:\n",
    "\n",
    "    TILE_PATH_ = TILE_PATH / (list(adata.uns[\"spatial\"].keys())[0] + \"_tissue_mask\")\n",
    "    TILE_PATH_.mkdir(parents=True, exist_ok=True)\n",
    "    tiling(adata, TILE_PATH_, crop_size=299, image_select=np.array(tissue_mask_up_scale), \n",
    "           save_name=\"tile_tissue_mask_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-dutch",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(10,2, figsize=(5, 15))\n",
    "for i in range(10):\n",
    "    norm_tile = plt.imread(Sample3_stain_norm.obs[\"tile_path\"][i], 0)\n",
    "    tile_mask = plt.imread(Sample3_stain_norm.obs[\"tile_tissue_mask_path\"][i], 0)\n",
    "    axarr[i,0].imshow(norm_tile)\n",
    "    axarr[i,1].imshow(tile_mask, cmap=\"gray_r\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_bg(Sample3_stain_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample3_stain_norm.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_area_plot(Sample3_stain_norm, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(Sample3_stain_norm.obs, x=\"tissue_area\")\n",
    "plt.axvline(Sample3_stain_norm.obs[\"tissue_area\"].quantile(0.15), color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-morning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-margin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-combination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-assumption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-coalition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-herald",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
