{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6cb5cc",
   "metadata": {},
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f637e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 18:05:50.745403: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/uqomulay/.conda/envs/Classification_STimage/lib/python3.8/site-packages/cv2/../../lib64:/opt/ohpc/pub/mpi/openmpi3-gnu8/3.1.4/lib:/opt/ohpc/pub/compiler/gcc/8.3.0/lib64\n",
      "2022-07-05 18:05:50.745454: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import anndata\n",
    "import joblib\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing import image as image_fun\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf5122",
   "metadata": {},
   "source": [
    "### ResNet50 and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50128b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing ResNet50 features\n",
    "def ResNet50_features(pre_model, anndata):\n",
    "    resnet_features = []\n",
    "    for imagePath in anndata.obs[\"tile_path\"]:\n",
    "        image = plt.imread(imagePath).astype('float32')\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = preprocess_input(image)\n",
    "        resnet_features.append(pre_model.predict(image, batch_size=1))\n",
    "        \n",
    "    #Shape of resnet50 features is coming out as (no. of tiles, 1, no. of resnet features)\n",
    "    resnet_features = np.asarray(resnet_features)\n",
    "    anndata.obsm[\"resnet50_features\"] = resnet_features.reshape(resnet_features.shape[0],resnet_features.shape[2])    \n",
    "    \n",
    "#Training Pre-Processing\n",
    "def classification_preprocessing(anndata):\n",
    "    gene_exp = anndata.to_df() \n",
    "    gene_exp['library_id'] = anndata.obs['library_id']\n",
    "    gene_exp_zscore = gene_exp.groupby('library_id')[list(gene_exp.iloc[:,:-1].columns)].apply(lambda x: (x-x.mean())/(x.std()))\n",
    "    anndata.obsm[\"true_gene_expression\"] = pd.DataFrame(gene_exp_zscore.apply(lambda x: [0 if y <= 0 else 1 for y in x]),\n",
    "                                                       columns = anndata.to_df().columns, index = anndata.obs.index)\n",
    "\n",
    "\n",
    "#Logistic Regression Classifier\n",
    "def LR_model(train_adata, iteration=10000, penalty_option=\"elasticnet\", regularization_strength=0.1, optimization=\"saga\", l1_l2_ratio=0.5):\n",
    "    model_c = LogisticRegression(max_iter=iteration, penalty=penalty_option, C=regularization_strength,solver=optimization,l1_ratio=l1_l2_ratio)\n",
    "    clf_resnet = MultiOutputClassifier(model_c).fit(train_adata.obsm[\"resnet50_features\"], train_adata.obsm[\"true_gene_expression\"])\n",
    "    joblib.dump(clf_resnet, Path+'pickle/LRmodel.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c15ea29",
   "metadata": {},
   "source": [
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf4ec1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(test_adata, gene_list):\n",
    "    AUROC = []; F1 = []; Precision = []; Recall = []\n",
    "    for i in set(test_adata.obs[\"library_id\"]):\n",
    "        anndata_adata = test_adata[test_adata.obs[\"library_id\"]==i]\n",
    "        for j in gene_list:\n",
    "            score_auroc = roc_auc_score(anndata_adata.obsm[\"predicted_gene_expression\"][j],anndata_adata.obsm[\"true_gene_expression\"][j])\n",
    "            AUROC.append(score_auroc)\n",
    "\n",
    "            score_f1 =  f1_score(anndata_adata.obsm[\"predicted_gene_expression\"][j],anndata_adata.obsm[\"true_gene_expression\"][j])\n",
    "            F1.append(score_f1)\n",
    "\n",
    "            score_precision =  precision_score(anndata_adata.obsm[\"predicted_gene_expression\"][j],anndata_adata.obsm[\"true_gene_expression\"][j])\n",
    "            Precision.append(score_precision)\n",
    "\n",
    "            score_recall =  recall_score(anndata_adata.obsm[\"predicted_gene_expression\"][j],anndata_adata.obsm[\"true_gene_expression\"][j])\n",
    "            Recall.append(score_recall)\n",
    "\n",
    "    Performance_metrics = pd.concat([pd.DataFrame(AUROC), pd.DataFrame(F1), pd.DataFrame(Precision), pd.DataFrame(Recall)])\n",
    "    Performance_metrics['Patient'] = list(np.repeat(list(set(test_adata.obs[\"library_id\"])),len(gene_list)))*4\n",
    "    Performance_metrics['Genes'] = gene_list*len(set(Performance_metrics['Patient']))*4\n",
    "    Performance_metrics['Metrics'] = ['AUROC']*len(AUROC)+['F1']*len(F1)+['Precision']*len(Precision)+['Recall']*len(Recall)\n",
    "\n",
    "    sns.set(font_scale = 2, style=\"whitegrid\",)\n",
    "    plt.figure(figsize=(22.50,12.50))\n",
    "    plt.ylim(-0.1, 1.10)\n",
    "    im = sns.boxplot(x=\"Patient\", y=0, hue=\"Metrics\", data=Performance_metrics,linewidth=3.5,width=0.6)\n",
    "    im.set_xticklabels(im.get_xticklabels(),rotation = 30)\n",
    "    plt.legend(loc=\"lower right\", frameon=True, fontsize=20)\n",
    "    im.axhline(0.5, linewidth=2, color='r')\n",
    "\n",
    "    sns.set(font_scale = 2, style=\"whitegrid\",)\n",
    "    plt.figure(figsize=(22.50,12.50))\n",
    "    plt.ylim(-0.1, 1.10)\n",
    "    im2 = sns.boxplot(x=\"Genes\", y=0, hue=\"Metrics\", data=Performance_metrics,linewidth=3.5,width=0.6)\n",
    "    im2.set_xticklabels(im2.get_xticklabels(),rotation = 30)\n",
    "    plt.legend(loc=\"lower right\", frameon=True, fontsize=20)\n",
    "    im2.axhline(0.5, linewidth=2, color='r')\n",
    "\n",
    "    return im.figure.savefig(Path+'Classification_boxplot_cancer_immune_controls.png'), im2.figure.savefig(Path+'Classification_boxplot_cancer_immune_controls_genes.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7bd0dc",
   "metadata": {},
   "source": [
    "### Cancer vs Non-Cancer Spot Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "453f8b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering followed by Classification\n",
    "def clustering(train_adata):\n",
    "    clustering = AgglomerativeClustering(n_clusters = 2, affinity = 'euclidean', linkage = 'ward')\n",
    "    model_c = LogisticRegression(max_iter=10000,penalty='elasticnet',C=0.1,solver='saga',l1_ratio=0.5)\n",
    "    clf_can_v_non_can = model_c.fit(train_adata.obsm[\"true_gene_expression\"],clustering.fit_predict(train_adata.obsm[\"true_gene_expression\"]))\n",
    "    joblib.dump(clf_can_v_non_can, Path+'pickle/resnet_block1_log_scaled_relu_clustering_logistic.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6442ad03",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84c9c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict_gene(gene):\n",
    "    i = gene_list_2.index(gene)\n",
    "    def combine_model_predict(tile1):\n",
    "        feature1 = resnet_model.predict(tile1)\n",
    "        prediction = clf_resnet.predict_proba(feature1)\n",
    "        return prediction[i]\n",
    "    return combine_model_predict\n",
    "\n",
    "def watershed_segment(image):\n",
    "    annotation_hed = rgb2hed(image)\n",
    "    annotation_h = annotation_hed[:,:,0]\n",
    "    annotation_h *= 255.0 / np.percentile(annotation_h, q=0.01)\n",
    "    thresh = skimage.filters.threshold_otsu(annotation_h)*0.9\n",
    "    im_fgnd_mask = sp.ndimage.morphology.binary_fill_holes(\n",
    "        annotation_h < thresh\n",
    "    )\n",
    "    distance = ndi.distance_transform_edt(im_fgnd_mask)\n",
    "    coords = peak_local_max(distance, footprint=np.ones((5, 5)), labels=im_fgnd_mask)\n",
    "    mask = np.zeros(distance.shape, dtype=bool)\n",
    "    mask[tuple(coords.T)] = True\n",
    "    markers, _ = ndi.label(mask)\n",
    "    labels = watershed(annotation_h, markers, mask=im_fgnd_mask)\n",
    "    im_nuclei_seg_mask = area_opening(labels, area_threshold=64).astype(np.int)\n",
    "    map_dic = dict(zip(np.unique(im_nuclei_seg_mask), np.arange(len(np.unique(im_nuclei_seg_mask)))))\n",
    "    im_nuclei_seg_mask = np.vectorize(map_dic.get)(im_nuclei_seg_mask)\n",
    "    return im_nuclei_seg_mask\n",
    "\n",
    "def LIME_heatmap(image_path, gene):\n",
    "    image = np.asarray(image_fun.load_img(image))\n",
    "    explanation = explainer.explain_instance(image, model_predict_gene(gene), top_labels=2, hide_color=0, num_samples=1000, segmentation_fn=watershed_segment)\n",
    "    temp, mask = explanation.get_image_and_mask(1, positive_only=False, num_features=10000, hide_rest=True)\n",
    "    dict_heatmap = dict(explanation.local_exp[1])\n",
    "    heatmap = np.vectorize(dict_heatmap.get)(explanation.segments)\n",
    "    return mask, heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c215d567",
   "metadata": {},
   "source": [
    "### User Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d884cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 18:06:19.455170: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/uqomulay/.conda/envs/Classification_STimage/lib/python3.8/site-packages/cv2/../../lib64:/opt/ohpc/pub/mpi/openmpi3-gnu8/3.1.4/lib:/opt/ohpc/pub/compiler/gcc/8.3.0/lib64\n",
      "2022-07-05 18:06:19.455231: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-05 18:06:19.455262: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (delta089): /proc/driver/nvidia/version does not exist\n",
      "2022-07-05 18:06:19.455556: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "Path = \"/home/uqomulay/90days/STimage_outputs/\"\n",
    "all_data = anndata.read_h5ad(Path+\"all_adata.h5ad\")\n",
    "gene_list = ['CD74', 'CD24', 'CD63', 'CD81', 'CD151', \n",
    "             'COX6C', 'TP53', 'PABPC1', 'GNAS', 'B2M', 'SPARC', 'HSP90AB1', 'TFF3', 'ATP1A1', 'FASN',\n",
    "             'CCSER2', 'SYMPK', 'ANKRD17','PUM1']\n",
    "all_data = all_data[:,gene_list]\n",
    "all_data.obs[\"tile_path\"] = Path+\"tiles/tiles/\"+all_data.obs[\"tile_path\"].str.split('/', expand=True)[6]\n",
    "model = ResNet50(weights='imagenet', pooling=\"avg\", include_top = False)\n",
    "\n",
    "\n",
    "iteration = 10000\n",
    "penalty_option = 'elasticnet'\n",
    "regularization_strength = 0.1\n",
    "optimization = 'saga'\n",
    "l1_l2_ratio = 0.5\n",
    "\n",
    "train_data_library_id = [\"block1\"]#,\"1142243F\",\"CID4290\",\"CID4465\",\"CID44971\",\"CID4535\",\"block2\"\n",
    "train_adata = all_data[all_data.obs[\"library_id\"].isin([\"block1\"])]\n",
    "test_adata = all_data[all_data.obs[\"library_id\"].isin([\"block2\",\"FFPE\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e1f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_features(model, train_adata)\n",
    "ResNet50_features(model, test_adata)\n",
    "print(\"Done-1\")\n",
    "\n",
    "classification_preprocessing(train_adata)\n",
    "classification_preprocessing(test_adata)\n",
    "print(\"Done-2\")\n",
    "\n",
    "LR_model(train_adata)\n",
    "print(\"Done-3\")\n",
    "\n",
    "clf_resnet = joblib.load(Path+'pickle/LRmodel.pkl')\n",
    "test_adata.obsm[\"predicted_gene_expression\"] = pd.DataFrame(clf_resnet.predict(test_adata.obsm[\"resnet50_features\"]),columns=test_adata.to_df().columns,index=test_adata.obs.index)\n",
    "print(\"Done-4\")\n",
    "\n",
    "performance_metrics(test_adata)\n",
    "\n",
    "clustering(train_adata)\n",
    "clf_can_v_non_can = joblib.load(Path+'pickle/resnet_block1_log_scaled_relu_clustering_logistic.pkl')\n",
    "can_v_non_can_spot = pd.DataFrame(clf_can_v_non_can.predict(test_adata.obsm[\"predicted_gene_expression\"]),index=test_adata.obs.index)\n",
    "test_adata.obsm[\"clusters_can_v_non_can\"] = can_v_non_can_spot\n",
    "print(\"Done-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f280ee7",
   "metadata": {},
   "source": [
    "### Performance Evaluation with exceptional handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f871022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot of Performance Metrics\n",
    "def performance_metrics_exceptional(Path, gene_exp_binary_all_true, performance_metrics_all_predictions, gene_list):\n",
    "    AUROC_genes = []; F1_genes = []; Precision_genes = []; Recall_genes = [];\n",
    "    for dataset in range(len(gene_exp_binary_all_true)):\n",
    "        for gene in range(len(gene_list)):\n",
    "            try:\n",
    "                score =  roc_auc_score(performance_metrics_all_predictions[dataset].iloc[:,gene],gene_exp_binary_all_true[dataset].iloc[:,gene])\n",
    "                AUROC_genes.append(score)\n",
    "            except:\n",
    "                AUROC_genes.append(score)\n",
    "\n",
    "    for dataset in range(len(gene_exp_binary_all_true)):\n",
    "        for gene in range(len(gene_list)):\n",
    "            try:\n",
    "                score =  f1_score(performance_metrics_all_predictions[dataset].iloc[:,gene],gene_exp_binary_all_true[dataset].iloc[:,gene])\n",
    "                F1_genes.append(score)\n",
    "            except:\n",
    "                F1_genes.append(score)\n",
    "\n",
    "    for dataset in range(len(gene_exp_binary_all_true)):\n",
    "        for gene in range(len(gene_list)):\n",
    "            try:\n",
    "                score =  precision_score(performance_metrics_all_predictions[dataset].iloc[:,gene],gene_exp_binary_all_true[dataset].iloc[:,gene])\n",
    "                Precision_genes.append(score)\n",
    "            except:\n",
    "                Precision_genes.append(score)\n",
    "\n",
    "    for dataset in range(len(gene_exp_binary_all_true)):\n",
    "        for gene in range(len(gene_list)):\n",
    "            try:\n",
    "                score =  recall_score(performance_metrics_all_predictions[dataset].iloc[:,gene],gene_exp_binary_all_true[dataset].iloc[:,gene])\n",
    "                Recall_genes.append(score)\n",
    "            except:\n",
    "                Recall_genes.append(score)\n",
    "\n",
    "    AUROC_genes = pd.DataFrame(AUROC_genes); F1_genes = pd.DataFrame(F1_genes); Precision_genes = pd.DataFrame(Precision_genes); Recall_genes = pd.DataFrame(Recall_genes)\n",
    "    Performance_metrics = pd.concat([AUROC_genes,F1_genes,Precision_genes,Recall_genes])\n",
    "    Performance_metrics['patient'] = list(np.repeat(pd.concat(gene_exp_binary_all_true).loc[~(pd.concat(gene_exp_binary_all_true)['dataset'].isin(train_data_library_id))].drop_duplicates('dataset', keep='first')['dataset'].to_list(),len(gene_list)))*4\n",
    "    Performance_metrics['genes'] = gene_list*len(set(Performance_metrics['patient']))*4\n",
    "    Performance_metrics['measure'] = ['AUROC']*len(AUROC_genes)+['F1']*len(F1_genes)+['Precision']*len(Precision_genes)+['Recall']*len(Recall_genes)\n",
    "\n",
    "    plt.figure(figsize=(19.20,10.80))\n",
    "    im = sns.boxplot(x=\"patient\", y=0, hue=\"measure\", data=Performance_metrics,linewidth=4)\n",
    "    im.axhline(0.5, linewidth=2, color='r')\n",
    "    return im.figure.savefig(Path+'Classification_boxplot.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
