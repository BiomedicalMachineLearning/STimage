{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import stlearn as st\n",
    "st.settings.set_figure_params(dpi=300)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sys\n",
    "file = Path(\"../stimage\").resolve()\n",
    "parent= file.parent\n",
    "sys.path.append(str(parent))\n",
    "from PIL import Image\n",
    "from stimage._utils import gene_plot, Read10X, ReadOldST, tiling\n",
    "from stimage._model import CNN_NB_multiple_genes, negative_binomial_layer, negative_binomial_loss\n",
    "from stimage._data_generator import DataGenerator, DataGenerator_LSTM_one_output, DataGenerator_LSTM_multi_output\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from libpysal.weights.contiguity import Queen\n",
    "from libpysal import examples\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import splot\n",
    "from splot.esda import moran_scatterplot, lisa_cluster\n",
    "from esda.moran import Moran, Moran_Local\n",
    "from esda.moran import Moran_BV, Moran_Local_BV\n",
    "from splot.esda import plot_moran_bv_simulation, plot_moran_bv, plot_local_autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anndata import AnnData\n",
    "from typing import Iterable, Union, Optional\n",
    "import pandas as pd\n",
    "def spatial_autocorr(adata_true: AnnData,\n",
    "                     adata_pred: AnnData,\n",
    "                     model_name: str,\n",
    "                     p: float = 0.05,\n",
    "                     save_plots: str = None,\n",
    ") -> Optional[AnnData]:\n",
    "    \n",
    "    assert len(adata_true.var_names) == len(adata_pred.var_names)\n",
    "    \n",
    "    gpd_name = \"gpd_{}\".format(model_name)\n",
    "    library_id = list(adata_true.uns[\"spatial\"].keys())[0]\n",
    "    tissue_image = adata_true.uns[\"spatial\"][library_id][\"images\"][\"fulres\"]\n",
    "    \n",
    "    adata_true.obsm[gpd_name] = gpd.GeoDataFrame(adata_true.obs,\n",
    "                                                 geometry=gpd.points_from_xy(\n",
    "                                                          adata_true.obs.imagecol, \n",
    "                                                          adata_true.obs.imagerow))\n",
    "    w = Queen.from_dataframe(adata_true.obsm[gpd_name])\n",
    "    \n",
    "    spatial_autocorr_label = []\n",
    "    moran_i = []\n",
    "    n_sigs = []\n",
    "    for gene in adata_true.var_names:\n",
    "        x = np.array(adata_true.to_df()[gene].values, dtype='float')\n",
    "        y = np.array(adata_pred.to_df()[gene].values, dtype='float')\n",
    "        \n",
    "        adata_true.obsm[gpd_name][\"gc_{}\".format(gene)] = x\n",
    "        adata_true.obsm[gpd_name][\"pred_{}\".format(gene)] = y\n",
    "        \n",
    "#         moran = Moran(x,w)\n",
    "        moran_bv = Moran_BV(y, x, w)\n",
    "#         moran_loc = Moran_Local(x, w)\n",
    "        moran_loc_bv = Moran_Local_BV(y, x, w)\n",
    "        \n",
    "        labels, n_sig = hot_cold_label(moran_loc_bv, p)\n",
    "        spatial_autocorr_label.append(labels)\n",
    "        moran_i.append(moran_bv.I)\n",
    "        n_sigs.append(n_sig)\n",
    "        \n",
    "        if save_plots:\n",
    "            lisa_cluster(moran_loc_bv, adata_true.obsm[gpd_name], p=0.05, \n",
    "                         figsize = (9,9), markersize=12,)# **{\"alpha\":1})\n",
    "            plt.imshow(tissue_image)\n",
    "            plt.savefig(save_plots / \"lisa_cluster_{}\".format(gene))\n",
    "            \n",
    "        adata_true.obsm[gpd_name].drop([\"gc_{}\".format(gene),\n",
    "                                        \"pred_{}\".format(gene)], inplace=True, axis=1)\n",
    "    \n",
    "    adata_true.obsm[\"spatial_autocorr_{}\".format(model_name)] = np.array(spatial_autocorr_label).transpose()\n",
    "    adata_true.var[\"moran_i_{}\".format(model_name)] = moran_i\n",
    "    adata_true.var[\"n_sigs_{}\".format(model_name)] = n_sigs\n",
    "    \n",
    "    return adata_true.copy()\n",
    "\n",
    "\n",
    "def hot_cold_label(moran_loc, p):\n",
    "    cluster = moran_hot_cold_spots(moran_loc, p)\n",
    "    cluster_labels = ['ns', 'HH', 'LH', 'LL', 'HL']\n",
    "    labels = [cluster_labels[i] for i in cluster]\n",
    "    n_sig = labels.count('HH') + labels.count('LL')\n",
    "    return labels, n_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches, colors\n",
    "def lisa_cluster(moran_loc, gdf, p=0.05, ax=None,\n",
    "                 legend=True, legend_kwds=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Create a LISA Cluster map\n",
    "    Parameters\n",
    "    ----------\n",
    "    moran_loc : esda.moran.Moran_Local or Moran_Local_BV instance\n",
    "        Values of Moran's Local Autocorrelation Statistic\n",
    "    gdf : geopandas dataframe instance\n",
    "        The Dataframe containing information to plot. Note that `gdf` will be\n",
    "        modified, so calling functions should use a copy of the user\n",
    "        provided `gdf`. (either using gdf.assign() or gdf.copy())\n",
    "    p : float, optional\n",
    "        The p-value threshold for significance. Points will\n",
    "        be colored by significance.\n",
    "    ax : matplotlib Axes instance, optional\n",
    "        Axes in which to plot the figure in multiple Axes layout.\n",
    "        Default = None\n",
    "    legend : boolean, optional\n",
    "        If True, legend for maps will be depicted. Default = True\n",
    "    legend_kwds : dict, optional\n",
    "        Dictionary to control legend formatting options. Example:\n",
    "        ``legend_kwds={'loc': 'upper left', 'bbox_to_anchor': (0.92, 1.05)}``\n",
    "        Default = None\n",
    "    **kwargs : keyword arguments, optional\n",
    "        Keywords designing and passed to geopandas.GeoDataFrame.plot().\n",
    "    Returns\n",
    "    -------\n",
    "    fig : matplotlip Figure instance\n",
    "        Figure of LISA cluster map\n",
    "    ax : matplotlib Axes instance\n",
    "        Axes in which the figure is plotted\n",
    "    Examples\n",
    "    --------\n",
    "    Imports\n",
    "    \n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> from libpysal.weights.contiguity import Queen\n",
    "    >>> from libpysal import examples\n",
    "    >>> import geopandas as gpd\n",
    "    >>> from esda.moran import Moran_Local\n",
    "    >>> from splot.esda import lisa_cluster\n",
    "    Data preparation and statistical analysis\n",
    "    \n",
    "    >>> guerry = examples.load_example('Guerry')\n",
    "    >>> link_to_data = guerry.get_path('guerry.shp')\n",
    "    >>> gdf = gpd.read_file(link_to_data)\n",
    "    >>> y = gdf['Donatns'].values\n",
    "    >>> w = Queen.from_dataframe(gdf)\n",
    "    >>> w.transform = 'r'\n",
    "    >>> moran_loc = Moran_Local(y, w)\n",
    "    Plotting\n",
    "    \n",
    "    >>> fig = lisa_cluster(moran_loc, gdf)\n",
    "    >>> plt.show()\n",
    "    \n",
    "    \"\"\"\n",
    "    # retrieve colors5 and labels from mask_local_auto\n",
    "    _, colors5, _, labels = mask_local_auto(moran_loc, p=p)\n",
    "\n",
    "    # define ListedColormap\n",
    "    hmap = colors.ListedColormap(colors5)\n",
    "\n",
    "    if ax is None:\n",
    "        figsize = kwargs.pop('figsize', None)\n",
    "        fig, ax = plt.subplots(1, figsize=figsize)\n",
    "    else:\n",
    "        fig = ax.get_figure()\n",
    "\n",
    "    gdf.assign(cl=labels).plot(column='cl', categorical=True,\n",
    "                               k=2, cmap=hmap, linewidth=0.1, ax=ax,\n",
    "                               edgecolor='white', legend=legend,\n",
    "                               legend_kwds=legend_kwds, **kwargs)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_aspect('equal')\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def mask_local_auto(moran_loc, p=0.5):\n",
    "    '''\n",
    "    Create Mask for coloration and labeling of local spatial autocorrelation\n",
    "    Parameters\n",
    "    ----------\n",
    "    moran_loc : esda.moran.Moran_Local instance\n",
    "        values of Moran's I Global Autocorrelation Statistic\n",
    "    p : float\n",
    "        The p-value threshold for significance. Points will\n",
    "        be colored by significance.\n",
    "    Returns\n",
    "    -------\n",
    "    cluster_labels : list of str\n",
    "        List of labels - ['ns', 'HH', 'LH', 'LL', 'HL']\n",
    "    colors5 : list of str\n",
    "        List of colours - ['#d7191c', '#fdae61', '#abd9e9',\n",
    "        '#2c7bb6', 'lightgrey']\n",
    "    colors : array of str\n",
    "        Array containing coloration for each input value/ shape.\n",
    "    labels : list of str\n",
    "        List of label for each attribute value/ polygon.\n",
    "    '''\n",
    "    # create a mask for local spatial autocorrelation\n",
    "    cluster = moran_hot_cold_spots(moran_loc, p)\n",
    "\n",
    "    cluster_labels = ['ns', 'HH', 'LH', 'LL', 'HL']\n",
    "    labels = [cluster_labels[i] for i in cluster]\n",
    "\n",
    "    colors5 = {0: '#ffffff00',\n",
    "               1: '#d7191cff',\n",
    "               2: '#abd9e9ff',\n",
    "               3: '#2c7bb6ff',\n",
    "               4: '#fdae61ff'}\n",
    "    colors = [colors5[i] for i in cluster]  # for Bokeh\n",
    "    # for MPL, keeps colors even if clusters are missing:\n",
    "    x = np.array(labels)\n",
    "    y = np.unique(x)\n",
    "    colors5_mpl = {'HH': '#d7191cff',\n",
    "                   'LH': '#abd9e9ff',\n",
    "                   'LL': '#2c7bb6ff',\n",
    "                   'HL': '#fdae61ff',\n",
    "                   'ns': '#ffffff00'}\n",
    "    colors5 = [colors5_mpl[i] for i in y]  # for mpl\n",
    "\n",
    "    # HACK need this, because MPL sorts these labels while Bokeh does not\n",
    "    cluster_labels.sort()\n",
    "    return cluster_labels, colors5, colors, labels\n",
    "\n",
    "\n",
    "def moran_hot_cold_spots(moran_loc, p=0.05):\n",
    "    sig = 1 * (moran_loc.p_sim < p)\n",
    "    HH = 1 * (sig * moran_loc.q == 1)\n",
    "    LL = 3 * (sig * moran_loc.q == 3)\n",
    "    LH = 2 * (sig * moran_loc.q == 2)\n",
    "    HL = 4 * (sig * moran_loc.q == 4)\n",
    "    cluster = HH + LL + LH + HL\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anndata import AnnData\n",
    "from typing import Iterable, Union, Optional\n",
    "import pandas as pd\n",
    "def enrich_group(adata: AnnData,\n",
    "                 gene_list: Iterable,\n",
    "                 enrich_name: Union[pd.Index, list],               \n",
    ") -> Optional[AnnData]:\n",
    "    \n",
    "    adata_ = adata[:,adata.var_names.isin(gene_list)].copy()\n",
    "    adata_enrich = AnnData(X=adata_.X.sum(axis=1),\n",
    "                       obs=adata_.obs,\n",
    "                       uns=adata_.uns,\n",
    "                       obsm=adata_.obsm)\n",
    "    adata_enrich.var_names = enrich_name\n",
    "    return adata_enrich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def plot_correlation(df, attr_1, attr_2):\n",
    "    r = stats.pearsonr(df[attr_1], \n",
    "                       df[attr_2])[0] **2\n",
    "\n",
    "    g = sns.lmplot(data=df,\n",
    "        x=attr_1, y=attr_2,\n",
    "        height=5, legend=True\n",
    "    )\n",
    "    # g.set(ylim=(0, 360), xlim=(0,360))\n",
    "\n",
    "    g.set_axis_labels(attr_1, attr_2)\n",
    "    plt.annotate(r'$R^2:{0:.2f}$'.format(r),\n",
    "                (max(df[attr_1])*0.9, max(df[attr_2])*0.9))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(\"/clusterdata/uqxtan9/Xiao/STimage/dataset/breast_cancer_10x_visium\")\n",
    "TILE_PATH = Path(\"/tmp\") / \"tiles\"\n",
    "TILE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAMPLE = \"block1\"\n",
    "Sample1 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\", 0)\n",
    "Sample1.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img\n",
    "\n",
    "SAMPLE = \"block2\"\n",
    "Sample2 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_2_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_2_image.tif\", 0)\n",
    "Sample2.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list=[\"SLITRK6\", \"PGM5\", \"LINC00645\", \n",
    "           \"TTLL12\", \"COX6C\", \"CPB1\",\n",
    "           \"KRT5\", \"MALAT1\"]\n",
    "gene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in [\n",
    "    Sample1,\n",
    "    Sample2,\n",
    "]:\n",
    "#     count_df = adata.to_df()\n",
    "#     count_df[count_df <=1] = 0\n",
    "#     count_df[count_df >1] = 1\n",
    "#     adata.X = count_df\n",
    "#     adata[:,gene_list]\n",
    "    st.pp.filter_genes(adata,min_cells=3)\n",
    "#     st.pp.normalize_total(adata)\n",
    "    st.pp.log1p(adata)\n",
    "#     st.pp.scale(adata)\n",
    "\n",
    "    # pre-processing for spot image\n",
    "    TILE_PATH_ = TILE_PATH / list(adata.uns[\"spatial\"].keys())[0]\n",
    "    TILE_PATH_.mkdir(parents=True, exist_ok=True)\n",
    "    tiling(adata, TILE_PATH_, crop_size=299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = len(gene_list)\n",
    "# training_index = Sample1.obs.sample(frac=0.9, random_state=1).index\n",
    "# training_dataset = Sample1[training_index,].copy()\n",
    "\n",
    "# valid_index = Sample1.obs.index.isin(training_index)\n",
    "# valid_dataset = Sample1[~valid_index,].copy()\n",
    "\n",
    "training_dataset = Sample1.copy()\n",
    "\n",
    "valid_index = Sample1.obs.sample(frac=0.3, random_state=1).index\n",
    "valid_dataset = Sample1[valid_index,].copy()\n",
    "\n",
    "test_dataset = Sample2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-diesel",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_LSTM_one_output(adata=training_dataset, \n",
    "                          genes=gene_list, aug=False),\n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([7,299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "train_gen_ = train_gen.shuffle(buffer_size=100).batch(8).repeat(1).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_LSTM_one_output(adata=valid_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([7,299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "valid_gen_ = valid_gen.shuffle(buffer_size=100).batch(8).repeat(1).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_LSTM_one_output(adata=test_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([7,299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "test_gen_ = test_gen.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout, Lambda, TimeDistributed, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def CNN_LSTM_NB_multiple_genes(steps_tile_shape, n_genes):\n",
    "    tile_input = Input(shape=steps_tile_shape, name=\"steps_tile_input\")\n",
    "    resnet_base = ResNet50(input_shape=steps_tile_shape[1:], weights='imagenet', include_top=False)\n",
    "    #     stage_5_start = resnet_base.get_layer(\"conv5_block1_1_conv\")\n",
    "    #     for i in range(resnet_base.layers.index(stage_5_start)):\n",
    "    #         resnet_base.layers[i].trainable = False\n",
    "\n",
    "#     for i in resnet_base.layers:\n",
    "#         i.trainable = False\n",
    "    cnn_out = resnet_base.output\n",
    "    cnn_out = GlobalAveragePooling2D()(cnn_out)\n",
    "    cnn = Model(inputs=resnet_base.input, outputs=cnn_out)\n",
    "    #     cnn = Dropout(0.5)(cnn)\n",
    "    #     cnn = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.01),\n",
    "    #                 activity_regularizer=tf.keras.regularizers.l2(0.01))(cnn)\n",
    "    # cnn = Dense(256, activation='relu')(cnn)\n",
    "    encoded_frames = TimeDistributed(cnn)(tile_input)\n",
    "    encoded_sequence = LSTM(256)(encoded_frames)\n",
    "    output_layers = []\n",
    "    for i in range(n_genes):\n",
    "        output = Dense(2)(encoded_sequence)\n",
    "        output_layers.append(Lambda(negative_binomial_layer, name=\"gene_{}\".format(i))(output))\n",
    "\n",
    "    model = Model(inputs=[tile_input], outputs=output_layers)\n",
    "    #     losses={}\n",
    "    #     for i in range(8):\n",
    "    #         losses[\"gene_{}\".format(i)] = negative_binomial_loss(i)\n",
    "    #     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "    model.compile(loss=negative_binomial_loss,\n",
    "                  optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_LSTM_NB_multiple_genes((7, 299, 299, 3), n_genes)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,\n",
    "                                            restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./LSTM_CNN_ft.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_gen_)\n",
    "from scipy.stats import nbinom\n",
    "y_preds = []\n",
    "if n_genes >1:\n",
    "    for i in range(n_genes):\n",
    "        n = test_predictions[i][:, 0]\n",
    "        p = test_predictions[i][:, 1]\n",
    "        y_pred = nbinom.mean(n, p)\n",
    "        y_preds.append(y_pred)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = np.array(y_preds).transpose()\n",
    "else:\n",
    "    n = test_predictions[:, 0]\n",
    "    p = test_predictions[:, 1]\n",
    "    y_pred = nbinom.mean(n, p)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = test_dataset[:,gene_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_lstm = test_final.copy()\n",
    "test_dataset_lstm.X = test_dataset.obsm[\"predicted_gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in gene_list:\n",
    "#     print(i)\n",
    "#     gene_plot(test_dataset_lstm, genes=i, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in gene_list:\n",
    "#     print(i)\n",
    "#     gene_plot(test_final, genes=i, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-baltimore",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# OUTPUT_PATH = Path(\"./lstm_one_plot\")\n",
    "# OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "# final_adata = spatial_autocorr(test_final, test_dataset_lstm, \"lstm_one\", save_plots=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from stimage._imgaug import seq_aug\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "class DataGenerator_LSTM_multi_output(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    def __init__(self, adata, dim=(299, 299), n_channels=3, genes=None, aug=False, tile_path=\"tile_path\"):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.adata = adata\n",
    "        self.n_channels = n_channels\n",
    "        self.genes = genes\n",
    "        self.num_genes = len(genes)\n",
    "        self.aug = aug\n",
    "        self.tile_path = tile_path\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(self.adata.n_obs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Find list of IDs\n",
    "        obs_temp = self.adata.obs_names[index]\n",
    "        \n",
    "        # Generate neighbour data\n",
    "        candidates = self.adata.obs[['imagecol', 'imagerow']]\n",
    "        quary_spots = np.array(candidates.loc[obs_temp,:]).reshape(1, -1)\n",
    "        nearest_index = self.get_nearest_index(quary_spots, candidates, k_nn=7, leaf_size=self.adata.n_obs//2)\n",
    "        np.random.shuffle(nearest_index.flat)\n",
    "        obs_temp_neighbour = self.adata.obs_names[nearest_index.ravel()]\n",
    "        \n",
    "        # Generate data\n",
    "        X_img_final = self._load_neighbour(self._load_img, obs_temp, obs_temp_neighbour)\n",
    "        y_final = self._load_neighbour(self._load_label, obs_temp, obs_temp_neighbour)\n",
    "        \n",
    "\n",
    "        return X_img_final, y_final\n",
    "    \n",
    "    def _load_neighbour(self, fn, obs_temp, obs_temp_neighbour):\n",
    "        obs_data = fn(obs_temp)\n",
    "        obs_neighbour = np.stack([fn(x) for x in obs_temp_neighbour], axis=0)\n",
    "        obs_data = np.expand_dims(obs_data, axis=0)\n",
    "        obs_data_final = np.concatenate([obs_neighbour, obs_data], axis=0)\n",
    "        return obs_data_final\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.adata.n_obs)\n",
    "\n",
    "    def _load_img(self, obs):\n",
    "        img_path = self.adata.obs.loc[obs, self.tile_path]\n",
    "        X_img = image.load_img(img_path, target_size=self.dim)\n",
    "        X_img = image.img_to_array(X_img).astype('uint8')\n",
    "        #         X_img = np.expand_dims(X_img, axis=0)\n",
    "        #         n_rotate = np.random.randint(0, 4)\n",
    "        #         X_img = np.rot90(X_img, k=n_rotate, axes=(1, 2))\n",
    "        if self.aug:\n",
    "            X_img = seq_aug(image=X_img)\n",
    "#         X_img = preprocess_resnet(X_img)\n",
    "#         X_img = np.expand_dims(X_img, axis=0)\n",
    "        return X_img\n",
    "\n",
    "    def _load_label(self, obs):\n",
    "        batch_adata = self.adata[obs, self.genes].copy()\n",
    "\n",
    "        return np.array([batch_adata.to_df()[i].values for i in self.genes])\n",
    "\n",
    "    def get_classes(self):\n",
    "        return self.adata.to_df().loc[:, self.genes]\n",
    "    \n",
    "    def get_nearest_index(self, quary_spots, candidates, k_nn, leaf_size):\n",
    "        tree = KDTree(candidates, leaf_size=leaf_size)\n",
    "        _, indices = tree.query(quary_spots, k=k_nn)\n",
    "        return indices.ravel()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-forest",
   "metadata": {},
   "source": [
    "# LSTM multiple output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_LSTM_multi_output(adata=training_dataset, \n",
    "                          genes=gene_list, aug=False),\n",
    "            output_types=(tf.float32, tf.float32), \n",
    "            output_shapes=([7,299,299,3], [7,8,1])\n",
    ")\n",
    "train_gen_ = train_gen.shuffle(buffer_size=100).batch(8).repeat(1).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_LSTM_multi_output(adata=valid_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tf.float32), \n",
    "            output_shapes=([7,299,299,3], [7,8,1])\n",
    ")\n",
    "valid_gen_ = valid_gen.shuffle(buffer_size=100).batch(8).repeat(1).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_LSTM_multi_output(adata=test_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tf.float32), \n",
    "            output_shapes=([7,299,299,3], [7,8,1])\n",
    ")\n",
    "test_gen_ = test_gen.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data(inputs, outputs):\n",
    "    return inputs, [tuple(i for i in outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = train_gen.map(tf.py_function(map_data, (tf.float32, tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in train_gen.shuffle(10).take(1):\n",
    "    print(a.dtype)\n",
    "    print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "c= DataGenerator_LSTM_multi_output(adata=training_dataset, \n",
    "                          genes=gene_list, aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in c:\n",
    "    print(a.dtype)\n",
    "    print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout, Lambda, TimeDistributed, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def CNN_LSTM_NB_multiple_output_genes(steps_tile_shape, n_genes):\n",
    "    tile_input = Input(shape=steps_tile_shape, name=\"steps_tile_input\")\n",
    "    resnet_base = ResNet50(input_shape=steps_tile_shape[1:], weights='imagenet', include_top=False)\n",
    "    #     stage_5_start = resnet_base.get_layer(\"conv5_block1_1_conv\")\n",
    "    #     for i in range(resnet_base.layers.index(stage_5_start)):\n",
    "    #         resnet_base.layers[i].trainable = False\n",
    "\n",
    "#     for i in resnet_base.layers:\n",
    "#         i.trainable = False\n",
    "    cnn_out = resnet_base.output\n",
    "    cnn_out = GlobalAveragePooling2D()(cnn_out)\n",
    "    cnn = Model(inputs=resnet_base.input, outputs=cnn_out)\n",
    "    #     cnn = Dropout(0.5)(cnn)\n",
    "    #     cnn = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.01),\n",
    "    #                 activity_regularizer=tf.keras.regularizers.l2(0.01))(cnn)\n",
    "    # cnn = Dense(256, activation='relu')(cnn)\n",
    "    encoded_frames = TimeDistributed(cnn)(tile_input)\n",
    "    encoded_sequence = LSTM(256, return_sequences=True)(encoded_frames)\n",
    "    output_layers = []\n",
    "    for i in range(n_genes):\n",
    "        output = Dense(2)(encoded_sequence)\n",
    "        output_layers.append(Lambda(negative_binomial_layer, name=\"gene_{}\".format(i))(output))\n",
    "\n",
    "    model = Model(inputs=[tile_input], outputs=output_layers)\n",
    "    #     losses={}\n",
    "    #     for i in range(8):\n",
    "    #         losses[\"gene_{}\".format(i)] = negative_binomial_loss(i)\n",
    "    #     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "    model.compile(loss=negative_binomial_loss,\n",
    "                  optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_LSTM_NB_multiple_output_genes((7, 299, 299, 3), n_genes)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,\n",
    "                                            restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = model.fit(train_gen_,\n",
    "                          epochs=5,\n",
    "                          validation_data=valid_gen_,\n",
    "                          callbacks=[callback]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = model.predict(test_gen_)\n",
    "from scipy.stats import nbinom\n",
    "y_preds = []\n",
    "if n_genes >1:\n",
    "    for i in range(n_genes):\n",
    "        n = test_predictions[i][:, -1, 0]\n",
    "        p = test_predictions[i][:, -1, 1]\n",
    "        y_pred = nbinom.mean(n, p)\n",
    "        y_preds.append(y_pred)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = np.array(y_preds).transpose()\n",
    "else:\n",
    "    n = test_predictions[:, 0]\n",
    "    p = test_predictions[:, 1]\n",
    "    y_pred = nbinom.mean(n, p)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_lstm_m = test_final.copy()\n",
    "test_dataset_lstm_m.X = test_dataset.obsm[\"predicted_gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-roads",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in gene_list:\n",
    "    print(i)\n",
    "    gene_plot(test_dataset_lstm_m, genes=i, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-summer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-rolling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "referenced-broadway",
   "metadata": {},
   "source": [
    "# CNN_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator(adata=training_dataset, \n",
    "                          genes=gene_list, aug=False),\n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "train_gen_ = train_gen.shuffle(buffer_size=500).batch(128).repeat(3).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator(adata=valid_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "valid_gen_ = valid_gen.shuffle(buffer_size=500).batch(128).repeat(3).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator(adata=test_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "test_gen_ = test_gen.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_NB_multiple_genes((299, 299, 3), n_genes)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,\n",
    "                                            restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./CNN_NB_8genes_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_gen_)\n",
    "from scipy.stats import nbinom\n",
    "y_preds = []\n",
    "if n_genes >1:\n",
    "    for i in range(n_genes):\n",
    "        n = test_predictions[i][:, 0]\n",
    "        p = test_predictions[i][:, 1]\n",
    "        y_pred = nbinom.mean(n, p)\n",
    "        y_preds.append(y_pred)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = np.array(y_preds).transpose()\n",
    "else:\n",
    "    n = test_predictions[:, 0]\n",
    "    p = test_predictions[:, 1]\n",
    "    y_pred = nbinom.mean(n, p)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_NB = test_final.copy()\n",
    "test_dataset_NB.X = test_dataset.obsm[\"predicted_gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-aviation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in gene_list:\n",
    "#     print(i)\n",
    "#     gene_plot(test_dataset_NB, genes=i, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-hollow",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# OUTPUT_PATH = Path(\"./cnn_nb_plot\")\n",
    "# OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "# final_adata = spatial_autocorr(test_final, test_dataset_NB, \"cnn_nb\", save_plots=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-nitrogen",
   "metadata": {},
   "source": [
    "# CNN NB two level tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in [\n",
    "    Sample1,\n",
    "    Sample2,\n",
    "]:\n",
    "#     count_df = adata.to_df()\n",
    "#     count_df[count_df <=1] = 0\n",
    "#     count_df[count_df >1] = 1\n",
    "#     adata.X = count_df\n",
    "#     adata[:,gene_list]\n",
    "#     st.pp.filter_genes(adata,min_cells=3)\n",
    "#     st.pp.normalize_total(adata)\n",
    "#     st.pp.log1p(adata)\n",
    "#     st.pp.scale(adata)\n",
    "\n",
    "    # pre-processing for spot image\n",
    "    TILE_PATH_ = TILE_PATH / list(adata.uns[\"spatial\"].keys())[0]\n",
    "    TILE_PATH_.mkdir(parents=True, exist_ok=True)\n",
    "    tiling(adata, TILE_PATH_, crop_size=299, target_size=299,save_name=\"small_tile\")\n",
    "    tiling(adata, TILE_PATH_, crop_size=900, target_size=900,save_name=\"large_tile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_NB_multiple_genes(tile_shape, n_genes):\n",
    "    tile_input = Input(shape=tile_shape, name=\"tile_input\")\n",
    "    resnet_base = ResNet50(input_tensor=tile_input, weights='imagenet', include_top=False)\n",
    "    #     stage_5_start = resnet_base.get_layer(\"conv5_block1_1_conv\")\n",
    "    #     for i in range(resnet_base.layers.index(stage_5_start)):\n",
    "    #         resnet_base.layers[i].trainable = False\n",
    "\n",
    "    for i in resnet_base.layers:\n",
    "        i.trainable = False\n",
    "    cnn = resnet_base.output\n",
    "    cnn = GlobalAveragePooling2D()(cnn)\n",
    "    #     cnn = Dropout(0.5)(cnn)\n",
    "    #     cnn = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.01),\n",
    "    #                 activity_regularizer=tf.keras.regularizers.l2(0.01))(cnn)\n",
    "    # cnn = Dense(256, activation='relu')(cnn)\n",
    "    output_layers = []\n",
    "    for i in range(n_genes):\n",
    "        output = Dense(2)(cnn)\n",
    "        output_layers.append(Lambda(negative_binomial_layer, name=\"gene_{}\".format(i))(output))\n",
    "\n",
    "    model = Model(inputs=tile_input, outputs=output_layers)\n",
    "    #     losses={}\n",
    "    #     for i in range(8):\n",
    "    #         losses[\"gene_{}\".format(i)] = negative_binomial_loss(i)\n",
    "    #     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "    model.compile(loss=negative_binomial_loss,\n",
    "                  optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-andrews",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-likelihood",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-wheel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene in gene_list:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final.obsm[\"gpd\"] = gpd.GeoDataFrame(test_final.obs,\n",
    "                                            geometry=gpd.points_from_xy(\n",
    "                                            test_final.obs.imagecol, \n",
    "                                            test_final.obs.imagerow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = gene_list[4]\n",
    "x = np.array(test_final.to_df()[gene].values, dtype='float')\n",
    "y = test_dataset_lstm.to_df()[gene].values\n",
    "w = Queen.from_dataframe(test_final.obsm[\"gpd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final.obsm[\"gpd\"][\"gc_{}\".format(gene)] = np.array(x, dtype='float')\n",
    "test_final.obsm[\"gpd\"][\"pred_{}\".format(gene)] = y\n",
    "tissue_image = test_final.uns[\"spatial\"][\"block2\"][\"images\"][\"fulres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "moran = Moran(x,w)\n",
    "moran_bv = Moran_BV(y, x, w)\n",
    "moran_loc = Moran_Local(x, w)\n",
    "moran_loc_bv = Moran_Local_BV(y, x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(test_final.obsm[\"gpd\"],\n",
    "                 \"pred_{}\".format(gene),\n",
    "                 \"gc_{}\".format(gene))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "moran_scatterplot(moran, ax=ax)\n",
    "ax.set_xlabel('prediction of gene {}'.format(gene))\n",
    "ax.set_ylabel('Spatial lag of ground truth of gene {}'.format(gene))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "moran_scatterplot(moran_bv, ax=ax)\n",
    "ax.set_xlabel('prediction of gene {}'.format(gene))\n",
    "ax.set_ylabel('Spatial lag of ground truth of gene {}'.format(gene))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "moran_scatterplot(moran_loc_bv, p=0.05, ax=ax)\n",
    "ax.set_xlabel('prediction of gene {}'.format(gene))\n",
    "ax.set_ylabel('Spatial lag of ground truth of gene {}'.format(gene))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa_cluster(moran_loc_bv, test_final.obsm[\"gpd\"], p=0.05, \n",
    "             figsize = (9,9), markersize=12,)# **{\"alpha\":1})\n",
    "plt.imshow(tissue_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa_cluster(moran_loc, test_final.obsm[\"gpd\"], p=0.05, \n",
    "             figsize = (9,9), markersize=12,)# **{\"alpha\":1})\n",
    "plt.imshow(tissue_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./8genes_spatial_autocorr.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm = df[[\"moran_i_lstm\", \"n_sigs_lstm\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb =  df[[\"moran_i_cnn_nb\", \"n_sigs_cnn_nb\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm[\"genes\"] = df_lstm.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb[\"genes\"] = df_nb.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm = df_lstm.reset_index()\n",
    "df_nb = df_nb.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm[\"model\"] = \"lstm\"\n",
    "df_nb[\"model\"] = \"cnn_nb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm.columns = ['index', 'moran_i', 'n_sigs', 'genes', 'model']\n",
    "df_nb.columns = ['index', 'moran_i', 'n_sigs', 'genes', 'model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_lstm, df_nb], axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    data=df_final,\n",
    "    x=\"genes\", y=\"moran_i\", hue=\"model\",\n",
    "    markers=True, dashes=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    data=df_final,\n",
    "    x=\"genes\", y=\"n_sigs\", hue=\"model\",\n",
    "    markers=True, dashes=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-progressive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
