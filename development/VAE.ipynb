{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "baking-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import stlearn as st\n",
    "st.settings.set_figure_params(dpi=300)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sys\n",
    "file = Path(\"../stimage\").resolve()\n",
    "parent= file.parent\n",
    "sys.path.append(str(parent))\n",
    "from PIL import Image\n",
    "from stimage._utils import gene_plot, Read10X, ReadOldST, tiling\n",
    "from stimage._model import CNN_NB_multiple_genes\n",
    "# from stimage._data_generator import DataGenerator\n",
    "from stimage._imgaug import seq_aug\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import anndata\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "electric-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator_VAE(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    def __init__(self, adata, dim=(299, 299), n_channels=3, genes=None, aug=False, tile_path=\"tile_path\"):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.adata = adata\n",
    "        self.n_channels = n_channels\n",
    "        self.genes = genes\n",
    "        self.num_genes = len(genes)\n",
    "        self.aug = aug\n",
    "        self.tile_path = tile_path\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(self.adata.n_obs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Find list of IDs\n",
    "        obs_temp = self.adata.obs_names[index]\n",
    "\n",
    "        # Generate data\n",
    "        X_img = self._load_img(obs_temp)\n",
    "        y = self._load_label(obs_temp)\n",
    "\n",
    "        return X_img, X_img, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.adata.n_obs)\n",
    "\n",
    "    def _load_img(self, obs):\n",
    "        img_path = self.adata.obs.loc[obs, 'tile_path']\n",
    "        X_img = image.load_img(img_path, target_size=self.dim)\n",
    "        X_img = image.img_to_array(X_img).astype('float64')\n",
    "        #         X_img = np.expand_dims(X_img, axis=0)\n",
    "        #         n_rotate = np.random.randint(0, 4)\n",
    "        #         X_img = np.rot90(X_img, k=n_rotate, axes=(1, 2))\n",
    "        if self.aug:\n",
    "            X_img = seq_aug(image=X_img)\n",
    "#         X_img = preprocess_resnet(X_img)\n",
    "        X_img /= 255.0\n",
    "        return X_img\n",
    "\n",
    "    def _load_label(self, obs):\n",
    "        batch_adata = self.adata[obs, self.genes].copy()\n",
    "\n",
    "        return tuple([batch_adata.to_df()[i].values for i in self.genes])\n",
    "\n",
    "    def get_classes(self):\n",
    "        return self.adata.to_df().loc[:, self.genes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "empirical-promise",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = Path(\"/clusterdata/uqxtan9/Xiao/STimage/dataset/breast_cancer_10x_visium\")\n",
    "TILE_PATH = Path(\"/tmp\") / \"tiles\"\n",
    "TILE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAMPLE = \"block1\"\n",
    "Sample1 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\", 0)\n",
    "Sample1.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img\n",
    "\n",
    "SAMPLE = \"block2\"\n",
    "Sample2 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_2_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_2_image.tif\", 0)\n",
    "Sample2.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "optical-dress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SLITRK6', 'PGM5', 'LINC00645', 'TTLL12', 'COX6C', 'CPB1', 'KRT5', 'MALAT1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_list=[\"SLITRK6\", \"PGM5\", \"LINC00645\", \n",
    "           \"TTLL12\", \"COX6C\", \"CPB1\",\n",
    "           \"KRT5\", \"MALAT1\"]\n",
    "gene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defensive-hometown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log transformation step is finished in adata.X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tiling image: 100%|██████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log transformation step is finished in adata.X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tiling image: 100%|██████████ [ time left: 00:00 ]\n"
     ]
    }
   ],
   "source": [
    "for adata in [\n",
    "    Sample1,\n",
    "    Sample2,\n",
    "]:\n",
    "#     count_df = adata.to_df()\n",
    "#     count_df[count_df <=1] = 0\n",
    "#     count_df[count_df >1] = 1\n",
    "#     adata.X = count_df\n",
    "#     adata[:,gene_list]\n",
    "    st.pp.filter_genes(adata,min_cells=3)\n",
    "#     st.pp.normalize_total(adata)\n",
    "    st.pp.log1p(adata)\n",
    "#     st.pp.scale(adata)\n",
    "\n",
    "    # pre-processing for spot image\n",
    "    TILE_PATH_ = TILE_PATH / list(adata.uns[\"spatial\"].keys())[0]\n",
    "    TILE_PATH_.mkdir(parents=True, exist_ok=True)\n",
    "    tiling(adata, TILE_PATH_, crop_size=512,target_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "desperate-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = len(gene_list)\n",
    "training_index = Sample1.obs.sample(frac=0.7, random_state=1).index\n",
    "# training_dataset = Sample1[training_index,].copy()\n",
    "\n",
    "training_dataset = Sample1.copy()\n",
    "\n",
    "valid_index = Sample1.obs.index.isin(training_index)\n",
    "valid_dataset = Sample1[~valid_index,].copy()\n",
    "\n",
    "test_dataset = Sample2.copy()\n",
    "\n",
    "train_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_VAE(adata=training_dataset, \n",
    "                          genes=gene_list, aug=False,dim=(128,128)),\n",
    "            output_types=(tf.float32, tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([128,128,3], [128,128,3], tuple([1]*n_genes))\n",
    ")\n",
    "train_gen_ = train_gen.shuffle(buffer_size=500).batch(8).repeat(3).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_VAE(adata=valid_dataset, \n",
    "                          genes=gene_list,dim=(128,128)), \n",
    "            output_types=(tf.float32, tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([128,128,3], [128,128,3], tuple([1]*n_genes))\n",
    ")\n",
    "valid_gen_ = valid_gen.shuffle(buffer_size=500).batch(8).repeat(3).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_VAE(adata=test_dataset, \n",
    "                          genes=gene_list,dim=(128,128)), \n",
    "            output_types=(tf.float32, tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([128,128,3], [128,128,3], tuple([1]*n_genes))\n",
    ")\n",
    "test_gen_ = test_gen.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unusual-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = len(gene_list)\n",
    "training_index = Sample1.obs.sample(frac=0.7, random_state=1).index\n",
    "# training_dataset = Sample1[training_index,].copy()\n",
    "\n",
    "training_dataset = Sample1.copy()\n",
    "\n",
    "valid_index = Sample1.obs.index.isin(training_index)\n",
    "valid_dataset = Sample1[~valid_index,].copy()\n",
    "\n",
    "test_dataset = Sample2.copy()\n",
    "\n",
    "train_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_VAE(adata=training_dataset, \n",
    "                          genes=gene_list, aug=False,dim=(224,224)),\n",
    "            output_types=(tf.float32, tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([224,224,3], [224,224,3], tuple([1]*n_genes))\n",
    ")\n",
    "train_gen_ = train_gen.shuffle(buffer_size=500).batch(8).repeat(3).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_VAE(adata=valid_dataset, \n",
    "                          genes=gene_list,dim=(224,224)), \n",
    "            output_types=(tf.float32, tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([224,224,3], [224,224,3], tuple([1]*n_genes))\n",
    ")\n",
    "valid_gen_ = valid_gen.shuffle(buffer_size=500).batch(8).repeat(3).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_VAE(adata=test_dataset, \n",
    "                          genes=gene_list,dim=(224,224)), \n",
    "            output_types=(tf.float32, tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([224,224,3], [224,224,3], tuple([1]*n_genes))\n",
    ")\n",
    "test_gen_ = test_gen.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "consolidated-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    \"\"\"Variational autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(224, 224, 3)),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "                \n",
    "                tf.keras.layers.LeakyReLU(),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "                tf.keras.layers.Dense(units=14*14*32, activation=tf.nn.relu),\n",
    "                tf.keras.layers.Reshape(target_shape=(14, 14, 32)),\n",
    "                tf.keras.layers.LeakyReLU(),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=3, kernel_size=3, strides=1, padding='same'),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=True):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "\n",
    "latent_dim = 256\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "\n",
    "model = VAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-rapid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "        axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    \n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for image_, _, label_ in train_gen_:\n",
    "        train_step(model, image_, optimizer)\n",
    "    end_time = time.time()\n",
    "\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for image_, _, label_ in train_gen_:\n",
    "        loss(compute_loss(model, image_))\n",
    "    elbo = -loss.result()\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, elbo, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#         model1 = tf.keras.Sequential(\n",
    "#             [\n",
    "#                 tf.keras.layers.InputLayer(input_shape=(224, 224, 3)),\n",
    "#                 tf.keras.layers.Conv2D(\n",
    "#                     filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "#                 tf.keras.layers.Conv2D(\n",
    "#                     filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "#                 tf.keras.layers.Flatten(),\n",
    "#                 # No activation\n",
    "#                 tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#         model2 = tf.keras.Sequential(\n",
    "#             [\n",
    "#                 tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "#                 tf.keras.layers.Dense(units=56*56*32, activation=tf.nn.relu),\n",
    "#                 tf.keras.layers.Reshape(target_shape=(56, 56, 32)),\n",
    "#                 tf.keras.layers.Conv2DTranspose(\n",
    "#                     filters=64, kernel_size=3, strides=2, padding='same',\n",
    "#                     activation='relu'),\n",
    "#                 tf.keras.layers.Conv2DTranspose(\n",
    "#                     filters=32, kernel_size=3, strides=2, padding='same',\n",
    "#                     activation='relu'),\n",
    "#                 # No activation\n",
    "#                 tf.keras.layers.Conv2DTranspose(\n",
    "#                     filters=3, kernel_size=3, strides=1, padding='same'),\n",
    "#             ]\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_, _, label_ in train_gen.shuffle(2000).take(1):\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_.numpy())\n",
    "    plt.axis('Off')\n",
    "    \n",
    "    mean, logvar = model.encode(np.expand_dims(image_.numpy(), axis=0))\n",
    "    z_sample = model.reparameterize(mean, logvar)\n",
    "    x_decoded = model.decode(z_sample)\n",
    "    decode_img = tf.reshape(x_decoded[0], (224, 224, 3))    \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(x_decoded[0])\n",
    "    plt.axis('Off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "exposed-recorder",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-63-854370302176>:58 sample  *\n        return self.decode(eps, apply_sigmoid=True)\n    <ipython-input-63-854370302176>:69 decode  *\n        logits = self.decoder(z)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__  **\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_17 is incompatible with the layer: expected axis -1 of input shape to have value 8 but received input with shape (1, 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-f137c90992c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mz_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdigit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_decoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdigit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         figure[i * digit_size: (i + 1) * digit_size,\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3885\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-63-854370302176>:58 sample  *\n        return self.decode(eps, apply_sigmoid=True)\n    <ipython-input-63-854370302176>:69 decode  *\n        logits = self.decoder(z)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__  **\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_17 is incompatible with the layer: expected axis -1 of input shape to have value 8 but received input with shape (1, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "digit_size = 224\n",
    "n = 15\n",
    "figure = np.zeros((digit_size * n, digit_size * n, 3))\n",
    "\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = model.sample(z_sample)\n",
    "        digit = tf.reshape(x_decoded[0], (digit_size, digit_size, 3))\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit.numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.axis('Off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-treasure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-sodium",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-emperor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-steel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-settle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "structured-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comparable-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = (128,128,3) # Image dimension\n",
    "BATCH_SIZE = 512\n",
    "Z_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vae(input_dim_en, output_dim_en, conv_filters_en, conv_kernel_size_en, \n",
    "                  conv_strides_en, use_batch_norm = False, use_dropout = False):\n",
    "\n",
    "    n_layers = len(conv_filters_en)\n",
    "\n",
    "    encoder_input = Input(shape = input_dim, name = 'encoder_input')\n",
    "    x = encoder_input\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        x = Conv2D(filters = conv_filters_en[i], \n",
    "                    kernel_size = conv_kernel_size_en[i],\n",
    "                    strides = conv_strides_en[i], \n",
    "                    padding = 'same',\n",
    "                    name = 'encoder_conv_' + str(i)\n",
    "                    )(x)\n",
    "        if use_batch_norm:\n",
    "            x = BathcNormalization()(x)\n",
    "  \n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        if use_dropout:\n",
    "            x = Dropout(rate=0.25)(x)\n",
    "\n",
    "\n",
    "    shape_before_flattening = K.int_shape(x)[1:] \n",
    "  \n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    mean_mu = Dense(output_dim, name = 'mu')(x)\n",
    "    log_var = Dense(output_dim, name = 'log_var')(x)\n",
    "\n",
    "\n",
    "    def sampling(args):\n",
    "        mean_mu, log_var = args\n",
    "        epsilon = K.random_normal(shape=K.shape(mean_mu), mean=0., stddev=1.) \n",
    "        return mean_mu + K.exp(log_var/2)*epsilon   \n",
    "  \n",
    "    encoder_output = Lambda(sampling, name='encoder_output')([mean_mu, log_var])\n",
    "\n",
    "\n",
    "    return encoder_input, encoder_output, mean_mu, log_var, shape_before_flattening, Model(encoder_input, encoder_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "outer-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER\n",
    "def build_vae_encoder(input_dim, output_dim, conv_filters, conv_kernel_size, \n",
    "                  conv_strides, use_batch_norm = False, use_dropout = False):\n",
    "    \n",
    "    n_layers = len(conv_filters)\n",
    "\n",
    "    encoder_input = Input(shape = input_dim, name = 'encoder_input')\n",
    "    x = encoder_input\n",
    "\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        x = Conv2D(filters = conv_filters[i], \n",
    "                  kernel_size = conv_kernel_size[i],\n",
    "                  strides = conv_strides[i], \n",
    "                  padding = 'same',\n",
    "                  name = 'encoder_conv_' + str(i)\n",
    "                  )(x)\n",
    "        if use_batch_norm:\n",
    "            x = BathcNormalization()(x)\n",
    "  \n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        if use_dropout:\n",
    "            x = Dropout(rate=0.25)(x)\n",
    "\n",
    "    shape_before_flattening = K.int_shape(x)[1:] \n",
    "  \n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    mean_mu = Dense(output_dim, name = 'mu')(x)\n",
    "    log_var = Dense(output_dim, name = 'log_var')(x)\n",
    "\n",
    "\n",
    "    def sampling(args):\n",
    "        mean_mu, log_var = args\n",
    "        epsilon = K.random_normal(shape=K.shape(mean_mu), mean=0., stddev=1.) \n",
    "        return mean_mu + K.exp(log_var/2)*epsilon   \n",
    "  \n",
    "    encoder_output = Lambda(sampling, name='encoder_output')([mean_mu, log_var])\n",
    "\n",
    "    return encoder_input, encoder_output, mean_mu, log_var, shape_before_flattening, Model(encoder_input, encoder_output)\n",
    "\n",
    "vae_encoder_input, vae_encoder_output,  mean_mu, log_var, vae_shape_before_flattening, vae_encoder  = build_vae_encoder(input_dim = INPUT_DIM,\n",
    "                                    output_dim = Z_DIM, \n",
    "                                    conv_filters = [32, 64, 64, 64],\n",
    "                                    conv_kernel_size = [3,3,3,3],\n",
    "                                    conv_strides = [2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "attractive-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "def build_decoder(input_dim, shape_before_flattening, conv_filters, conv_kernel_size, \n",
    "                  conv_strides):\n",
    "\n",
    "\n",
    "    n_layers = len(conv_filters)\n",
    "\n",
    "\n",
    "    decoder_input = Input(shape = (input_dim,) , name = 'decoder_input')\n",
    "\n",
    "\n",
    "    x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "    x = Reshape(shape_before_flattening)(x)\n",
    "\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        x = Conv2DTranspose(filters = conv_filters[i], \n",
    "                  kernel_size = conv_kernel_size[i],\n",
    "                  strides = conv_strides[i], \n",
    "                  padding = 'same',\n",
    "                  name = 'decoder_conv_' + str(i)\n",
    "                  )(x)\n",
    "      \n",
    "\n",
    "        if i < n_layers - 1:\n",
    "            x = LeakyReLU()(x)\n",
    "        else:\n",
    "            x = Activation('sigmoid')(x)\n",
    "\n",
    "    decoder_output = x\n",
    "\n",
    "    return decoder_input, decoder_output, Model(decoder_input, decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "qualified-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_decoder_input, vae_decoder_output, vae_decoder = build_decoder(input_dim = Z_DIM,\n",
    "                                        shape_before_flattening = vae_shape_before_flattening,\n",
    "                                        conv_filters = [64,64,32,3],\n",
    "                                        conv_kernel_size = [3,3,3,3],\n",
    "                                        conv_strides = [2,2,2,2]\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "guilty-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vae_input = vae_encoder.input\n",
    "\n",
    "\n",
    "vae_output = vae_decoder(vae_encoder.output)\n",
    "\n",
    "\n",
    "vae_model = Model(vae_encoder.input, vae_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "specified-interaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128, 128, 3) dtype=float32 (created by layer 'model_1')>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "marine-chicken",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)         (None, 64, 64, 32)   896         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 64, 64, 32)   0           encoder_conv_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)         (None, 32, 32, 64)   18496       leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           encoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)         (None, 16, 16, 64)   36928       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 64)   0           encoder_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)         (None, 8, 8, 64)     36928       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 8, 8, 64)     0           encoder_conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4096)         0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 200)          819400      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 200)          819400      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 200)          0           mu[0][0]                         \n",
      "                                                                 log_var[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 128, 128, 3)  916483      encoder_output[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,648,531\n",
      "Trainable params: 2,648,531\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dangerous-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = train_gen_.map(lambda x,y,z : (x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "affected-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 128, 128, 3), (None, 128, 128, 3)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "informational-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = images.cache().shuffle(1000).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dying-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ = zip(images,images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "parliamentary-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:755 train_step\n        loss = self.compiled_loss(\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:237 __call__\n        self._loss_metric.update_state(\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:177 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:363 update_state  **\n        sample_weight = weights_broadcast_ops.broadcast_weights(\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/ops/weights_broadcast_ops.py:155 broadcast_weights\n        values = ops.convert_to_tensor(values, name=\"values\")\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1540 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:264 constant\n        return _constant_impl(value, dtype, shape, name, verify_shape=False,\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:281 _constant_impl\n        tensor_util.make_tensor_proto(\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:435 make_tensor_proto\n        values = np.asarray(values)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/numpy/core/_asarray.py:83 asarray\n        return array(a, dtype, copy=False, order=order)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/keras_tensor.py:273 __array__\n        raise TypeError(\n\n    TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a1033ee175b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# checkpoint_vae = ModelCheckpoint(os.path.join(WEIGHTS_FOLDER, 'VAE/weights.h5'), save_weights_only = True, verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m vae_model.fit(images,\n\u001b[0m\u001b[1;32m     23\u001b[0m                         epochs = N_EPOCHS)\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:755 train_step\n        loss = self.compiled_loss(\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:237 __call__\n        self._loss_metric.update_state(\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:177 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:363 update_state  **\n        sample_weight = weights_broadcast_ops.broadcast_weights(\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/ops/weights_broadcast_ops.py:155 broadcast_weights\n        values = ops.convert_to_tensor(values, name=\"values\")\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1540 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:264 constant\n        return _constant_impl(value, dtype, shape, name, verify_shape=False,\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:281 _constant_impl\n        tensor_util.make_tensor_proto(\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:435 make_tensor_proto\n        values = np.asarray(values)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/numpy/core/_asarray.py:83 asarray\n        return array(a, dtype, copy=False, order=order)\n    /scratch/imb/Xiao/.conda/envs/stimage/lib/python3.8/site-packages/tensorflow/python/keras/engine/keras_tensor.py:273 __array__\n        raise TypeError(\n\n    TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "N_EPOCHS = 10\n",
    "LOSS_FACTOR = 10000\n",
    "\n",
    "\n",
    "def r_loss(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n",
    "\n",
    "def kl_loss(y_true, y_pred):\n",
    "    kl_loss =  -0.5 * K.sum(1 + log_var - K.square(mean_mu) - K.exp(log_var), axis = 1)\n",
    "    return kl_loss\n",
    "\n",
    "def total_loss(y_true, y_pred):\n",
    "    return LOSS_FACTOR*r_loss(y_true, y_pred) + kl_loss(y_true, y_pred)\n",
    "  \n",
    "adam_optimizer = Adam(lr = LEARNING_RATE)\n",
    "\n",
    "vae_model.compile(optimizer=adam_optimizer, loss = total_loss, metrics = [r_loss, kl_loss])\n",
    "\n",
    "# checkpoint_vae = ModelCheckpoint(os.path.join(WEIGHTS_FOLDER, 'VAE/weights.h5'), save_weights_only = True, verbose=1)\n",
    "\n",
    "vae_model.fit(images,\n",
    "                        epochs = N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-transcript",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "solved-ancient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23355 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = \"/tmp/tiles/\"\n",
    "data_flow = ImageDataGenerator(rescale=1./255).flow_from_directory(DATA_FOLDER, \n",
    "                                                                   target_size = INPUT_DIM[:2],\n",
    "                                                                   batch_size = 10,\n",
    "                                                                   shuffle = True,\n",
    "                                                                   class_mode = \"input\",\n",
    "                                                                   subset = 'training'\n",
    "                                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "removed-management",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x7f9db753e0a0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-installation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
