{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import stlearn as st\n",
    "st.settings.set_figure_params(dpi=300)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sys\n",
    "file = Path(\"../stimage\").resolve()\n",
    "parent= file.parent\n",
    "sys.path.append(str(parent))\n",
    "from PIL import Image\n",
    "from stimage._utils import gene_plot, Read10X, ReadOldST, tiling\n",
    "from stimage._model import CNN_NB_multiple_genes\n",
    "from stimage._data_generator import DataGenerator\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-delight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(\"/clusterdata/uqxtan9/Xiao/STimage/dataset/breast_cancer_10x_visium\")\n",
    "TILE_PATH = Path(\"/tmp\") / \"tiles\"\n",
    "TILE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAMPLE = \"block1\"\n",
    "Sample1 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\", 0)\n",
    "Sample1.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img\n",
    "\n",
    "SAMPLE = \"block2\"\n",
    "Sample2 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_2_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_2_image.tif\", 0)\n",
    "Sample2.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-pressure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Sample1.to_df()[Sample1.to_df().sum().sort_values(ascending=False).index[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "MinMax_scaler_y = preprocessing.MinMaxScaler(feature_range =(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame(MinMax_scaler_y.fit_transform(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.apply(lambda x: pd.cut(x, bins=[-0.01, 0.33, 0.66, 1], labels = [0, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_1 = Sample1.to_df().filter(regex=(\"KRT.*\")).columns\n",
    "gene_list_2 = Sample2.to_df().filter(regex=(\"KRT.*\")).columns\n",
    "gene_list_share = gene_list_1.intersection(gene_list_2)\n",
    "len(gene_list_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-mention",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_plot(Sample1, genes=gene_list_share, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_plot(Sample2, genes=gene_list_share, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list = [\"ACTA2\", \"CNN1\", \"COL1A1\", \"MYLK\", \"MME\", \"MYH11\", \"KRT5\", \"ITGB6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_plot(Sample1, genes=gene_list, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_plot(Sample2, genes=gene_list, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anndata import AnnData\n",
    "from typing import Iterable, Union, Optional\n",
    "import pandas as pd\n",
    "def enrich_group(adata: AnnData,\n",
    "                 gene_list: Iterable,\n",
    "                 enrich_name: Union[pd.Index, list],\n",
    "                 \n",
    "\n",
    "                \n",
    ") -> Optional[AnnData]:\n",
    "    adata_ = adata[:,adata.var_names.isin(gene_list)].copy()\n",
    "    adata_enrich = AnnData(X=adata_.X.sum(axis=1),\n",
    "                       obs=adata_.obs,\n",
    "                       uns=adata_.uns,\n",
    "                       obsm=adata_.obsm)\n",
    "    adata_enrich.var_names = enrich_name\n",
    "    return adata_enrich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-graphic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-publicity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-audience",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list=[\"SLITRK6\", \"PGM5\", \"LINC00645\", \n",
    "           \"TTLL12\", \"COX6C\", \"CPB1\",\n",
    "           \"KRT5\", \"MALAT1\"]\n",
    "gene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-carbon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for adata in [\n",
    "    Sample1,\n",
    "    Sample2,\n",
    "]:\n",
    "#     count_df = adata.to_df()\n",
    "#     count_df[count_df <=1] = 0\n",
    "#     count_df[count_df >1] = 1\n",
    "#     adata.X = count_df\n",
    "#     adata[:,gene_list]\n",
    "    st.pp.filter_genes(adata,min_cells=3)\n",
    "#     st.pp.normalize_total(adata)\n",
    "#     st.pp.log1p(adata)\n",
    "#     st.pp.scale(adata)\n",
    "\n",
    "    # pre-processing for spot image\n",
    "    TILE_PATH_ = TILE_PATH / list(adata.uns[\"spatial\"].keys())[0]\n",
    "    TILE_PATH_.mkdir(parents=True, exist_ok=True)\n",
    "    tiling(adata, TILE_PATH_, crop_size=299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_1 = Sample1.to_df().filter(regex=(\"KRT.*\")).columns\n",
    "gene_list_2 = Sample2.to_df().filter(regex=(\"KRT.*\")).columns\n",
    "gene_list_share = gene_list_1.intersection(gene_list_2)\n",
    "len(gene_list_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list=pd.Index([\"KRT_enrich\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample1 = enrich_group(Sample1, \n",
    "                       gene_list_share, \n",
    "                       gene_list)\n",
    "Sample2 = enrich_group(Sample2, \n",
    "                       gene_list_share, \n",
    "                       gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-crown",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = len(gene_list)\n",
    "training_index = Sample1.obs.sample(frac=0.7, random_state=1).index\n",
    "training_dataset = Sample1[training_index,].copy()\n",
    "\n",
    "valid_index = Sample1.obs.index.isin(training_index)\n",
    "valid_dataset = Sample1[~valid_index,].copy()\n",
    "\n",
    "test_dataset = Sample2.copy()\n",
    "\n",
    "train_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator(adata=training_dataset, \n",
    "                          genes=gene_list, aug=False),\n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "train_gen_ = train_gen.shuffle(buffer_size=500).batch(128).repeat(3).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator(adata=valid_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "valid_gen_ = valid_gen.shuffle(buffer_size=500).batch(128).repeat(3).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator(adata=test_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "test_gen_ = test_gen.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-minimum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_NB_multiple_genes((299, 299, 3), n_genes)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,\n",
    "                                            restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-present",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_history = model.fit(train_gen_,\n",
    "                          epochs=100,\n",
    "                          validation_data=valid_gen_,\n",
    "                          callbacks=[callback]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_gen_)\n",
    "from scipy.stats import nbinom\n",
    "y_preds = []\n",
    "if n_genes >1:\n",
    "    for i in range(n_genes):\n",
    "        n = test_predictions[i][:, 0]\n",
    "        p = test_predictions[i][:, 1]\n",
    "        y_pred = nbinom.mean(n, p)\n",
    "        y_preds.append(y_pred)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = np.array(y_preds).transpose()\n",
    "else:\n",
    "    n = test_predictions[:, 0]\n",
    "    p = test_predictions[:, 1]\n",
    "    y_pred = nbinom.mean(n, p)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./CNN_NB_8genes_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_ = test_dataset[:,gene_list].copy()\n",
    "test_dataset_.X = test_dataset_.obsm[\"predicted_gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gene_list:\n",
    "    print(i)\n",
    "    gene_plot(test_dataset_, genes=i, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gene_list:\n",
    "    print(i)\n",
    "    gene_plot(Sample1, genes=i, spot_size=8)\n",
    "    gene_plot(test_dataset_, genes=i, spot_size=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
