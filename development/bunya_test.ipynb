{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 20:02:50.088093: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-03 20:02:50.132491: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-03 20:02:50.146830: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-03 20:02:50.207918: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-03 20:02:56.585585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sys\n",
    "from PIL import Image\n",
    "from stimage._utils import gene_plot, Read10X, ReadOldST, tiling\n",
    "from stimage._model import CNN_NB_multiple_genes, negative_binomial_layer, negative_binomial_loss\n",
    "from stimage._data_generator import DataGenerator, DataGenerator_LSTM_one_output\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "# import geopandas as gpd\n",
    "from sklearn.neighbors import KDTree\n",
    "from anndata import read_h5ad\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: rscp: command not found\n"
     ]
    }
   ],
   "source": [
    "#!mkdir -p /tmp/STimage_dataset/breast_cancer_10x_visium\n",
    "#!rscp /scratch/project_mnt/S0010/Xiao/Q1851/Xiao/Working_project/STimage_dataset/breast_cancer_10x_visium/dataset_3_299 /tmp/STimage_dataset/breast_cancer_10x_visium/dataset_3_299\n",
    "#!cd /tmp/STimage_dataset/breast_cancer_10x_visium/dataset_3_299\n",
    "#!extract tiles-delta2-Nov-10-21.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"/tmp/STimage_dataset/breast_cancer_10x_visium/dataset_3_299\")\n",
    "adata_all = read_h5ad(DATA_PATH / \"all_adata.h5ad\")\n",
    "adata_all.obs[\"tile_path\"] = adata_all.obs.tile_path.map(lambda x:x.replace(\"/clusterdata/uqxtan9/Xiao/Q1851/Xiao/\",\n",
    "                                               \"/tmp/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list=[\"COX6C\",\"TTLL12\", \"PABPC1\", \"GNAS\", \"HSP90AB1\", \n",
    "           \"TFF3\", \"ATP1A1\", \"B2M\", \"FASN\", \"SPARC\", \"CD74\", \"CD63\", \"CD24\", \"CD81\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = len(gene_list)\n",
    "training_index = adata_all.obs.library_id == \"block1\"\n",
    "training_dataset = adata_all[training_index,].copy()\n",
    "\n",
    "valid_index = adata_all.obs.library_id == \"block2\"\n",
    "valid_dataset = adata_all[valid_index,].copy()\n",
    "\n",
    "test_index = adata_all.obs.library_id == \"FFPE\"\n",
    "test_dataset = adata_all[test_index,].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator(adata=training_dataset, \n",
    "                          genes=gene_list, aug=False),\n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "train_gen_ = train_gen.shuffle(buffer_size=500).batch(128).repeat(3).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator(adata=valid_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "valid_gen_ = valid_gen.shuffle(buffer_size=500).batch(128).repeat(3).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator(adata=test_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "test_gen_ = test_gen.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = CNN_NB_multiple_genes((299, 299, 3), n_genes)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,\n",
    "                                            restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 20:11:55.314069: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 15 of 500\n",
      "2024-08-03 20:12:15.142051: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 44 of 500\n",
      "2024-08-03 20:12:25.427718: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 59 of 500\n",
      "2024-08-03 20:12:45.020575: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 88 of 500\n",
      "2024-08-03 20:12:55.309930: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 103 of 500\n",
      "2024-08-03 20:13:05.425564: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 118 of 500\n",
      "2024-08-03 20:13:25.240112: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 147 of 500\n",
      "2024-08-03 20:13:35.453159: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 162 of 500\n",
      "2024-08-03 20:13:55.340221: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 191 of 500\n",
      "2024-08-03 20:14:15.160970: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 220 of 500\n",
      "2024-08-03 20:14:25.242304: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 235 of 500\n",
      "2024-08-03 20:14:35.310630: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 250 of 500\n",
      "2024-08-03 20:14:45.457433: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 265 of 500\n",
      "2024-08-03 20:15:04.973511: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 294 of 500\n",
      "2024-08-03 20:15:14.979967: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 309 of 500\n",
      "2024-08-03 20:15:24.997671: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 324 of 500\n",
      "2024-08-03 20:15:45.498998: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 355 of 500\n",
      "2024-08-03 20:15:55.515063: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 370 of 500\n",
      "2024-08-03 20:16:15.365456: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 400 of 500\n",
      "2024-08-03 20:16:25.404201: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 415 of 500\n",
      "2024-08-03 20:16:45.421336: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 445 of 500\n",
      "2024-08-03 20:17:05.340020: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 475 of 500\n",
      "2024-08-03 20:17:21.896829: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/Unknown \u001b[1m1043s\u001b[0m 87s/step - loss: 52.5293"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(train_gen_,\n",
    "                          epochs=50,\n",
    "                          validation_data=valid_gen_,\n",
    "                          callbacks=[callback]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_gen_)\n",
    "from scipy.stats import nbinom\n",
    "y_preds = []\n",
    "for i in range(n_genes):\n",
    "    n = test_predictions[i][:, 0]\n",
    "    p = test_predictions[i][:, 1]\n",
    "    y_pred = nbinom.mean(n, p)\n",
    "    y_preds.append(y_pred)\n",
    "test_dataset.obsm[\"predicted_gene\"] = np.array(y_preds).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stimage_ld",
   "language": "python",
   "name": "stimage_ld"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
