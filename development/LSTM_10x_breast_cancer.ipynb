{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import stlearn as st\n",
    "st.settings.set_figure_params(dpi=300)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sys\n",
    "file = Path(\"../stimage\").resolve()\n",
    "parent= file.parent\n",
    "sys.path.append(str(parent))\n",
    "from PIL import Image\n",
    "from stimage._utils import gene_plot, Read10X, ReadOldST, tiling\n",
    "from stimage._model import CNN_NB_multiple_genes, negative_binomial_layer, negative_binomial_loss\n",
    "from stimage._data_generator import DataGenerator, DataGenerator_LSTM_one_output\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anndata import AnnData\n",
    "from typing import Iterable, Union, Optional\n",
    "import pandas as pd\n",
    "def enrich_group(adata: AnnData,\n",
    "                 gene_list: Iterable,\n",
    "                 enrich_name: Union[pd.Index, list],\n",
    "                 \n",
    "\n",
    "                \n",
    ") -> Optional[AnnData]:\n",
    "    adata_ = adata[:,adata.var_names.isin(gene_list)].copy()\n",
    "    adata_enrich = AnnData(X=adata_.X.sum(axis=1),\n",
    "                       obs=adata_.obs,\n",
    "                       uns=adata_.uns,\n",
    "                       obsm=adata_.obsm)\n",
    "    adata_enrich.var_names = enrich_name\n",
    "    return adata_enrich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def plot_correlation(df, attr_1, attr_2):\n",
    "    r = stats.pearsonr(df[attr_1], \n",
    "                       df[attr_2])[0] **2\n",
    "\n",
    "    g = sns.lmplot(data=df,\n",
    "        x=attr_1, y=attr_2,\n",
    "        height=5, legend=True\n",
    "    )\n",
    "    # g.set(ylim=(0, 360), xlim=(0,360))\n",
    "\n",
    "    g.set_axis_labels(attr_1, attr_2)\n",
    "    plt.annotate(r'$R^2:{0:.2f}$'.format(r),\n",
    "                (max(df[attr_1])*0.9, max(df[attr_2])*0.9))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(\"/clusterdata/uqxtan9/Xiao/STimage/dataset/breast_cancer_10x_visium\")\n",
    "TILE_PATH = Path(\"/tmp\") / \"tiles\"\n",
    "TILE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAMPLE = \"block1\"\n",
    "Sample1 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\", 0)\n",
    "Sample1.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img\n",
    "\n",
    "SAMPLE = \"block2\"\n",
    "Sample2 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_2_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_2_image.tif\", 0)\n",
    "Sample2.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list=[\"SLITRK6\", \"PGM5\", \"LINC00645\", \n",
    "           \"TTLL12\", \"COX6C\", \"CPB1\",\n",
    "           \"KRT5\", \"MALAT1\"]\n",
    "gene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-courtesy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-carbon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for adata in [\n",
    "    Sample1,\n",
    "    Sample2,\n",
    "]:\n",
    "#     count_df = adata.to_df()\n",
    "#     count_df[count_df <=1] = 0\n",
    "#     count_df[count_df >1] = 1\n",
    "#     adata.X = count_df\n",
    "#     adata[:,gene_list]\n",
    "    st.pp.filter_genes(adata,min_cells=3)\n",
    "#     st.pp.normalize_total(adata)\n",
    "    st.pp.log1p(adata)\n",
    "#     st.pp.scale(adata)\n",
    "\n",
    "    # pre-processing for spot image\n",
    "    TILE_PATH_ = TILE_PATH / list(adata.uns[\"spatial\"].keys())[0]\n",
    "    TILE_PATH_.mkdir(parents=True, exist_ok=True)\n",
    "    tiling(adata, TILE_PATH_, crop_size=299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_1 = Sample1.to_df().filter(regex=(\"KRT.*\")).columns\n",
    "gene_list_2 = Sample2.to_df().filter(regex=(\"KRT.*\")).columns\n",
    "gene_list_share = gene_list_1.intersection(gene_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list=pd.Index([\"KRT_enrich\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample1 = enrich_group(Sample1, \n",
    "                       gene_list_share, \n",
    "                       gene_list)\n",
    "Sample2 = enrich_group(Sample2, \n",
    "                       gene_list_share, \n",
    "                       gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = len(gene_list)\n",
    "# training_index = Sample1.obs.sample(frac=0.9, random_state=1).index\n",
    "# training_dataset = Sample1[training_index,].copy()\n",
    "\n",
    "# valid_index = Sample1.obs.index.isin(training_index)\n",
    "# valid_dataset = Sample1[~valid_index,].copy()\n",
    "\n",
    "training_dataset = Sample1.copy()\n",
    "\n",
    "valid_index = Sample1.obs.sample(frac=0.3, random_state=1).index\n",
    "valid_dataset = Sample1[valid_index,].copy()\n",
    "\n",
    "test_dataset = Sample2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_LSTM_one_output(adata=training_dataset, \n",
    "                          genes=gene_list, aug=False),\n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([7,299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "train_gen_ = train_gen.shuffle(buffer_size=100).batch(8).repeat(1).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_LSTM_one_output(adata=valid_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([7,299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "valid_gen_ = valid_gen.shuffle(buffer_size=100).batch(8).repeat(1).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_gen = tf.data.Dataset.from_generator(\n",
    "            lambda:DataGenerator_LSTM_one_output(adata=test_dataset, \n",
    "                          genes=gene_list), \n",
    "            output_types=(tf.float32, tuple([tf.float32]*n_genes)), \n",
    "            output_shapes=([7,299,299,3], tuple([1]*n_genes))\n",
    ")\n",
    "test_gen_ = test_gen.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout, Lambda, TimeDistributed, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def CNN_LSTM_NB_multiple_genes(steps_tile_shape, n_genes):\n",
    "    tile_input = Input(shape=steps_tile_shape, name=\"steps_tile_input\")\n",
    "    resnet_base = ResNet50(input_shape=steps_tile_shape[1:], weights='imagenet', include_top=False)\n",
    "    #     stage_5_start = resnet_base.get_layer(\"conv5_block1_1_conv\")\n",
    "    #     for i in range(resnet_base.layers.index(stage_5_start)):\n",
    "    #         resnet_base.layers[i].trainable = False\n",
    "\n",
    "#     for i in resnet_base.layers:\n",
    "#         i.trainable = False\n",
    "    cnn_out = resnet_base.output\n",
    "    cnn_out = GlobalAveragePooling2D()(cnn_out)\n",
    "    cnn = Model(inputs=resnet_base.input, outputs=cnn_out)\n",
    "    #     cnn = Dropout(0.5)(cnn)\n",
    "    #     cnn = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.01),\n",
    "    #                 activity_regularizer=tf.keras.regularizers.l2(0.01))(cnn)\n",
    "    # cnn = Dense(256, activation='relu')(cnn)\n",
    "    encoded_frames = TimeDistributed(cnn)(tile_input)\n",
    "    encoded_sequence = LSTM(256)(encoded_frames)\n",
    "    output_layers = []\n",
    "    for i in range(n_genes):\n",
    "        output = Dense(2)(encoded_sequence)\n",
    "        output_layers.append(Lambda(negative_binomial_layer, name=\"gene_{}\".format(i))(output))\n",
    "\n",
    "    model = Model(inputs=[tile_input], outputs=output_layers)\n",
    "    #     losses={}\n",
    "    #     for i in range(8):\n",
    "    #         losses[\"gene_{}\".format(i)] = negative_binomial_loss(i)\n",
    "    #     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "    model.compile(loss=negative_binomial_loss,\n",
    "                  optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-caution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_LSTM_NB_multiple_genes((7, 299, 299, 3), n_genes)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,\n",
    "                                            restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-gathering",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_history = model.fit(train_gen_,\n",
    "                          epochs=50,\n",
    "                          validation_data=valid_gen_,\n",
    "                          callbacks=[callback]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./LSTM_CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./LSTM_CNN_ft.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./LSTM_CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_gen_)\n",
    "from scipy.stats import nbinom\n",
    "y_preds = []\n",
    "if n_genes >1:\n",
    "    for i in range(n_genes):\n",
    "        n = test_predictions[i][:, 0]\n",
    "        p = test_predictions[i][:, 1]\n",
    "        y_pred = nbinom.mean(n, p)\n",
    "        y_preds.append(y_pred)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = np.array(y_preds).transpose()\n",
    "else:\n",
    "    n = test_predictions[:, 0]\n",
    "    p = test_predictions[:, 1]\n",
    "    y_pred = nbinom.mean(n, p)\n",
    "    test_dataset.obsm[\"predicted_gene\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_ = test_dataset[:,gene_list].copy()\n",
    "test_dataset_.X = test_dataset_.obsm[\"predicted_gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_plot(test_dataset_, genes=\"KRT5\", spot_size=8, vmin=0,vmax=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_plot(test_dataset_, genes=\"TTLL12\", spot_size=8, vmin=0,vmax=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-receiver",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in gene_list:\n",
    "#     print(i)\n",
    "#     gene_plot(test_dataset_, genes=i, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in gene_list:\n",
    "#     print(i)\n",
    "#     gene_plot(test_dataset, genes=i, spot_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-privacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-cowboy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-offset",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-pound",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-white",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
