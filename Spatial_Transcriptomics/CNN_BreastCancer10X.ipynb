{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install talos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications import Xception\n",
    "from keras.applications import NASNetLarge\n",
    "from keras.applications import DenseNet201\n",
    "from keras.applications import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the DataFrame\n",
    "df2=pd.read_csv('D:/onkar/Projects/Project_Spt.Transcriptomics/Spt_Trans/df.csv')\n",
    "#Aggregate, groupby and join\n",
    "df3=df2.groupby(['x','y']).agg('gene_name').apply(lambda x:\" \".join(list(set(x)))).reset_index()\n",
    "#Save File\n",
    "df3.to_csv('genes_file.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing the Dataframe\n",
    "df3 = pd.read_csv('genes_file.csv')\n",
    "df3=df3.drop(columns=['Unnamed: 0'])\n",
    "df3['Sno'] = np.arange(len(df3))+1\n",
    "df3['Sno'] = df3['Sno'].astype(str)\n",
    "df3['Sno']= df3['Sno'].str.zfill(4) + 'img'\n",
    "#link_to_img=df3[['x','y','Sno']]\n",
    "#link_to_img.to_csv('link_to_img.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df3.drop(columns=['x','y'])\n",
    "df3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_name</th>\n",
       "      <th>Sno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>NIBAN3 AC110285.2 PTPRC SLC26A11 SLC19A2 MESD ...</td>\n",
       "      <td>3794img</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>AC110285.2 USP28 SLC19A2 MESD MAPK1IP1L SPTLC2...</td>\n",
       "      <td>3795img</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>AC015871.1 SLC26A11 SLC36A4 SLC19A2 MESD MOB4 ...</td>\n",
       "      <td>3796img</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>AC015871.1 AC110285.2 PTPRC USP28 SLC19A2 STK3...</td>\n",
       "      <td>3797img</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>AC015871.1 PARM1 PTPRC SLC19A2 STK35 MESD MAPK...</td>\n",
       "      <td>3798img</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              gene_name      Sno\n",
       "3793  NIBAN3 AC110285.2 PTPRC SLC26A11 SLC19A2 MESD ...  3794img\n",
       "3794  AC110285.2 USP28 SLC19A2 MESD MAPK1IP1L SPTLC2...  3795img\n",
       "3795  AC015871.1 SLC26A11 SLC36A4 SLC19A2 MESD MOB4 ...  3796img\n",
       "3796  AC015871.1 AC110285.2 PTPRC USP28 SLC19A2 STK3...  3797img\n",
       "3797  AC015871.1 PARM1 PTPRC SLC19A2 STK35 MESD MAPK...  3798img"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.read_csv('Gene_list_df5.csv')\n",
    "df5=df5.drop(columns=['Unnamed: 0'])\n",
    "df5.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Vals=pd.read_csv('link_to_img.csv')\n",
    "Vals['left']=Vals['x']-70\n",
    "Vals['up']=Vals['y']-70\n",
    "Vals['right']=Vals['x']+70\n",
    "Vals['down']=Vals['y']+70\n",
    "Vals=Vals.values\n",
    "x_offset = Vals[:,4] \n",
    "Y_offset = Vals[:,5]\n",
    "width = Vals[:,6] \n",
    "height = Vals[:,7]\n",
    "box = (Y_offset, x_offset, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n",
    "image=Image.open('D:/onkar/Projects/Project_Spt.Transcriptomics/Input_files/V1_Breast_Cancer_Block_A_Section_1_image.tif')\n",
    "#Transpose\n",
    "numpy_array = np.array(box)\n",
    "transpose = numpy_array.T\n",
    "box = transpose.tolist()\n",
    "box\n",
    "#Save Images\n",
    "imgno=1\n",
    "for i in range(0,len(box)):\n",
    "    crop = image.crop(box[i])\n",
    "    crop.save(str(imgno).zfill(4)+'img.tif')\n",
    "    imgno=imgno+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Sharpened Images\n",
    "from PIL import ImageFilter\n",
    "from PIL import Image\n",
    "import glob\n",
    "imgnoo=1\n",
    "for img in glob.glob(\"C:/Users/Onkar/Untitled Folder/Trainimg/*.tif\"):\n",
    "    img=Image.open(img)\n",
    "    sharpened1 = img.filter(ImageFilter.SHARPEN)\n",
    "    sharpened2 = sharpened1.filter(ImageFilter.SHARPEN)\n",
    "    sharpened2.save(str(imgnoo).zfill(4)+'img.tif')\n",
    "    imgnoo=imgnoo+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Smooth Images\n",
    "from PIL import ImageFilter\n",
    "from PIL import Image\n",
    "import glob\n",
    "imgnoo=1\n",
    "for img in glob.glob(\"C:/Users/Onkar/Untitled Folder/Trainimg/*.tif\"):\n",
    "    img=Image.open(img)\n",
    "    smoothenedImage = img.filter(ImageFilter.SMOOTH)\n",
    "    moreSmoothenedImage = img.filter(ImageFilter.SMOOTH_MORE)\n",
    "    moreSmoothenedImage.save(str(imgnoo).zfill(4)+'img.tif')\n",
    "    imgnoo=imgnoo+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Resize Images -> Resnet\n",
    "from PIL import ImageFilter\n",
    "from PIL import Image\n",
    "import glob\n",
    "imgnoo=1\n",
    "for img in glob.glob(\"C:/Users/Onkar/Untitled Folder/Trainimg/*.tif\"):\n",
    "    img=Image.open(img)\n",
    "    resized=img.resize((331,331))\n",
    "    resized.save(str(imgnoo).zfill(4)+'img.tif')\n",
    "    imgnoo=imgnoo+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encode and Mapping X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping of tags to integers given the loaded mapping file\n",
    "def create_tag_mapping(df3):\n",
    "    # create a set of all known tags\n",
    "    labels = set()\n",
    "    for i in range(len(df3)):\n",
    "        # convert spaced separated tags into an array of tags\n",
    "        gene_name = df3['gene_name'][i].split(' ')\n",
    "        # add tags to the set of known labels\n",
    "        labels.update(gene_name)\n",
    "    # convert set of labels to a list to list\n",
    "    labels = list(labels)\n",
    "    # order set alphabetically\n",
    "    labels.sort()\n",
    "    # dict that maps labels to integers, and the reverse\n",
    "    labels_map = {labels[i]:i for i in range(len(labels))}\n",
    "    inv_labels_map = {i:labels[i] for i in range(len(labels))}\n",
    "    return labels_map, inv_labels_map\n",
    "# create a mapping of filename to tags\n",
    "def create_file_mapping(df3):\n",
    "    mapping = dict()\n",
    "    for i in range(len(df3)):\n",
    "        name, gene_name = df3['Sno'][i], df3['gene_name'][i]\n",
    "        mapping[name] = gene_name.split(' ')\n",
    "    return mapping\n",
    "# create a one hot encoding for one list of tags\n",
    "def one_hot_encode(gene_name, mapping):\n",
    "    # create empty vector\n",
    "    encoding = zeros(len(mapping), dtype='uint8')\n",
    "    # mark 1 for each tag in the vector\n",
    "    for tag in gene_name:\n",
    "        encoding[mapping[tag]] = 1\n",
    "    return encoding\n",
    "def load_dataset(path, file_mapping, tag_mapping):\n",
    "    photos, targets = list(), list()\n",
    "    # enumerate files in the directory\n",
    "    for filename in listdir(folder):\n",
    "        # load image\n",
    "        photo = load_img(path + filename, target_size=(140,140))\n",
    "        # convert to numpy array\n",
    "        photo = img_to_array(photo, dtype='uint8')\n",
    "        # get tags\n",
    "        gene_name = file_mapping[filename[:-4]]\n",
    "        # one hot encode tags\n",
    "        target = one_hot_encode(gene_name, tag_mapping)\n",
    "        # store\n",
    "        photos.append(photo)\n",
    "        targets.append(target)\n",
    "    X = asarray(photos, dtype='uint8')\n",
    "    y = asarray(targets, dtype='uint8')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3798, 140, 140, 3) (3798, 24916)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# save both arrays to one file in compressed format\\n#savez_compressed('planet_data.npz', X, y)\\n#X = np.delete(X, slice(3551,3798), axis=0)\\n#y = np.delete(y, slice(3551,3798), axis=0)\\n#file_mapping\\n\\narr2D1 = np.delete(X, slice(1,46), axis=0)\\narr2Dy1 = np.delete(y, slice(1,46), axis=0)\\nprint(arr2D1.shape, arr2Dy1.shape)\\n\\nX = np.delete(arr2D1, slice(3049,3753), axis=0)\\ny = np.delete(arr2Dy1, slice(3049,3753), axis=0)\\nprint(X.shape, y.shape)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and prepare planet dataset and save to file\n",
    "from os import listdir\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "mapping_csv = df5\n",
    "# create a mapping of tags to integers\n",
    "tag_mapping, _ = create_tag_mapping(mapping_csv)\n",
    "# create a mapping of filenames to tag lists\n",
    "file_mapping = create_file_mapping(mapping_csv)\n",
    "folder = 'C:/Users/Onkar/UntitledFolder/Trainimg_breast2/'\n",
    "X, y = load_dataset(folder, file_mapping, tag_mapping)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "'''\n",
    "# save both arrays to one file in compressed format\n",
    "#savez_compressed('planet_data.npz', X, y)\n",
    "#X = np.delete(X, slice(3551,3798), axis=0)\n",
    "#y = np.delete(y, slice(3551,3798), axis=0)\n",
    "#file_mapping\n",
    "\n",
    "arr2D1 = np.delete(X, slice(1,46), axis=0)\n",
    "arr2Dy1 = np.delete(y, slice(1,46), axis=0)\n",
    "print(arr2D1.shape, arr2Dy1.shape)\n",
    "\n",
    "X = np.delete(arr2D1, slice(3049,3753), axis=0)\n",
    "y = np.delete(arr2Dy1, slice(3049,3753), axis=0)\n",
    "print(X.shape, y.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the data for Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3798, 335)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import savez_compressed\n",
    "indices = list(np.where((y.sum(axis=0)<3600)))\n",
    "a = np.delete(y, indices, 1)\n",
    "#a1 = a.sum(axis=0)/3407\n",
    "#b= a*a1\n",
    "#b\n",
    "X=X/255\n",
    "#savez_compressed('planet_data1.npz', X, a)\n",
    "#X=X/255\n",
    "savez_compressed('planet_data_trail.npz', X, a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # load dataset\n",
    "    data = load('planet_data_trail.npz')\n",
    "    X, y = data['arr_0'], data['arr_1']\n",
    "    # separate into train and test datasets\n",
    "    trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "    return trainX, trainY, testX, testY\n",
    "    print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta(y_true, y_pred, beta=2):\n",
    "    # clip predictions\n",
    "    y_pred = backend.clip(y_pred, 0, 1)\n",
    "    # calculate elements\n",
    "    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "    # calculate precision\n",
    "    p = tp / (tp + fp + backend.epsilon())\n",
    "    # calculate recall\n",
    "    r = tp / (tp + fn + backend.epsilon())\n",
    "    # calculate fbeta, averaged across each class\n",
    "    bb = beta ** 2\n",
    "    #bb1 = (beta-1) ** 2\n",
    "    fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "    #fbeta_score1 = backend.mean((1 + bb1) * (p * r) / (bb1 * p + r + backend.epsilon()))\n",
    "    return fbeta_score #, fbeta_score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Gene Names from the tags for low counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_left=_\n",
    "for i in indices[0]:\n",
    "    if i in genes_left.keys():\n",
    "        del genes_left[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Between Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTB</th>\n",
       "      <th>ACTG1</th>\n",
       "      <th>ADAR</th>\n",
       "      <th>ADIRF</th>\n",
       "      <th>AEBP1</th>\n",
       "      <th>AGR2</th>\n",
       "      <th>ANAPC11</th>\n",
       "      <th>APOC1</th>\n",
       "      <th>APOE</th>\n",
       "      <th>APRT</th>\n",
       "      <th>...</th>\n",
       "      <th>UBC</th>\n",
       "      <th>UBL5</th>\n",
       "      <th>UQCR11</th>\n",
       "      <th>UQCRB</th>\n",
       "      <th>UQCRQ</th>\n",
       "      <th>VIM</th>\n",
       "      <th>VMP1</th>\n",
       "      <th>XBP1</th>\n",
       "      <th>YWHAZ</th>\n",
       "      <th>ZNF703</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001img</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002img</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003img</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004img</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0005img</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ACTB  ACTG1  ADAR  ADIRF  AEBP1  AGR2  ANAPC11  APOC1  APOE  APRT  \\\n",
       "Sno                                                                          \n",
       "0001img     1      1     1      1      1     1        1      1     1     1   \n",
       "0002img     1      1     1      1      1     1        0      1     1     1   \n",
       "0003img     1      1     1      1      1     1        1      1     1     1   \n",
       "0004img     1      1     1      1      1     1        1      1     1     1   \n",
       "0005img     1      1     1      1      0     1        1      1     1     1   \n",
       "\n",
       "         ...  UBC  UBL5  UQCR11  UQCRB  UQCRQ  VIM  VMP1  XBP1  YWHAZ  ZNF703  \n",
       "Sno      ...                                                                   \n",
       "0001img  ...    1     1       1      0      1    1     1     1      1       1  \n",
       "0002img  ...    1     1       1      1      1    1     1     1      1       1  \n",
       "0003img  ...    1     1       1      1      1    1     1     1      1       1  \n",
       "0004img  ...    1     1       1      1      1    1     1     1      1       1  \n",
       "0005img  ...    1     1       1      1      1    1     1     1      1       1  \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes=genes_left.values()\n",
    "list(genes)\n",
    "a1.columns=genes\n",
    "a1['Sno'] = df5['Sno']\n",
    "#a1['Sno'] = np.arange(len(df5))+1\n",
    "#a1['Sno'] = a1['Sno'].astype(str)\n",
    "#a1['Sno']= a1['Sno'].str.zfill(4) + 'img'\n",
    "a1=a1.set_index('Sno')\n",
    "#a1 = a1.drop(labels='Sno', axis=1)\n",
    "a1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "col_Trues=a1.columns.to_numpy()\n",
    "col_Trues=asarray(col_Trues)\n",
    "save('col_Trues.npy', col_Trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highly expressed genes\n",
    "corr_matrix=a1.corr()\n",
    "#corr_matrix.to_csv('Correlation.csv')\n",
    "import seaborn as sb\n",
    "sb.heatmap(corr_matrix, vmin = .75, square = True)\n",
    "plt.show()\n",
    "#Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(20,20))\n",
    "a1_sum = a1.sum()\n",
    "a1_sum.plot(kind='barh')\n",
    "#fig=go.Figure(data=go.Bar(a1_sum.plot()))\n",
    "#fig.show()\n",
    "'''\n",
    "import seaborn as sns\n",
    "categories = list(a1.columns.values)\n",
    "sns.set(font_scale = 2)\n",
    "plt.figure(figsize=(15,8))\n",
    "ax= sns.barplot(categories, a1.iloc[:,0:].sum().values)\n",
    "plt.title(\"Comments in each category\", fontsize=24)\n",
    "plt.ylabel('Number of comments', fontsize=18)\n",
    "plt.xlabel('Comment Type ', fontsize=18)\n",
    "#adding the text labels\n",
    "rects = ax.patches\n",
    "labels = a1.iloc[:,2:].sum().values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "from keras.layers import BatchNormalization\n",
    "def define_model(in_shape=(190,314, 3), out_shape=4316):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(out_shape, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Fbeta')\n",
    "    pyplot.plot(history.history['fbeta'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# baseline model with dropout on the planet dataset\n",
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "#from keras.layers import Merge\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications import Xception\n",
    "from keras.applications import NASNetLarge\n",
    "from keras.applications import DenseNet201\n",
    "from keras.applications import InceptionResNetV2\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    # prepare iterators\n",
    "    train_it = datagen.flow(trainX, trainY, batch_size=128)\n",
    "    test_it = datagen.flow(testX, testY, batch_size=128)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    history = model.fit(train_it, steps_per_epoch=len(train_it),\n",
    "    validation_data=test_it, validation_steps=len(test_it), epochs=1, verbose=1)\n",
    "    # evaluate model\n",
    "    loss, fbeta = model.evaluate(test_it, steps=len(test_it), verbose=1)\n",
    "    print('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "    # learning curves\n",
    "    #summarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "48/48 [==============================] - 55s 1s/step - loss: 0.2777 - fbeta: 0.9043 - val_loss: 0.1058 - val_fbeta: 0.9949\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 62s 1s/step - loss: 0.1122 - fbeta: 0.9952 - val_loss: 0.1016 - val_fbeta: 0.9948\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 62s 1s/step - loss: 0.1072 - fbeta: 0.9954 - val_loss: 0.1010 - val_fbeta: 0.9949\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 61s 1s/step - loss: 0.1053 - fbeta: 0.9955 - val_loss: 0.1040 - val_fbeta: 0.9949\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 60s 1s/step - loss: 0.1074 - fbeta: 0.9956 - val_loss: 0.1069 - val_fbeta: 0.9949\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 71s 1s/step - loss: 0.1068 - fbeta: 0.9955 - val_loss: 0.1055 - val_fbeta: 0.9949\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 78s 2s/step - loss: 0.1050 - fbeta: 0.9955 - val_loss: 0.1048 - val_fbeta: 0.9948\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 77s 2s/step - loss: 0.1049 - fbeta: 0.9955 - val_loss: 0.1048 - val_fbeta: 0.9949\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 76s 2s/step - loss: 0.1046 - fbeta: 0.9955 - val_loss: 0.1014 - val_fbeta: 0.9948\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 77s 2s/step - loss: 0.1012 - fbeta: 0.9956 - val_loss: 0.1031 - val_fbeta: 0.9948\n",
      "12/12 [==============================] - 12s 971ms/step - loss: 0.1031 - fbeta: 0.9949\n",
      "> loss=0.103, fbeta=0.995\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiS0lEQVR4nO3de5SddX3v8fdnbpnc7xdIYhIk0ESKAdMcKNVVy1GJoFhPtUCRHg4UrWKxR63gqtKerq7D6lKPcIqkVGileEOUlqOpRihIbZGQQLiEMEMICRmS2QyBJHuSTOb2PX/sJ8meyZ6ZPWGe2bP3/rwWWcxz/+49M/szv+f5Pb9HEYGZmVl/NaUuwMzMxiYHhJmZFeSAMDOzghwQZmZWkAPCzMwKckCYmVlBDggzMyvIAWFmZgU5IMxKRDn+HbQxyz+cVvUkXS/pRUlZSc9J+t28ZX8kaUvesrOT+Qsl/UhSm6Q9kv42mf8Xku7O236xpJBUl0w/LOmvJf0HcBA4RdKVecfYJunj/eq7WNImSfuTOi+Q9BFJG/ut91lJ/5zaG2VVxwFhBi8C7wSmAn8J3C3pJEkfAf4CuAKYAnwQ2COpFvgxsANYDMwHvjeM430MuAaYnOzjVeCi5BhXAv8nL4hWAXcBnwemAe8CtgP3A0skLcvb7+XAPw3nhZsNxgFhVS8ifhARuyKiNyK+D7wArAKuBv4mIh6PnK0RsSNZdjLw+Yg4EBEdEfHLYRzyHyNic0R0R0RXRPwkIl5MjvELYB25wAK4CrgzIn6e1PdKRDwfEYeB75MLBSS9jVxY/XgE3hIzwAFhhqQrklM4eyXtBc4AZgELybUu+lsI7IiI7hM85M5+x18t6VeSXk+O//7k+EeOVagGgG8Bl0kSuVbJPUlwmI0IB4RVNUmLgL8HrgVmRsQ04FlA5D7I31pgs53AW45cV+jnADAhb3pegXWODqEsaRzwQ+ArwNzk+GuT4x85VqEaiIhfAZ3kWhuX4dNLNsIcEFbtJpL7wG4DkHQluRYEwDeBz0l6R9Lj6NQkUNYDu4GbJE2U1CjpvGSbTcC7JL1F0lTghiGO3wCMS47fLWk18N685XcAV0o6X1KNpPmSfi1v+V3A3wLdwzzNZTYkB4RVtYh4Dvgq8CiQAX4d+I9k2Q+Avwa+A2SBfwZmREQP8AHgVOBloAX4/WSbn5O7NvA0sJEhrglERBb4E+Ae4A1yLYH785avJ7lwDewDfgEsytvFP5ELNLcebMTJDwwyK1+SxpPrBXV2RLxQ6nqssrgFYVbe/hh43OFgaUgtICTdKelVSc8OsFySbpG0VdLTR/p9J8sukNSULLs+rRrNypmk7cB1wGdLXIpVqDRbEP8IXDDI8tXA0uTfNcBtAMlNSLcmy5cDl0panmKdZmUpIhZHxKKIeLLUtVhlSi0gIuIR4PVBVrkYuCu5OehXwDRJJ5G7CWlrRGyLiE5yd6henFadZmZWWKF+3KNlPn1vGGpJ5hWa/1+K2eGsWbNi8eLFI1WfmVnF27hx42sRMbvQslIGhArMi0HmF96JdA25U1S85S1vYcOGDSNTnZlZFZC0Y6BlpezF1EJuGIEjFgC7BplfUETcHhErI2Ll7NkFQ9DMzE5AKQPifuCKpDfTOcC+iNgNPA4slbREUgNwCXk3DpmZ2ehI7RSTpO8Cvw3MktQC3AjUA0TEGnLjzbwf2EpuXPwrk2Xdkq4FfgbUkhvJcnNadZqZWWGpBUREXDrE8gA+NcCyteQC5E3r6uqipaWFjo6OkdjdmNXY2MiCBQuor68vdSlmViFKeZF6VLS0tDB58mQWL15MblTkyhMR7Nmzh5aWFpYsWVLqcsysQlT8UBsdHR3MnDmzYsMBQBIzZ86s+FaSmY2uig8IoKLD4YhqeI1mNroq/hST5U5BdfcGPb1BV08vPb256e6eoLu3N/l/3+WRbJf7/yBfEyT/HZ3uzVuHZF5uOwbf75H1knVI5vdGFNg2f16yTrJBDLAd9J+Xm6bf/vLXIX+0Ywnl/odQ8v9kOgnoIzl93PJkOrdO/n7y5h2ZHuA4ydt59H1JXvGxWvPqjWNfHvte5M/Le0/yNy20z2PbjM2Rn8Wx9/7Y+3n8sqPrH/leHbduoe/jsZUG2nf+e5ab5oS/D/nvdZ/9cfz359g2wfiGOq76rZE/veyAAIjeAjML/EV+An+l7927l+985zt88pOfHLyECHbv66C7N4gI/vslH+bmNXcyeeq0fh+2/T98j/0w7d7XwR/81c/pTj7ku5IP/Z7esfmLPTKOf20qOO94hdcrME99fyH7Hn3gn4nBlw1s4O3cSrTCZk0a54BIze5ngEIhUayBf3H37tzFN275Gp/83fP6zO/p6aG2tu/bP6c3IPkr6IFv/Q3wGnS+NsiR+v8F2Mavei9HCqgF1R5bT3nrq9/2OvrpN7aCpNCHtR1zNEiO/uEy2HSx61Jgef916ZeYUWDeUOsU2maAdQaad9RQr63YdY7Nj2L2VfCPyP715uv/+5e3bsHxI4bx8z9xFvBU8esXyQEBMGXeoN/Q/l8OMKPgNtf/zY28uKOFFe+9jPr6eiZNnMBJ8+aw6ZnneO6xf+NDl13Fzld2c6ijg6uv/EOuu+YKamvE4l8/lw0P/4T29gOs/sgV/NY5v8F/rt/I/JPm8i/fuYPx4yccd2SNO0TDuR9PJor50Bhkeqwo2GrT8NcZ1npF1AVD5OkgCwf9xR+oqXL8B6v6TfdffnR6sGWF6hlq20I/K0N+8A62TrH7GSyohhEuRbz+wu/tQPsY4Aem2J+3AdcdxvoNkwbY/s2pqoD4y/+3med27R/RfS4/eQo3fuBtAy6/6as382zTRWx65lkefvhhLrzwQp599tmj3VHv/KfvMmPGDF7c/ToXvPu3uOKqjzNr+iyoqYUpJ0NNOy+8+BLf/f4P+PsVK/joRz/KDx94jMsvv/z4g43fD+/9qxF9fWZWvaoqIMaCVatW9blX4ZZbbuG+++6js7uX1l2vsHXrVmbNmtVnmyVLlrBixQoA3vGOd7B9+/ZRrNjMqlVVBcRgf+mPlokTJx79+uGHH+aBBx7g0UcfZfvebq766EUF72UYN27c0a9ra2s5dOjQqNRqZtWtKu6DKKXJkyeTzWYLLtu3bx/Tp0+nYVwjLzQ/z5Mb1o9ydWZmA6uqFkQpzJw5k/POO48zzjiD8ePHM3fu3KPLLrjgAtasWcOKFW/n5EVv5TdWFfVcJDOzUaH+N8uUs5UrV0b/BwZt2bKFZcuWlaii4rzWfphdew+xbN4U6utOvFFXDq/VzMYWSRsjYmWhZT7FNAZ0dPVQWyPqasdYF1Mzq2oOiDHgcFcvjXW1Hk/JzMYUB0SJRQQd3T001vtbYWZjiz+VSqyrJzdW0rj62qFXNjMbRQ6IEjvc3QNAowPCzMYYB0SJdXQlAfEmei+ZmaXBn0op27t3L9/4xjcGXN7R1UtdbQ11tcd/K77+9a9z8ODBNMszMxuQAyJlQwdEz4CtBweEmZWS76RO2fXXX8+LL77IihUreM973sOcOXO45557OHz4MB/60If46Mc/SyNdXHjh79PS0kJPTw9f+tKXyGQy7Nq1i3e/+93MmjWLhx56qNQvxcyqTHUFxL9eD63PjOw+5/06rL5pwMU33XQTzz77LJs2bWLdunXce++9rF+/nojgog98gCWP/hIdznLyySfzk5/8BMiN0TR16lS+9rWv8dBDDx03uquZ2WjwKaZRtG7dOtatW8dZZ53F2WefzfPPN7Fj+zbOevuZPPDAA3zhC1/g3//935k6dWqpSzUzq7IWxCB/6Y+GiOCGG27g4x/PPfUts7+DzP4O3nbyVDZu3MjatWu54YYbeO9738uXv/zlktZqZuYWRMryh/t+3/vex5133kl7ezsAO17eSfaNPWRadzNhwgQuv/xyPve5z/HEE08ct62Z2WirrhZECeQP97169Wouu+wyzj33XADqxo3n67fdwTPPbOXzn/88NTU11NfXc9tttwFwzTXXsHr1ak466SRfpDazUefhvkukN4LNr+xn1uQGTpo6fkT2OVZfq5mNXR7uewzq7O4lCA+xYWZjlgOiRI4NseGAMLOxqSoCYiyeRuvo6kWIcSM0BtNYfI1mVt4qPiAaGxvZs2fPmPsA7ejqoaGuhpqaN/+QoIhgz549NDY2jkBlZmY5Fd+LacGCBbS0tNDW1lbqUvpo3ddBfV0NvW80jMj+GhsbWbBgwYjsy8wMqiAg6uvrWbJkSanL6ONQZw/vv/GnXHf+Uj6z8rRSl2NmVlDFn2Iai7a+2k4EnD53cqlLMTMbUKoBIekCSU2Stkq6vsDy6ZLuk/S0pPWSzshb9qeSNkt6VtJ3JVXMCfamTO7u6NPmOSDMbOxKLSAk1QK3AquB5cClkpb3W+2LwKaIOBO4Arg52XY+8CfAyog4A6gFLkmr1tHWnMnSUFfDohkTSl2KmdmA0mxBrAK2RsS2iOgEvgdc3G+d5cCDABHxPLBY0txkWR0wXlIdMAHYlWKto6qpNcupsycVfIqcmdlYkeYn1HxgZ950SzIv31PAhwEkrQIWAQsi4hXgK8DLwG5gX0SsK3QQSddI2iBpw1jrqTSQ5kyW0316yczGuDQDolAH//43I9wETJe0Cfg08CTQLWk6udbGEuBkYKKkywsdJCJuj4iVEbFy9uzZI1Z8WvYd6mL3vg5O8wVqMxvj0uzm2gIszJteQL/TRBGxH7gSQJKAl5J/7wNeioi2ZNmPgN8E7k6x3lHxQnKB+vR5k0pciZnZ4NJsQTwOLJW0RFIDuYvM9+evIGlasgzgauCRJDReBs6RNCEJjvOBLSnWOmqO9mByC8LMxrjUWhAR0S3pWuBn5Hoh3RkRmyV9Ilm+BlgG3CWpB3gOuCpZ9pike4EngG5yp55uT6vW0dTcmmViQy3zp43MEN9mZmlJ9U7qiFgLrO03b03e148CSwfY9kbgxjTrK4WmTJbT5k0m1zAyMxu73M9yFEUETa1Z30FtZmXBATGKXmvv5I2DXb7+YGZlwQExipqP9mByQJjZ2OeAGEVNre7BZGblwwExipozWWZMbGDWpJF5BoSZWZocEKOoKZPltLmT3IPJzMqCA2KURATN7sFkZmXEATFKXtl7iAOdPX4GhJmVDQfEKDnag8ktCDMrEw6IUdLU2g7AUgeEmZUJB8Qoac5kOWlqI1PH15e6FDOzojggRklTa9b3P5hZWXFAjILunl62trX7DmozKysOiFGw4/WDdHb3ugVhZmXFATEKmlvdg8nMyo8DYhQ0ZbJIcOocP2bUzMqHA2IUNGeyLJoxgfENtaUuxcysaA6IUeAeTGZWjhwQKevo6mH7noPuwWRmZccBkbJtbQfo6Q23IMys7DggUuanyJlZuXJApKwpk6W+ViyeObHUpZiZDYsDImXNrVlOmTWJhjq/1WZWXvyplbKmTNbPgDCzsuSASFH74W5a3jjE6XN9g5yZlR8HRIpeSC5QuweTmZUjB0SK3IPJzMqZAyJFTa3tNNbXsHD6hFKXYmY2bA6IFDVnckNs1NSo1KWYmQ2bAyJFTRmPwWRm5csBkZLXD3TSlj3sZ0CYWdlyQKTkyAVq3wNhZuXKAZGSoz2Y3IIwszLlgEhJU2uWKY11zJ0yrtSlmJmdkFQDQtIFkpokbZV0fYHl0yXdJ+lpSeslnZG3bJqkeyU9L2mLpHPTrHWkNWeynD5vMpJ7MJlZeUotICTVArcCq4HlwKWSlvdb7YvApog4E7gCuDlv2c3ATyPi14C3A1vSqnWkRYSfImdmZS/NFsQqYGtEbIuITuB7wMX91lkOPAgQEc8DiyXNlTQFeBdwR7KsMyL2pljriMrsP8z+jm7fQW1mZS3NgJgP7Mybbknm5XsK+DCApFXAImABcArQBvyDpCclfVNSwQcqSLpG0gZJG9ra2kb6NZyQJo/BZGYVIM2AKHTyPfpN3wRMl7QJ+DTwJNAN1AFnA7dFxFnAAeC4axgAEXF7RKyMiJWzZ88eqdrflOZWB4SZlb+6FPfdAizMm14A7MpfISL2A1cCKHc196Xk3wSgJSIeS1a9lwECYixqymSZPXkcMyY2lLoUM7MTlmYL4nFgqaQlkhqAS4D781dIeiod+RS9GngkIvZHRCuwU9LpybLzgedSrHVENWeyvv/BzMpeai2IiOiWdC3wM6AWuDMiNkv6RLJ8DbAMuEtSD7kAuCpvF58Gvp0EyDaSlsZY19sbNGeyXLZqUalLMTN7U9I8xURErAXW9pu3Ju/rR4GlA2y7CViZZn1p2PnGQTq6ejl9np8iZ2blzXdSj7AmX6A2swrhgBhhR8ZgWuqAMLMy54AYYU2ZdhZMH8+kcamevTMzS50DYoQ1t7oHk5lVBgfECOrs7uXFtnY/A8LMKoIDYgRt33OA7t5wC8LMKkLRJ8olzQEaj0xHxMupVFTG3IPJzCrJkC0ISR+U9AK5ITB+AWwH/jXluspScyZLbY04ZXbBcQXNzMpKMaeY/go4B2iOiCXkhr34j1SrKlNNrVkWz5xAY31tqUsxM3vTigmIrojYA9RIqomIh4AV6ZZVno48Rc7MrBIUcw1ir6RJwCPkxkZ6ldyQ3JbnUGcPO14/yIfO6v/ICzOz8lRMC+Ji4CDwp8BPgReBi9IsqhxtfbWdCNyDycwqRjEB8eWI6I2I7oj4VkTcAnwh7cLKzdGnyPkUk5lViGIC4j0F5q0e6ULKXXMmS0NdDYtmTCh1KWZmI2LAaxCS/hj4JHCKpKfzFk3GvZiO09Sa5dTZk6ir9b2HZlYZBrtI/R1y9zv8b/o+7jMbEa+nWlUZas5kOeeUmaUuw8xsxAz4525E7IuI7RFxKblnS/9OROwg1911yahVWAb2Hepi974O30FtZhWlmDupbyR3UfqGZFYDcHeaRZWbF5IL1H6KnJlVkmJOmP8u8EHgAEBE7CJ3HcISR3swuQVhZhWkmIDojIgAAkCSBxrqp7k1y8SGWuZPG1/qUszMRkwxAXGPpL8Dpkn6I+AB4O/TLau8NGWynDZvMpJKXYqZ2YgZcqiNiPiKpPcA+4HTyN049/PUKysTEUFTa5b3vW1eqUsxMxtRxT4P4hlgPLnTTM+kV075ea29kzcOdvn6g5lVnGJ6MV0NrAc+DPwe8CtJ/yPtwspF89EeTA4IM6ssxbQgPg+clQz5jaSZwH8Cd6ZZWLnwU+TMrFIVc5G6BcjmTWeBnemUU36aM1lmTGxg1qSGUpdiZjaiBhuL6X8mX74CPCbpX8hdg7iY3CknI+nBNHeSezCZWcUZrAVxFrkb4j4A/DPJfRDAvwC70y2rPEQEza1ZPwPCzCrSYNcg3gH8OfDfgP87OuWUl1f2HuJAZ4+fAWFmFWmwgFhD7glyS4ANefNFrjVxSop1lYWjPZjcgjCzCjTYaK63RMQy4B8i4pS8f0siourDAaCptR2ApQ4IM6tAQ/Ziiog/Ho1CylFzJstJUxuZOr6+1KWYmY04P/7sTWhqzfr+BzOrWA6IE9Td08vWtnbfQW1mFcsBcYJ2vH6Qzu5etyDMrGKlGhCSLpDUJGmrpOsLLJ8u6T5JT0taL+mMfstrJT0p6cdp1nkimlvdg8nMKltqASGpFrgVWA0sBy6VtLzfal8ENkXEmcAVwM39ll8HbEmrxjejKZNFglPn+DGjZlaZ0mxBrAK2RsS2iOgEvkdumI58y4EHASLieWCxpLkAkhYAFwLfTLHGE9acybJoxgTGN9SWuhQzs1SkGRDz6TuoX0syL99T5IYRR9IqYBGwIFn2deDPgN7BDiLpGkkbJG1oa2sbgbKL4x5MZlbp0gyIQqPXRb/pm4DpkjYBnwaeBLolXQS8GhEbhzpIRNweESsjYuXs2bPfbM1F6ejqYfueg+7BZGYVrdgnyp2IFmBh3vQCYFf+ChGxH7gSQLnhUF9K/l0CfFDS+4FGYIqkuyPi8hTrLdq2tgP09IZbEGZW0dJsQTwOLJW0RFIDuQ/9+/NXkDQtWQZwNfBIROyPiBsiYkFELE62+7exEg7gp8iZWXVIrQUREd2SrgV+BtQCd0bEZkmfSJavAZYBd0nqAZ4DrkqrnpHUlMlSXysWz5xY6lLMzFKT5ikmImItsLbfvDV5Xz8KLB1iHw8DD6dQ3glrbs1yyqxJNNT5PkMzq1z+hDsBTZmsnwFhZhXPATFM7Ye7aXnjEKfP9Q1yZlbZHBDD9EJygdo9mMys0jkghsk9mMysWjgghqmptZ3G+hoWTp9Q6lLMzFLlgBim5kxuiI2amkI3ipuZVQ4HxDA1ZTwGk5lVBwfEMLx+oJO27GE/A8LMqoIDYhiOXKD2PRBmVg0cEMNwtAeTWxBmVgUcEMPQ1JplSmMdc6eMK3UpZmapc0AMQ3Mmy+nzJpMbmdzMrLI5IIoUEX6KnJlVFQdEkTL7D7O/o9t3UJtZ1XBAFKnJYzCZWZVxQBSpudUBYWbVxQFRpKZMltmTxzFjYsPQK5uZVQAHRJGaM1nf/2BmVcUBUYTe3qA5k2WpHxJkZlXEAVGEnW8cpKOr1y0IM6sqDogiNLV6DCYzqz4OiCIcGYNp6RyfYjKz6uGAKEJTpp3508YzubG+1KWYmY0aB0QRmluzvoPazKqOA2IInd29vNjW7hvkzKzqOCCGsH3PAbp7g9Pn+fqDmVUXB8QQmjzEhplVKQfEEJozWWoEb53tFoSZVRcHxBCaWrMsnjWRxvraUpdiZjaqHBBD8BhMZlatHBCDONTZw47XD/r6g5lVJQfEILa+2k4EvgfCzKqSA2IQfoqcmVUzB8QgmjNZGmprWDxzQqlLMTMbdakGhKQLJDVJ2irp+gLLp0u6T9LTktZLOiOZv1DSQ5K2SNos6bo06xxIU2uWt86ZRF2tc9TMqk9qn3ySaoFbgdXAcuBSScv7rfZFYFNEnAlcAdyczO8GPhsRy4BzgE8V2DZ1uR5Mvv/BzKpTmn8arwK2RsS2iOgEvgdc3G+d5cCDABHxPLBY0tyI2B0RTyTzs8AWYH6KtR5n36Eudu/r8DMgzKxqpRkQ84GdedMtHP8h/xTwYQBJq4BFwIL8FSQtBs4CHit0EEnXSNogaUNbW9vIVA68kFyg9j0QZlat0gwIFZgX/aZvAqZL2gR8GniS3Oml3A6kScAPgc9ExP5CB4mI2yNiZUSsnD179ogUDu7BZGZWl+K+W4CFedMLgF35KyQf+lcCSBLwUvIPSfXkwuHbEfGjFOssqLk1y8SGWuZPGz/ahzYzGxPSbEE8DiyVtERSA3AJcH/+CpKmJcsArgYeiYj9SVjcAWyJiK+lWOOAmjJZls6dTE1NoYaQmVnlSy0gIqIbuBb4GbmLzPdExGZJn5D0iWS1ZcBmSc+T6+10pDvrecDHgN+RtCn59/60ai1QO02tHoPJzKpbmqeYiIi1wNp+89bkff0osLTAdr+k8DWMUfFaeydvHOxyDyYzq2q+A6wA92AyM3NAFHS0B5MfM2pmVcwBUUBzJsv0CfXMnjSu1KWYmZWMA6KAptYsp82dTK4zlZlZdXJA9BMRNGfa/QwIM6t6Doh+du3roP1wt++gNrOq54Dop7k16cHkFoSZVTkHRD9HezDNcUCYWXVzQPTT3Jpl3pRGpk6oL3UpZmYl5YDopymT9R3UZmY4IPro6Q1eeLXdT5EzM8MB0ceOPQfo7O51DyYzMxwQfTRn3IPJzOwIB0SeptZ2JDh1jk8xmZk5IPI0Z7K8ZcYEJjSkOgq6mVlZcEDkacpkff3BzCzhgEgc7u7hpdcO+BkQZmYJB0RiW9sBenrD90CYmSUcEIlmP0XOzKwPB0SiqTVLXY1YMmtiqUsxMxsTHBCJ5kyWU2ZPpKHOb4mZGTggjnIPJjOzvhwQwIHD3ex8/ZCvP5iZ5XFAAC+82g7gHkxmZnkcEOQ9Rc4tCDOzoxwQ5K4/NNbXsHDGhFKXYmY2ZjggyPVgWjpnMrU1KnUpZmZjhgOC3D0Q7sFkZtZX1QdEV08v71w6m3cunVXqUszMxpSqH9e6vraGr3707aUuw8xszKn6FoSZmRXmgDAzs4IcEGZmVpADwszMCko1ICRdIKlJ0lZJ1xdYPl3SfZKelrRe0hnFbmtmZulKLSAk1QK3AquB5cClkpb3W+2LwKaIOBO4Arh5GNuamVmK0mxBrAK2RsS2iOgEvgdc3G+d5cCDABHxPLBY0twitzUzsxSlGRDzgZ150y3JvHxPAR8GkLQKWAQsKHJbku2ukbRB0oa2trYRKt3MzNK8Ua7QwEbRb/om4GZJm4BngCeB7iK3zc2MuB24HUBSm6QdJ1jvLOC1E9y20vi96MvvR19+P46phPdi0UAL0gyIFmBh3vQCYFf+ChGxH7gSQJKAl5J/E4batpCImH2ixUraEBErT3T7SuL3oi+/H335/Tim0t+LNE8xPQ4slbREUgNwCXB//gqSpiXLAK4GHklCY8htzcwsXam1ICKiW9K1wM+AWuDOiNgs6RPJ8jXAMuAuST3Ac8BVg22bVq1mZna8VAfri4i1wNp+89bkff0osLTYbVN2+ygea6zze9GX34++/H4cU9HvhSIKXvs1M7Mq56E2zMysIAeEmZkVVPUB4TGfjpG0UNJDkrZI2izpulLXVGqSaiU9KenHpa6l1JJeh/dKej75GTm31DWVkqQ/TX5PnpX0XUmNpa5ppFV1QHjMp+N0A5+NiGXAOcCnqvz9ALgO2FLqIsaIm4GfRsSvAW+nit8XSfOBPwFWRsQZ5HpbXlLaqkZeVQcEHvOpj4jYHRFPJF9nyX0AFBzipBpIWgBcCHyz1LWUmqQpwLuAOwAiojMi9pa0qNKrA8ZLqiN3c++QN/OWm2oPiKLHfKo2khYDZwGPlbiUUvo68GdAb4nrGAtOAdqAf0hOuX1T0sRSF1UqEfEK8BXgZWA3sC8i1pW2qpFX7QFR9JhP1UTSJOCHwGeSO9urjqSLgFcjYmOpaxkj6oCzgdsi4izgAFC11+wkTSd3tmEJcDIwUdLlpa1q5FV7QAw5XlS1kVRPLhy+HRE/KnU9JXQe8EFJ28mdevwdSXeXtqSSagFaIuJIi/JecoFRrf4r8FJEtEVEF/Aj4DdLXNOIq/aA8JhPeZIBE+8AtkTE10pdTylFxA0RsSAiFpP7ufi3iKi4vxCLFRGtwE5Jpyezzic3PE61ehk4R9KE5PfmfCrwon2qQ22MdR7z6TjnAR8DnkmGYAf4YjLsidmngW8nf0xtIxmJuRpFxGOS7gWeINf770kqcNgND7VhZmYFVfspJjMzG4ADwszMCnJAmJlZQQ4IMzMryAFhZmYFOSDMxgBJv+0RY22scUCYmVlBDgizYZB0uaT1kjZJ+rvkeRHtkr4q6QlJD0qanay7QtKvJD0t6b5k/B4knSrpAUlPJdu8Ndn9pLznLXw7uUPXrGQcEGZFkrQM+H3gvIhYAfQAfwBMBJ6IiLOBXwA3JpvcBXwhIs4Ensmb/23g1oh4O7nxe3Yn888CPkPu2SSnkLuz3axkqnqoDbNhOh94B/B48sf9eOBVcsOBfz9Z527gR5KmAtMi4hfJ/G8BP5A0GZgfEfcBREQHQLK/9RHRkkxvAhYDv0z9VZkNwAFhVjwB34qIG/rMlL7Ub73Bxq8Z7LTR4byve/Dvp5WYTzGZFe9B4PckzQGQNEPSInK/R7+XrHMZ8MuI2Ae8IemdyfyPAb9Inq/RIulDyT7GSZowmi/CrFj+C8WsSBHxnKQ/B9ZJqgG6gE+Re3jO2yRtBPaRu04B8IfAmiQA8kc//Rjwd5L+V7KPj4ziyzArmkdzNXuTJLVHxKRS12E20nyKyczMCnILwszMCnILwszMCnJAmJlZQQ4IMzMryAFhZmYFOSDMzKyg/w+PFd2e/OBKOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "#from keras.layers import Merge\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.applications import Xception\n",
    "from keras.applications import NASNetLarge\n",
    "from keras.applications import DenseNet201\n",
    "from keras.applications import InceptionResNetV2\n",
    "# define cnn model\n",
    "def define_model(in_shape=(140,140,3), out_shape=335):\n",
    "    # load model\n",
    "    model = InceptionV3(include_top=False, input_shape=in_shape)\n",
    "    # mark loaded layers as not trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False  \n",
    "    # allow last vgg block to be trainable\n",
    "    #model.get_layer('block5_conv1').trainable = True\n",
    "    #model.get_layer('block5_conv2').trainable = True\n",
    "    #model.get_layer('block5_conv3').trainable = True\n",
    "    #model.get_layer('block5_pool').trainable = True\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(32, activation='relu', kernel_initializer='random_normal',kernel_regularizer =regularizers.l1_l2( l1=1e-7,l2=1e-7))(flat1)#\n",
    "    #,kernel_regularizer =tf.keras.regularizers.l1( l=0.01)\n",
    "    #batch=BatchNormalization()(class1)\n",
    "    #max_pool=MaxPooling2D()(batch)\n",
    "    #model.add(Dense(units=128,activation = 'relu'))\n",
    "    drop = Dropout(0.35)(class1)\n",
    "    output = Dense(out_shape, activation='sigmoid')(drop)\n",
    "    # dfine new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    #opt = optimizer.ADAM\n",
    "    opt = SGD(lr=0.2, momentum=0.9,decay=1e-6)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics = fbeta)\n",
    "    return model\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['fbeta'])\n",
    "    plt.plot(history.history['val_fbeta'])\n",
    "    plt.title('accuracy')\n",
    "    plt.ylabel('fbeta')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "    # load dataset\n",
    "trainX, trainY, testX, testY = load_dataset()\n",
    "# create data generator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,featurewise_center=True, horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,featurewise_center=True)\n",
    "    # specify imagenet mean values for centering\n",
    "    #train_datagen.mean = [123.68, 116.779, 103.939]\n",
    "    #test_datagen.mean = [123.68, 116.779, 103.939]\n",
    "    # prepare iterators\n",
    "train_datagen.fit(trainX)\n",
    "test_datagen.fit(testX)\n",
    "train_it = train_datagen.flow(trainX, trainY, batch_size=64)\n",
    "test_it = test_datagen.flow(testX, testY, batch_size=64)\n",
    "    # define model\n",
    "model = define_model()\n",
    "    # fit model\n",
    "history = model.fit(train_it, steps_per_epoch=len(train_it),\n",
    "validation_data=test_it, validation_steps=len(test_it), epochs=10, verbose=1)\n",
    "    # evaluate model\n",
    "loss, fbeta = model.evaluate(test_it, steps=len(test_it), verbose=1)\n",
    "print('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "    # learning curves\n",
    "summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# baseline model with dropout on the planet dataset\n",
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "#from keras.layers import Merge\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from keras.applications import Xception\n",
    "from keras.applications import NASNetLarge\n",
    "from keras.applications import DenseNet201\n",
    "from keras.applications import InceptionResNetV2\n",
    "# define cnn model\n",
    "def define_model(in_shape=(190,314, 3), out_shape=4316):\n",
    "    # load model\n",
    "    model = DenseNet201(include_top=False, input_shape=in_shape)\n",
    "    # mark loaded layers as not trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    # allow last vgg block to be trainable\n",
    "    #model.get_layer('block5_conv1').trainable = True\n",
    "    #model.get_layer('block5_conv2').trainable = True\n",
    "    #model.get_layer('block5_conv3').trainable = True\n",
    "    #model.get_layer('block5_pool').trainable = True\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(32, activation='relu', kernel_initializer='random_normal',kernel_regularizer =regularizers.l1_l2( l1=0.000000001,l2=0.000000001))(flat1)#\n",
    "    #,kernel_regularizer =tf.keras.regularizers.l1( l=0.01)\n",
    "    #batch=BatchNormalization()(class1)\n",
    "    #max_pool=MaxPooling2D()(batch)\n",
    "    #model.add(Dense(units=128,activation = 'relu'))\n",
    "    drop = Dropout(0.2)(class1)\n",
    "    output = Dense(out_shape, activation='sigmoid')(drop)\n",
    "    # dfine new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    #opt = optimizer.ADAM\n",
    "    opt = SGD(lr=0.7, momentum=0.5)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "    return model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # create data generator\n",
    "    train_datagen = ImageDataGenerator(featurewise_center=True, horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
    "    test_datagen = ImageDataGenerator(featurewise_center=True)\n",
    "    # specify imagenet mean values for centering\n",
    "    #train_datagen.mean = [123.68, 116.779, 103.939]\n",
    "    #test_datagen.mean = [123.68, 116.779, 103.939]\n",
    "    # prepare iterators\n",
    "    train_it = train_datagen.flow(trainX, trainY, batch_size=32)\n",
    "    test_it = test_datagen.flow(testX, testY, batch_size=32)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    history = model.fit(train_it, steps_per_epoch=len(train_it),\n",
    "    validation_data=test_it, validation_steps=len(test_it), epochs=2, verbose=1)\n",
    "    # evaluate model\n",
    "    loss, fbeta = model.evaluate(test_it, steps=len(test_it), verbose=1)\n",
    "    print('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import metrics\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "#from keras.layers import Merge\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications import Xception\n",
    "from keras.applications import NASNetLarge\n",
    "from keras.applications import DenseNet201\n",
    "from keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from keras.utils import plot_model\n",
    "#from ann_visualizer.visualize import ann_viz\n",
    "from keras.applications import InceptionResNetV2\n",
    "def define_model(in_shape=(190,314, 3), out_shape=2065):\n",
    "    # load model\n",
    "    model = InceptionResNetV2(include_top=False, input_shape=in_shape)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    # allow last vgg block to be trainable\n",
    "    #model.get_layer('block5_conv1').trainable = True\n",
    "    #model.get_layer('block5_conv2').trainable = True\n",
    "    #model.get_layer('block5_conv3').trainable = True\n",
    "    #model.get_layer('block5_pool').trainable = True\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(32, activation='relu', kernel_initializer='random_normal',kernel_regularizer =regularizers.l1_l2( l1=1e-8,l2=1e-8))(flat1)#\n",
    "    #,kernel_regularizer =tf.keras.regularizers.l1( l=0.01)\n",
    "    #batch=BatchNormalization()(class1)\n",
    "    #max_pool=MaxPooling2D()(batch)\n",
    "    #model.add(Dense(units=128,activation = 'relu'))\n",
    "    drop = Dropout(0.15)(class1)\n",
    "    output = Dense(out_shape, activation='sigmoid')(class1)\n",
    "    # dfine new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    #opt = optimizer.ADAM\n",
    "    opt = SGD(lr=0.5, momentum = 0.5)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "    return model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    # summarize history for loss\n",
    "    #plt.plot(history.history['fbeta'])\n",
    "    #plt.plot(history.history['val_fbeta'])\n",
    "    plt.plot(history.history['loss'], color='blue', label='loss')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='val-loss')\n",
    "    plt.plot(history.history['fbeta'], color='black', label='train-f2score')\n",
    "    plt.plot(history.history['val_fbeta'], color='red', label='test-f2score')\n",
    "    plt.title('model loss and fbeta')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test','train-f2score','test-f2score'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "#def run_test_harness():\n",
    "    # load dataset\n",
    "trainX1, trainY1, testX1, testY1 = load_dataset()\n",
    "    # create data generator\n",
    "train_datagen = ImageDataGenerator(featurewise_center=True, horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
    "test_datagen = ImageDataGenerator(featurewise_center=True)\n",
    "\n",
    "train_it = train_datagen.flow(trainX1, trainY1, batch_size=64)\n",
    "test_it = test_datagen.flow(testX1, testY1, batch_size=64)\n",
    "    # define model\n",
    "model = define_model()\n",
    "    # fit model\n",
    "history = model.fit(train_it, steps_per_epoch=len(train_it),\n",
    "validation_data=test_it, validation_steps=len(test_it), epochs=3, verbose=1)\n",
    "    # evaluate model\n",
    "loss, fbeta = model.evaluate(test_it, steps=len(test_it), verbose=1)\n",
    "print('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "    # learning curves\n",
    "summarize_diagnostics(history)\n",
    "    #ann_viz(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "#run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [n_epochs_cv],\n",
    "    'dropout_rate': [0.0, 0.10, 0.20, 0.30],\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=n_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model \n",
    "model.save(\"model.h5\")\n",
    "#loaded_model = load_model(\"model.h5\") \n",
    "#loss, accuracy = loaded_model.evaluate(test_data, test_targets) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999571 , 0.9999421 , 0.95887464, ..., 0.9976542 , 0.99057984,\n",
       "        0.99440145],\n",
       "       [0.9999572 , 0.9999421 , 0.95888484, ..., 0.9976548 , 0.99058294,\n",
       "        0.9944031 ],\n",
       "       [0.9999572 , 0.9999422 , 0.95888364, ..., 0.9976548 , 0.9905823 ,\n",
       "        0.994403  ],\n",
       "       ...,\n",
       "       [0.99995714, 0.99994206, 0.9588701 , ..., 0.9976535 , 0.99057806,\n",
       "        0.99440026],\n",
       "       [0.9999571 , 0.9999421 , 0.95888484, ..., 0.9976553 , 0.9905837 ,\n",
       "        0.9944041 ],\n",
       "       [0.99995714, 0.99994206, 0.9588729 , ..., 0.99765366, 0.9905795 ,\n",
       "        0.994401  ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_vals = model.predict(test_it, steps=len(test_it))\n",
    "predicted_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_vals[predicted_vals >= 0.94] = 1\n",
    "predicted_vals[predicted_vals <= 0.94] = 0\n",
    "predicted_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "cm1=multilabel_confusion_matrix(testY,predicted_vals)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "score = []\n",
    "for i in range(len(testY)):\n",
    "    score1 = roc_auc_score(testY[i],predicted_vals[i])\n",
    "    score.append(score1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9779850746268658\n",
      "0.9779850746268657\n",
      "0.022014925373134327\n"
     ]
    }
   ],
   "source": [
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        #print('\\nset_true: {0}'.format(set_true))\n",
    "        #print('set_pred: {0}'.format(set_pred))\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        #print('tmp_a: {0}'.format(tmp_a))\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "recall = recall_score(testY,predicted_vals,average='micro')\n",
    "print(recall)\n",
    "accuracy = hamming_score(testY,predicted_vals)\n",
    "print(accuracy)\n",
    "precision = precision_score(testY,predicted_vals,average='micro')\n",
    "print(precision)\n",
    "h_loss = hamming_loss(testY,predicted_vals)\n",
    "print(h_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7531706  0.9070909  0.76818347 0.77047634 0.40134597 0.53475577\n",
      " 0.45767528 0.54019123 0.79943216 0.71474826 0.6390277  0.9163444\n",
      " 0.76782084 0.5216131  0.5738925  0.42444268 0.87563866 0.56849945\n",
      " 0.9691734  0.7827164  0.6488867  0.648545   0.7224454  0.7655648\n",
      " 0.9363706  0.76054615 0.6089323  0.5127853  0.8296776  0.6763642\n",
      " 0.8653209  0.94671404 0.8242276  0.66641426 0.9317034  0.5525591\n",
      " 0.92279875 0.21773994 0.4464489  0.7474635  0.8970195  0.7606018\n",
      " 0.4347903  0.67828983 0.64620024 0.3192467  0.15082675 0.87037116\n",
      " 0.8542737  0.75894237 0.5955496  0.9201027  0.7576709  0.34681702\n",
      " 0.84218204 0.69161665 0.8097879  0.9560134  0.55195755 0.35161397\n",
      " 0.5892229  0.73691195 0.63724995 0.3279738  0.7062819  0.5658614\n",
      " 0.8091023  0.6055113  0.9324207  0.816286   0.85090536 0.45553118\n",
      " 0.40999663 0.7058779  0.93961656 0.8490083  0.71599203 0.81432617\n",
      " 0.7766331  0.5139609  0.44556406 0.38729045 0.821112   0.5537502\n",
      " 0.52002394 0.6557669  0.92052424 0.38935566 0.3618654  0.50400215\n",
      " 0.97580254 0.8143613  0.7601087  0.71003795 0.45254382 0.66776615\n",
      " 0.22361931 0.5035754  0.737287   0.9563036  0.72366077 0.508924\n",
      " 0.33686215 0.90955555 0.82232606 0.7093402  0.97572917 0.44764078\n",
      " 0.8918569  0.6545626  0.78056204 0.5446976  0.8181016  0.6449772\n",
      " 0.68164766 0.7198725  0.9331267  0.41019964 0.71078503 0.72049934\n",
      " 0.7594369  0.7247987  0.9213548  0.9352417  0.8226616  0.95766234\n",
      " 0.9262196  0.8949118  0.9083703  0.7580199  0.7459243  0.7696605\n",
      " 0.8106367  0.7726544  0.9001228  0.86257076 0.74744904 0.5066206\n",
      " 0.15152696 0.64998746 0.7997151  0.8530422  0.81028026 0.83362186\n",
      " 0.34974483 0.7774544  0.19456628 0.6155962  0.78363526 0.4105845\n",
      " 0.8628354  0.84831494 0.94925857 0.85675293 0.7093474  0.96546686\n",
      " 0.9229127  0.86387014 0.92030096 0.9011055  0.9568435  0.6658809\n",
      " 0.7380252  0.6711054  0.9052644  0.4055854  0.86119866 0.8226168\n",
      " 0.65778273 0.9060055  0.91267633 0.8273726  0.7081283  0.3523418\n",
      " 0.56184137 0.7276628  0.63833874 0.8612586  0.29520816 0.8062806\n",
      " 0.6095767  0.61990094 0.8212646  0.77298826 0.77722275 0.61104697\n",
      " 0.51228553 0.590657   0.5785157  0.77307856 0.90810496 0.42042407\n",
      " 0.5715911  0.9265036  0.5196429  0.8115591  0.49877414 0.9302318\n",
      " 0.82952225 0.7653081  0.91572237 0.8286277  0.813914   0.78328764\n",
      " 0.9305172  0.3954726  0.5851641  0.976434   0.8032489  0.87873113\n",
      " 0.79943013 0.39847958 0.97498655 0.95003396 0.8664613  0.49402538\n",
      " 0.32128236 0.923383   0.7339066  0.69930196 0.8364059  0.71539146\n",
      " 0.9377841  0.885455   0.8713707  0.46948308 0.52528715 0.5783314\n",
      " 0.8382903  0.7552668  0.85328996 0.8978729  0.8705437  0.7252073\n",
      " 0.73235774 0.73899126 0.85988456 0.97316283 0.8531753  0.89766157\n",
      " 0.47906625 0.67249274 0.93602437 0.69437647 0.9576833  0.76500976\n",
      " 0.8309262  0.78166616 0.7634429  0.83997923 0.77731234 0.3583634\n",
      " 0.63427895 0.88350594 0.9393928  0.57417303 0.76743174 0.881287\n",
      " 0.85630953 0.78901553 0.96803045 0.23295802 0.7571142  0.9002683\n",
      " 0.80117315 0.72309744 0.49528348 0.9578695  0.55884534 0.90205705\n",
      " 0.85829765 0.7032836  0.56159675 0.91186607 0.5251621  0.937083\n",
      " 0.84194374 0.8356625  0.8353477  0.53233534 0.81552595 0.8982334\n",
      " 0.9057989  0.39651802 0.67823374 0.68757904 0.6315551  0.3326547\n",
      " 0.8611698  0.30997694 0.41126812 0.9254062  0.844389   0.5562869\n",
      " 0.80270517 0.91340506 0.6058543  0.59164894 0.7899488  0.7635406\n",
      " 0.8031675  0.9273995  0.29760534 0.4267202  0.8667277  0.60574466\n",
      " 0.8164471  0.48818344 0.80051076 0.8288568  0.8858605  0.2595721\n",
      " 0.8928385  0.93308216 0.96376324 0.5794125  0.57556736 0.44953594\n",
      " 0.8387464  0.6324619  0.8873471  0.6887785  0.6160082  0.6331014\n",
      " 0.41600206 0.8243004  0.61763746 0.59664065 0.6321964  0.83813286\n",
      " 0.9335724  0.70500743 0.8792114  0.63549554 0.2118355 ]\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    " \n",
    "def create_tag_mapping(mapping_csv):\n",
    "    # create a set of all known tags\n",
    "    labels = set()\n",
    "    for i in range(len(mapping_csv)):\n",
    "        # convert spaced separated tags into an array of tags\n",
    "        tags = mapping_csv['gene_name'][i].split(' ')\n",
    "        # add tags to the set of known labels\n",
    "        labels.update(tags)\n",
    "    # convert set of labels to a list to list\n",
    "    labels = list(labels)\n",
    "    # order set alphabetically\n",
    "    labels.sort()\n",
    "    # dict that maps labels to integers, and the reverse\n",
    "    labels_map = {labels[i]:i for i in range(len(labels))}\n",
    "    inv_labels_map = {i:labels[i] for i in range(len(labels))}\n",
    "    return labels_map, inv_labels_map\n",
    " \n",
    "# convert a prediction to tags\n",
    "def prediction_to_tags(inv_mapping, prediction):\n",
    "    # round probabilities to {0, 1}\n",
    "    values = prediction.round()\n",
    "    # collect all predicted tags\n",
    "    tags = [inv_mapping[i] for i in range(len(values)) if values[i] == 1.0]\n",
    "    return tags\n",
    "\n",
    "mapping_csv = df5\n",
    "\n",
    "img = load_img('0014img.tif', target_size=(140,140))\n",
    "# convert to array\n",
    "img = img_to_array(img)\n",
    "# reshape into a single sample with 3 channels\n",
    "img = img.reshape(1, 140,140, 3)\n",
    "# center pixel data\n",
    "img = img.astype('float32')\n",
    "img=img/255\n",
    "#img = img - [123.68, 116.779, 103.939]\n",
    "\n",
    "_, inv_mapping = create_tag_mapping(mapping_csv)\n",
    "\n",
    "#load_image('trailimg.tif')\n",
    "result = model.predict(img)\n",
    "print(result[0])\n",
    "\n",
    "# map prediction to tags\n",
    "#tags = prediction_to_tags(inv_mapping, result[0])\n",
    "#print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1BG', 'A1BG-AS1', 'A2M', 'A2M-AS1', 'A2ML1', 'A4GALT', 'AAAS', 'AACS', 'AADAC', 'AADAT', 'AAGAB', 'AAK1', 'AAMDC', 'AAMP', 'AANAT']\n"
     ]
    }
   ],
   "source": [
    "l=result[0]\n",
    "sorted_index_array = np.argsort(l) \n",
    "sorted_array = l[sorted_index_array] \n",
    "rslt = sorted_array[-15 :] \n",
    "rslt\n",
    "\n",
    "tags = prediction_to_tags(inv_mapping, rslt)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Visualisation Grad Class Activation Maps (Heatmap) Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "model = model \n",
    "\n",
    "img = image.load_img('0013img.tif', target_size=(140,140))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "#print(decode_predictions(predicted_vals[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    last_conv_layer = model.get_layer('activation_4')\n",
    "    iterate = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output])\n",
    "    model_out, last_conv_layer = iterate(x)\n",
    "    class_out = model_out[:, np.argmax(model_out[0])]\n",
    "    grads = tape.gradient(class_out, last_conv_layer)\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "heatmap = heatmap.reshape((31,31))\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INTENSITY = 0.5\n",
    "\n",
    "img1=cv2.imread(\"0014img.tif\")\n",
    "img1 = cv2.resize(img1,(31,31))\n",
    "#heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "img1 = heatmap * INTENSITY + img1\n",
    "img1 = cv2. resize(img1,(140,140))\n",
    "cv2.imwrite('lol.png', img1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Visualisation Grad Class Activation Maps (Heatmap) Part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, model=None, rescale=255, resize=(190,314)):\n",
    "    \n",
    "    from keras.preprocessing.image import img_to_array, load_img\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    assert type(img_path) == str, \"Image path must be a string\"\n",
    "    assert (\n",
    "        type(rescale) == int or type(rescale) == float\n",
    "    ), \"Rescale factor must be either a float or int\"\n",
    "    assert (\n",
    "        type(resize) == tuple and len(resize) == 2\n",
    "    ), \"Resize target must be a tuple with two elements\"\n",
    "\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img)\n",
    "    img = img / float(rescale)\n",
    "    img = cv2.resize(img, resize)\n",
    "    if model != None:\n",
    "        if len(model.input_shape) == 4:\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keract import display_activations\n",
    "from keract import get_activations\n",
    "import cv2\n",
    "\n",
    "img_path=\"0047img.tif\"\n",
    "x = preprocess_image(img_path=img_path,model=model,resize=(190,314))\n",
    "# Generate the activations \n",
    "activations = get_activations(model, x)\n",
    "#display_activations(activations, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Model\n",
    "from matplotlib import pyplot\n",
    "from numpy import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "# redefine model to output right after the first hidden layer\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "\n",
    "img = load_img('3182img.tif', target_size=(190,314))\n",
    "# convert the image to an array\n",
    "img = img_to_array(img)\n",
    "# expand dimensions so that it represents a single 'sample'\n",
    "img = expand_dims(img, axis=1)\n",
    "# prepare the image (e.g. scale pixel values for the vgg)\n",
    "img = preprocess_input(img)\n",
    "# get feature map for first hidden layer\n",
    "feature_maps = model.predict(img)\n",
    "# plot all 64 maps in an 8x8 squares\n",
    "square = 8\n",
    "ix = 1\n",
    "for _ in range(square):\n",
    "    for _ in range(square):\n",
    "        # specify subplot and turn of axis\n",
    "        ax = pyplot.subplot(square, square, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        pyplot.imshow(feature_maps[0, :,ix-1], cmap='gray')\n",
    "        ix += 1\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CapsuleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "from keras import layers, models, optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def CapsNet(input_shape, n_class, routings):\n",
    "\n",
    "    x = layers.Input(shape=input_shape)\n",
    "\n",
    "   # Layer 1: Just a conventional Conv2D layer\n",
    "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=5, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "   # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "   # Layer 3: Capsule layer. Routing algorithm works here.\n",
    "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
    "    name='digitcaps')(primarycaps)\n",
    "\n",
    "   # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "   # If using tensorflow, this will not be necessary. :)\n",
    "    out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "   # Decoder network.\n",
    "    y = layers.Input(shape=(n_class,))\n",
    "    masked_by_y = Mask()([digitcaps, y]) # The true label is used to mask the output of capsule layer. For training\n",
    "    masked = Mask()(digitcaps) # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "   # Shared Decoder model in training and prediction\n",
    "    decoder = models.Sequential(name='decoder')\n",
    "    decoder.add(layers.Dense(512, activation='relu', input_dim=16*n_class))\n",
    "    decoder.add(layers.Dense(1024, activation='relu'))\n",
    "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "   # Models for training and evaluation (prediction)\n",
    "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "   # manipulate model\n",
    "    noise = layers.Input(shape=(n_class, 16))\n",
    "    noised_digitcaps = layers.Add()([digitcaps, noise])\n",
    "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "    return train_model, eval_model, manipulate_model\n",
    "\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "    0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model, eval_model, manipulate_model = CapsNet(input_shape=(190,252,3),n_class=24916,routings=3)\n",
    "# compile the model\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001),\n",
    "loss=[margin_loss, 'mse'],\n",
    "loss_weights=[1., 0.392],\n",
    "metrics={'capsnet': 'accuracy'})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_generator(x, y, batch_size, shift_fraction=0.1):\n",
    "    train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "    height_shift_range=shift_fraction) # shift up to 2 pixel for MNIST\n",
    "    generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "    while 1:\n",
    "    x_batch, y_batch = generator.next()\n",
    "    yield ([x_batch, y_batch], [y_batch, x_batch])\n",
    "\n",
    "# Training with data augmentation. If shift_fraction=0., also no augmentation.abs\n",
    "    trained_model3 = model.fit(generator=train_generator(trainX, trainY, 1000, 0.1),\n",
    "    steps_per_epoch=int(trainY.shape[0] / 1000),\n",
    "    epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_freqs(labels):\n",
    "\n",
    "    N = labels.shape[0]\n",
    "    positive_frequencies = np.sum(labels, axis=0) / labels.shape[0]\n",
    "    negative_frequencies = 1 - positive_frequencies\n",
    "    return positive_frequencies, negative_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n",
    "\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "\n",
    "        # initialize loss to zero\n",
    "        loss = 0.0\n",
    "        \n",
    "        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "\n",
    "        for i in range(len(pos_weights)):\n",
    "            # for each class, add average weighted loss for that class \n",
    "            loss += -(K.mean( pos_weights[i] * y_true[:,i] * K.log(y_pred[:,i] + epsilon) + \\\n",
    "                                neg_weights[i] * (1 - y_true[:,i]) * K.log(1 - y_pred[:,i] + epsilon), axis = 0))\n",
    "        return loss\n",
    "    \n",
    "        ### END CODE HERE ###\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pos, freq_neg = compute_class_freqs(trainY1)\n",
    "\n",
    "pos_weights = freq_neg\n",
    "neg_weights = freq_pos\n",
    "pos_contribution = freq_pos * pos_weights \n",
    "neg_contribution = freq_neg * neg_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    gamma,alpha = 2.0,0.25\n",
    "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('lol.jpg',0)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitkey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0;\n",
    "for i in model.layers:\n",
    "    i=i+1;\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 140, 140, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 69, 69, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 69, 69, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 69, 69, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 67, 67, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 67, 67, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 67, 67, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 67, 67, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 67, 67, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 67, 67, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 33, 33, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 33, 33, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 33, 33, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 33, 33, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 31, 31, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 31, 31, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 31, 31, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 15, 15, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 15, 15, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 15, 15, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 15, 15, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 15, 15, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 15, 15, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 15, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 15, 15, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 15, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 15, 15, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 15, 15, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 15, 15, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 15, 15, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 15, 15, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 15, 15, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 15, 15, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 15, 15, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 15, 15, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 15, 15, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 15, 15, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 15, 15, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 15, 15, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 15, 15, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 15, 15, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 15, 15, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 15, 15, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 15, 15, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 15, 15, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 15, 15, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 15, 15, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 15, 15, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 15, 15, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 15, 15, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 15, 15, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 15, 15, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 15, 15, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 15, 15, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 15, 15, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 15, 15, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 15, 15, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 15, 15, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 15, 15, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 15, 15, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 15, 15, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 15, 15, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 15, 15, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 15, 15, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 15, 15, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 15, 15, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 15, 15, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 15, 15, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 15, 15, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 15, 15, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 15, 15, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 15, 15, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 15, 15, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 15, 15, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 15, 15, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 15, 15, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 15, 15, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 15, 15, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 15, 15, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 15, 15, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 15, 15, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 15, 15, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 15, 15, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 15, 15, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 15, 15, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 15, 15, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 15, 15, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 15, 15, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 15, 15, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 15, 15, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 15, 15, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 15, 15, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 18432)        0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           589856      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 335)          11055       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,403,695\n",
      "Trainable params: 600,911\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
