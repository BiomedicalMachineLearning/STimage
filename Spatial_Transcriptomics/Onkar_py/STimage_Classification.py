{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2c138-1419-470f-aa5a-fc9b07b410dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import anndata\n",
    "import joblib\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "#Computing ResNet50 features\n",
    "def ResNet50_features(unzipped_file, pre_model):\n",
    "    files = pd.DataFrame(unzipped_file.namelist()).iloc[1:,:][0]\n",
    "    x_scratch_train = []\n",
    "    for imagePath in files:\n",
    "        image = plt.imread(unzipped_file.open(imagePath)).astype('float32')\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = preprocess_input(image)\n",
    "        x_scratch_train.append(image)\n",
    "    x_train = np.vstack(x_scratch_train)\n",
    "    resnet_features = pd.DataFrame(pre_model.predict(x_train, batch_size=1))\n",
    "    resnet_features.index = files.str.split('/', expand=True)[1].str[:-5]\n",
    "    resnet_features = resnet_features.sort_index()\n",
    "    return resnet_features\n",
    "\n",
    "\n",
    "#Training Pre-Processing\n",
    "def LR_model(Path, anndata, gene_list, train_data_library_id, resnet_features):\n",
    "    h5ad = anndata.obs\n",
    "    gene_exp = anndata.to_df()\n",
    "\n",
    "    h5ad['tile_tissue_mask_path'] = h5ad['tile_tissue_mask_path'].str.split('/', expand=True)[3].str[:-5]\n",
    "    h5ad = h5ad.set_index(['tile_tissue_mask_path'])\n",
    "\n",
    "    gene_exp.index = h5ad.index\n",
    "\n",
    "    h5ad = h5ad.sort_index()\n",
    "    gene_exp = gene_exp.sort_index()\n",
    "\n",
    "    resnet_features['dataset'] = h5ad['library_id']\n",
    "    gene_exp['dataset'] = h5ad['library_id']\n",
    "\n",
    "    #Training Data Split, Binarization and Prediction\n",
    "    gene_exp_zscore = gene_exp.groupby('dataset')[gene_list].apply(lambda x: (x-x.mean())/(x.std()))\n",
    "    gene_exp_binary = gene_exp_zscore.apply(lambda x: [0 if y <= 0 else 1 for y in x])\n",
    "    gene_exp_binary['dataset'] = gene_exp['dataset']\n",
    "\n",
    "    model_c = LogisticRegression(max_iter=10000,penalty='elasticnet',C=0.1,solver='saga',l1_ratio=0.5)\n",
    "    clf_resnet = MultiOutputClassifier(model_c).fit(resnet_features.loc[(resnet_features['dataset'] == train_data_library_id)].iloc[:,:-1], gene_exp_binary.loc[(gene_exp_binary['dataset'] == train_data_library_id)].iloc[:,:-1])\n",
    "    joblib.dump(clf_resnet, Path+'LRmodel.pkl')\n",
    "    clf_resnet = joblib.load(Path+'LRmodel.pkl')\n",
    "    pred_gexp = pd.DataFrame(clf_resnet.predict(resnet_features.loc[(resnet_features['dataset'] != train_data_library_id)].iloc[:,:-1]),columns=gene_exp.iloc[:,:-1].columns,index=resnet_features.loc[(resnet_features['dataset'] != train_data_library_id)].index)\n",
    "    pred_gexp['dataset'] = resnet_features.loc[(resnet_features['dataset'] != train_data_library_id)]['dataset']\n",
    "\n",
    "    performance_metrics_all_predictions = [x for _, x in pred_gexp.groupby('dataset')]\n",
    "    gene_exp_binary_all_true = [x for _, x in gene_exp_binary.loc[(gene_exp_binary['dataset'] != train_data_library_id)].groupby('dataset')]\n",
    "    return gene_exp_binary, pred_gexp, performance_metrics_all_predictions, gene_exp_binary_all_true\n",
    "\n",
    "\n",
    "#Boxplot of Performance Metrics\n",
    "def performance_metrics(Path, gene_exp_binary_all_true, performance_metrics_all_predictions, gene_list):\n",
    "    AUROC_genes = []; F1_genes = []; Precision_genes = []; Recall_genes = []\n",
    "    for dataset in range(len(gene_exp_binary_all_true)):\n",
    "        for gene in range(len(gene_list)):\n",
    "            score =  roc_auc_score(performance_metrics_all_predictions[dataset].iloc[:,gene],\n",
    "                                   gene_exp_binary_all_true[dataset].iloc[:,gene])\n",
    "            AUROC_genes.append(score)\n",
    "\n",
    "    for dataset in range(len(gene_exp_binary_all_true)):\n",
    "        for gene in range(len(gene_list)):\n",
    "            score =  f1_score(performance_metrics_all_predictions[dataset].iloc[:,gene],\n",
    "                                   gene_exp_binary_all_true[dataset].iloc[:,gene])\n",
    "            F1_genes.append(score)\n",
    "\n",
    "    for dataset in range(len(gene_exp_binary_all_true)):\n",
    "        for gene in range(len(gene_list)):\n",
    "            score =  precision_score(performance_metrics_all_predictions[dataset].iloc[:,gene],\n",
    "                                   gene_exp_binary_all_true[dataset].iloc[:,gene])\n",
    "            Precision_genes.append(score)\n",
    "\n",
    "    for dataset in range(len(gene_exp_binary_all_true)):\n",
    "        for gene in range(len(gene_list)):\n",
    "            score =  recall_score(performance_metrics_all_predictions[dataset].iloc[:,gene],\n",
    "                                   gene_exp_binary_all_true[dataset].iloc[:,gene])\n",
    "            Recall_genes.append(score)\n",
    "\n",
    "    AUROC_genes = pd.DataFrame(AUROC_genes); F1_genes = pd.DataFrame(F1_genes); Precision_genes = pd.DataFrame(Precision_genes); Recall_genes = pd.DataFrame(Recall_genes)\n",
    "    Performance_metrics = pd.concat([AUROC_genes,F1_genes,Precision_genes,Recall_genes])\n",
    "    Performance_metrics['patient'] = list(np.repeat(pd.concat(gene_exp_binary_all_true).loc[(pd.concat(gene_exp_binary_all_true)['dataset'] != train_data_library_id)].drop_duplicates('dataset', keep='first')['dataset'].to_list(),len(gene_list)))*4\n",
    "    Performance_metrics['genes'] = gene_list*len(set(Performance_metrics['patient']))*4\n",
    "    Performance_metrics['measure'] = ['AUROC']*len(AUROC_genes)+['F1']*len(F1_genes)+['Precision']*len(Precision_genes)+['Recall']*len(Recall_genes)\n",
    "\n",
    "    plt.figure(figsize=(19.20,10.80))\n",
    "    im = sns.boxplot(x=\"patient\", y=0, hue=\"measure\", data=Performance_metrics,linewidth=4)\n",
    "    im.axhline(0.5, linewidth=2, color='r')\n",
    "    return im.figure.savefig(Path+'Classification_boxplot.png')\n",
    "\n",
    "\n",
    "# Clustering followed by Classification\n",
    "def clustering(Path,gene_exp_binary,train_data_library_id,pred_gexp):\n",
    "    clustering = AgglomerativeClustering(n_clusters = 2, affinity = 'euclidean', linkage = 'ward')\n",
    "    model_c = LogisticRegression(max_iter=10000,penalty='elasticnet',C=0.1,solver='saga',l1_ratio=0.5)\n",
    "    clf_can_v_non_can = model_c.fit(gene_exp_binary.loc[(gene_exp_binary['dataset'] == train_data_library_id)].iloc[:,:-1],\n",
    "                                                          clustering.fit_predict(gene_exp_binary.loc[(gene_exp_binary['dataset'] == train_data_library_id)].iloc[:,:-1]))\n",
    "    joblib.dump(clf_can_v_non_can, Path+'resnet_block1_log_scaled_relu_clustering_logistic.pkl')\n",
    "    clf_can_v_non_can = joblib.load(Path+'resnet_block1_log_scaled_relu_clustering_logistic.pkl')\n",
    "    can_v_non_can_spot = pd.DataFrame(clf_can_v_non_can.predict(pred_gexp.iloc[:,:-1]))\n",
    "    can_v_non_can_spot['dataset'] = list(pred_gexp['dataset'])\n",
    "    return can_v_non_can_spot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Path = \"/home/uqomulay/90days/\"\n",
    "anndata = anndata.read_h5ad(Path+\"all_adata.h5ad\")\n",
    "unzipped_file = zipfile.ZipFile(Path+\"tiles-wiener-Nov-03.zip\", \"r\")\n",
    "model = ResNet50(weights='imagenet', pooling=\"avg\", include_top = False)\n",
    "gene_list = ['CD74', 'CD24', 'CD63', 'CD81', 'CD151', 'COX6C', 'TP53', 'PABPC1',\n",
    "             'GNAS', 'B2M', 'SPARC', 'HSP90AB1', 'TFF3', 'ATP1A1', 'FASN']\n",
    "train_data_library_id = \"block1\"\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(Path)\n",
    "resnet_features = ResNet50_features(unzipped_file, model)\n",
    "print(\"1\")\n",
    "gene_exp_binary, pred_gexp, performance_metrics_all_predictions, gene_exp_binary_all_true = LR_model(Path, anndata, gene_list, train_data_library_id, resnet_features)\n",
    "print(\"2\")\n",
    "performance_metrics(Path,gene_exp_binary_all_true, performance_metrics_all_predictions, gene_list)\n",
    "print(\"3\")\n",
    "can_v_non_can_spot = clustering(Path, gene_exp_binary, train_data_library_id, pred_gexp)\n",
    "print(\"4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
