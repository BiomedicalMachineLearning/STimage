{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fb8468-4c79-40e4-9d9d-d87551a2c05c",
   "metadata": {},
   "source": [
    "# STimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4664e60-f16f-42d6-a2bc-cd53bdd81e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stlearn as st\n",
    "st.settings.set_figure_params(dpi=300)\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import sys; import scanpy as sc\n",
    "from typing import Optional, Union\n",
    "from anndata import AnnData\n",
    "import pandas as pd\n",
    "from typing import Optional, Union\n",
    "from anndata import AnnData\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os; import sys\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.color import rgb2hed\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from numpy import array, argmax, load\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from PIL import Image\n",
    "import lime; from lime import lime_image\n",
    "\n",
    "import skimage\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.segmentation import mark_boundaries, watershed\n",
    "from skimage.color import rgb2hed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import label\n",
    "import glob\n",
    "from tensorflow.keras.preprocessing import image as image_fun\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import area_opening\n",
    "import math; import copy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def tiling(\n",
    "        adata: AnnData,\n",
    "        out_path: Union[Path, str] = \"./tiling\",\n",
    "        library_id: str = None,\n",
    "        crop_size: int = 40,\n",
    "        target_size: int = 299,\n",
    "        verbose: bool = False,\n",
    "        copy: bool = False,\n",
    ") -> Optional[AnnData]:\n",
    "    \n",
    "\n",
    "    if library_id is None:\n",
    "        library_id = list(adata.uns[\"spatial\"].keys())[0]\n",
    "\n",
    "    # Check the exist of out_path\n",
    "    if not os.path.isdir(out_path):\n",
    "        os.mkdir(out_path)\n",
    "\n",
    "    image = adata.uns[\"spatial\"][library_id][\"images\"][adata.uns[\"spatial\"][\"use_quality\"]]\n",
    "    if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    img_pillow = Image.fromarray(image)\n",
    "    tile_names = []\n",
    "\n",
    "    with tqdm(\n",
    "            total=len(adata),\n",
    "            desc=\"Tiling image\",\n",
    "            bar_format=\"{l_bar}{bar} [ time left: {remaining} ]\",\n",
    "    ) as pbar:\n",
    "        for imagerow, imagecol in zip(adata.obs[\"imagerow\"], adata.obs[\"imagecol\"]):\n",
    "            imagerow_down = imagerow - crop_size / 2\n",
    "            imagerow_up = imagerow + crop_size / 2\n",
    "            imagecol_left = imagecol - crop_size / 2\n",
    "            imagecol_right = imagecol + crop_size / 2\n",
    "            tile = img_pillow.crop(\n",
    "                (imagecol_left, imagerow_down, imagecol_right, imagerow_up)\n",
    "            )\n",
    "            # tile.thumbnail((target_size, target_size), Image.ANTIALIAS)\n",
    "            tile = tile.resize((target_size, target_size))\n",
    "            tile_name = library_id + \"-\" + str(imagecol) + \"-\" + str(imagerow) + \"-\" + str(crop_size)#np.arange(len(pd.Series(adata))+1).astype(str).str.zfill(4)+1 + \"-\" +\n",
    "            out_tile = Path(out_path) / (tile_name + \".jpeg\")\n",
    "            tile_names.append(str(out_tile))\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"generate tile at location ({}, {})\".format(\n",
    "                        str(imagecol), str(imagerow)\n",
    "                    )\n",
    "                )\n",
    "            tile.save(out_tile, \"JPEG\")\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    adata.obs[\"tile_path\"] = tile_names\n",
    "    return adata if copy else None\n",
    "\n",
    "#os.chdir(\"C:/Users/ONKAR\")\n",
    "#from STimage.stimage._utils import gene_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458700e0-9fe7-48a6-b676-599656088b32",
   "metadata": {},
   "source": [
    "# 10X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4548dbaf-0fcb-4d39-a6a1-ecd51751f7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log transformation step is finished in adata.X\n",
      "Log transformation step is finished in adata.X\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = Path(\"D:/Onkar_D/UQ/Project_Spt.Transcriptomics/Output_files\")\n",
    "TILE_PATH = BASE_PATH / \"tiles\"\n",
    "TILE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "SAMPLE = \"block1\"\n",
    "Sample1 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\", 0)\n",
    "Sample1.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img\n",
    "\n",
    "\n",
    "SAMPLE = \"block2\"\n",
    "Sample2 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"V1_Breast_Cancer_Block_A_Section_2_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "                  #source_image_path=BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"V1_Breast_Cancer_Block_A_Section_2_image.tif\", 0)\n",
    "Sample2.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img\n",
    "\n",
    "\n",
    "for adata in [Sample1,Sample2,]:\n",
    "    #Preprocessing\n",
    "    st.pp.filter_genes(adata,min_cells=3)\n",
    "    st.pp.log1p(adata)\n",
    "    sc.pp.filter_cells(adata,min_counts=100)\n",
    "    \n",
    "    TILE_PATH_ = TILE_PATH / list(adata.uns[\"spatial\"].keys())[0]\n",
    "    TILE_PATH_.mkdir(parents=True, exist_ok=True)\n",
    "    #tiling(adata, TILE_PATH_, crop_size=299)\n",
    "    #st.pp.extract_feature(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7b1a22-c937-41d0-96c7-8b88d613775b",
   "metadata": {},
   "source": [
    "# FFPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9843f507-f143-4f5e-bd27-c4346776580b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log transformation step is finished in adata.X\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = Path(\"D:/Onkar_D/UQ/Project_Spt.Transcriptomics/Output_files\")\n",
    "TILE_PATH = BASE_PATH / \"tiles\"\n",
    "TILE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "SAMPLE = \"FFPE_Breast_Cancer\"\n",
    "Sample3 = st.Read10X(BASE_PATH / SAMPLE, \n",
    "                  library_id=SAMPLE, \n",
    "                  count_file=\"Visium_FFPE_Human_Breast_Cancer_filtered_feature_bc_matrix.h5\",\n",
    "                  quality=\"fulres\",)\n",
    "img = plt.imread(BASE_PATH / SAMPLE /\"Visium_FFPE_Human_Breast_Cancer_image.tif\", 0)\n",
    "Sample3.uns[\"spatial\"][SAMPLE]['images'][\"fulres\"] = img\n",
    "\n",
    "\n",
    "Sample3_un_norm = copy.copy(Sample3)\n",
    "for adata in [Sample3,]:\n",
    "     \n",
    "    st.pp.filter_genes(adata,min_cells=3)\n",
    "    sc.pp.filter_cells(adata,min_counts=100)\n",
    "    st.pp.log1p(adata)\n",
    "    \n",
    "    TILE_PATH_ = TILE_PATH / list(adata.uns[\"spatial\"].keys())[0]\n",
    "    TILE_PATH_.mkdir(parents=True, exist_ok=True)\n",
    "    #tiling(adata, TILE_PATH_, crop_size=299)\n",
    "    #st.pp.extract_feature(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbdca3e-2f1c-4f88-8525-7206ae497cd8",
   "metadata": {},
   "source": [
    "### st.pp.extract_features will give us ResNet50 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d9613-7016-499f-b584-845225133b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wd = \"D:/Onkar_D/UQ/Project_Spt.Transcriptomics/Output_files/pickle\"\n",
    "pd.DataFrame(Sample1.obsm['X_tile_feature']).to_csv(wd+'Sample1_small_ResNet50.csv')\n",
    "pd.DataFrame(Sample2.obsm['X_tile_feature']).to_csv(wd+'Sample2_small_ResNet50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c99b8-adac-4c4f-a675-be6b6f9e5fff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wd = \"D:/Onkar_D/UQ/Project_Spt.Transcriptomics/Output_files/pickle\"\n",
    "pd.DataFrame(Sample3.obsm['X_tile_feature']).to_csv(wd+'Sample3_small_ResNet50.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f5122-a402-4355-85d3-ebd3c6ff1366",
   "metadata": {},
   "source": [
    "# Concatenation of 10X & FFPE ResNet Features of Small and Big Tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57258f82-ef70-4149-8d39-9cdea8ac0aff",
   "metadata": {},
   "source": [
    "### X_train -> 10X Tissue 1A -> Training Features both Small and Big\n",
    "### X_test -> 10X Tissue 2A -> External Test Features both Small and Big\n",
    "### X_test_ffpe -> FFPE -> External Test Features both Small and Big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f43ebd-140d-4d10-bb12-89aa2184ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3798, 4096) (3986, 4096) (2518, 4096)\n"
     ]
    }
   ],
   "source": [
    "wd = \"D:/Onkar_D/UQ/Project_Spt.Transcriptomics/Output_files/pickle/\"\n",
    "\n",
    "#10X\n",
    "Sample1_resnet = pd.read_csv(wd+'Sample1_small_ResNet50.csv').iloc[:,1:] #Renset Features of Small 299 size tiles adata.obsm[X_tile_feature] --> saved as dataframe\n",
    "Sample1_big_resnet = pd.read_csv(wd+'Sample1_big_ResNet50.csv').iloc[:,1:] # Renset Features of Small 1950 size tiles adata.obsm[X_tile_feature] --> saved as dataframe\n",
    "X_train = pd.concat([Sample1_resnet, Sample1_big_resnet],axis=1)\n",
    "X_train.columns = np.arange(len(X_train.columns))\n",
    "\n",
    "#10X\n",
    "Sample2_resnet = pd.read_csv(wd+'Sample2_small_ResNet50.csv').iloc[:,1:] #Renset Features of Small 299 size tiles adata.obsm[X_tile_feature] --> saved as dataframe\n",
    "Sample2_big_resnet = pd.read_csv(wd+'Sample2_big_ResNet50.csv').iloc[:,1:]\n",
    "X_test = pd.concat([Sample2_resnet, Sample2_big_resnet],axis=1)\n",
    "X_test.columns = np.arange(len(X_test.columns))\n",
    "\n",
    "#FFPE\n",
    "Sample2_resnet_ffpe = pd.read_csv(wd+'Sample3_small_ResNet50.csv').iloc[:,1:] #Renset Features of Small 299 size tiles adata.obsm[X_tile_feature] --> saved as dataframe\n",
    "Sample2_big_resnet_ffpe = pd.read_csv(wd+'Sample3_big_ResNet50.csv').iloc[:,1:]\n",
    "X_test_ffpe = pd.concat([Sample2_resnet_ffpe, Sample2_big_resnet_ffpe],axis=1)\n",
    "X_test_ffpe.columns = np.arange(len(X_test_ffpe.columns))\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_test_ffpe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e9c307-2dc3-4394-a766-6e2df85caed1",
   "metadata": {},
   "source": [
    "# Hierarchial Clustering of the Spots \n",
    "### This information will be added along with Classifier to train regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f09736-704c-49f6-acc4-77edfd6b36ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "hc1 = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\n",
    "hc2 = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage = 'ward')\n",
    "hc3 = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage = 'ward')\n",
    "\n",
    "Spots1_hc = hc1.fit_predict(X_train)\n",
    "Spots2_hc = hc2.fit_predict(X_test)\n",
    "Spots3_hc = hc3.fit_predict(X_test_ffpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7077865f-c797-41ec-8897-f526f7079e1d",
   "metadata": {},
   "source": [
    "## Train MLP Classifier for Concatenated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b512743-40de-48f3-b890-ecf3ae4a264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier; from sklearn.multioutput import MultiOutputRegressor; import lightgbm as lgb\n",
    "import pandas as pd; import shap; import numpy as np; import joblib\n",
    "from sklearn import preprocessing; from sklearn.preprocessing import LabelEncoder;\n",
    "from sklearn import preprocessing; from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score; from sklearn.model_selection import train_test_split; from sklearn.neural_network import MLPClassifier; from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "biomarker_list_1 = [\"COX6C\", \"TTLL12\", \"CD74\"]#['COX6C','TTLL12','PGM5','KRT5','SLITRK6', 'CPB1', \"PABPC1\", \"GNAS\", \"HSP90AB1\", \"TFF3\", \"ATP1A1\", \"B2M\", \"FASN\", \"ESR1\", \"SPARC\", \"ACTG1\", \"HLA-B\", \"LINC00645\", \"MALAT1\"]\n",
    "biomarker_list_2 = ['COX6C','TTLL12', \"PABPC1\", \"GNAS\", \"HSP90AB1\", \"TFF3\", \"ATP1A1\", \"B2M\", \"FASN\", \"SPARC\"]\n",
    "\n",
    "#\n",
    "\n",
    "#lgb.LGBMRegressor()\n",
    "model_c = MLPClassifier(max_iter=10000)\n",
    "model_r = MLPRegressor(max_iter=10000)\n",
    "    \n",
    "MinMax_scaler_y_1 = preprocessing.MinMaxScaler(feature_range =(0, 1))\n",
    "MinMax_scaler_y_2 = preprocessing.MinMaxScaler(feature_range =(0, 1))\n",
    "\n",
    "Y_1 = Sample1.to_df()[biomarker_list_1]\n",
    "Y_1 = MinMax_scaler_y_1.fit_transform(Y_1) \n",
    "Y_1 = pd.DataFrame(data=Y_1)\n",
    "Y_1 = Y_1.apply(lambda x: pd.cut(x, bins=[-0.01, 0.5, 1.01], labels = [0, 1]))\n",
    "#Y_1 = Y_1.apply(lambda x: pd.qcut(x, 2,duplicates='drop',labels=False))\"\"\"\n",
    "\n",
    "test_Y_1 = Sample2.to_df()[biomarker_list_1]\n",
    "test_Y_1 = MinMax_scaler_y_2.fit_transform(test_Y_1)\n",
    "test_Y_1 = pd.DataFrame(data=test_Y_1)\n",
    "test_Y_1 = test_Y_1.apply(lambda x: pd.cut(x, bins=[-0.01, 0.5, 1.01], labels = [0, 1]))\n",
    "#test_Y_1 = test_Y_1.apply(lambda x: pd.qcut(x, 2,duplicates='drop',labels=False))\n",
    "test_Y_1 = test_Y_1.fillna(0)\n",
    "\n",
    "Y_1 = Y_1.astype('int64')\n",
    "test_Y_1 = test_Y_1.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eba55f-0475-4353-8b56-9e1541779a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib; wd = \"D:/Onkar_D/UQ/Project_Spt.Transcriptomics/Output_files/pickle/\"\n",
    "\n",
    "model_c = MultiOutputClassifier(model_c).fit(X_train, Y_1)\n",
    "pred = model_c.predict(X_test)\n",
    "joblib.dump(model_c, wd+'Temp-Biomarker_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c946b8-416b-403b-b851-00d48111db48",
   "metadata": {},
   "source": [
    "# Regression \n",
    "## Added information along with concatenated Resnet features -> Hierarchial cluster outputs and Low or High Spot Classification output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7411f975-6a6e-4f6f-aa20-c1f234c69470",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Spots2_hc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2518 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  Spots2_hc\n",
       "0     1  0  1  1  1  1  0  1  1  1          2\n",
       "1     0  0  1  1  0  0  0  1  0  0          0\n",
       "2     0  0  1  1  1  0  0  1  0  0          0\n",
       "3     0  0  0  0  0  0  0  0  0  0          0\n",
       "4     0  0  1  0  0  0  0  0  0  0          0\n",
       "...  .. .. .. .. .. .. .. .. .. ..        ...\n",
       "2513  0  0  0  1  0  1  0  0  0  0          0\n",
       "2514  0  0  0  1  0  1  0  0  0  0          0\n",
       "2515  0  0  0  0  0  1  0  0  0  0          1\n",
       "2516  0  0  0  1  0  1  0  0  0  0          0\n",
       "2517  0  0  1  0  0  0  1  1  0  0          0\n",
       "\n",
       "[2518 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reg_train = pd.DataFrame()\n",
    "Reg_train = Y_1\n",
    "Reg_train[\"Spots1_hc\"] = Spots1_hc\n",
    "\n",
    "\n",
    "Reg_test = pd.DataFrame()\n",
    "Reg_test = pd.DataFrame(pred)\n",
    "Reg_test[\"Spots2_hc\"] = Spots2_hc\n",
    "Reg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faec158-1446-4b8e-ab20-529b8b678e08",
   "metadata": {},
   "source": [
    "## For every gene the particular Outputs of Low and High spot is selected and concatenated with resnet features and hierarchial cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10c718ca-b54b-4d04-a0f8-ccc00db82d46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg_pred = []\n",
    "for i in range(0,len(pred[0])):\n",
    "    Train = pd.concat([X_train, Reg_train.iloc[:,[i,len(pred[0])]]], axis=1)\n",
    "    Test = pd.concat([X_test_ffpe, Reg_test.iloc[:,[i,len(pred[0])]]], axis=1)\n",
    "    reg = model_r.fit(Train, Sample1.to_df()[biomarker_list_1[i]])\n",
    "    pred2 = reg.predict(Test)\n",
    "    reg_pred.append(pred2)\n",
    "pd.DataFrame(reg_pred).T.to_csv(wd+\"Regression_FFPE.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a741f97-3521-43da-8f67-23d186745b55",
   "metadata": {},
   "source": [
    "# Can be ignored from below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ff283c-9cf5-44ce-a01b-8c0738819a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wd = 'D:/Onkar_D/UQ/Project_Spt.Transcriptomics/Output_files/pickle/'\n",
    "pred2_ffpe = pd.read_csv(wd+'Regression_FFPE.csv')\n",
    "pred2_10x = pd.read_csv(wd+'Regression_10X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccf7fed6-7314-4d8c-9504-b342027797bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Onkar_D/UQ/Project_Spt.Transcriptomics/Output_files/pickle/New_model_reg_biomarker_FFPE.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train = pd.concat([X_train, Reg_train], axis=1)\n",
    "Test = pd.concat([X_test, Reg_test], axis=1)\n",
    "\n",
    "reg = MultiOutputRegressor(model_r).fit(Train, Sample1.to_df()[biomarker_list_1].values)\n",
    "pred2 = reg.predict(Test)\n",
    "joblib.dump(reg, wd+'New_model_reg_biomarker_FFPE.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
